"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[4111],{98529:function(e,t,r){r.r(t),r.d(t,{ASTFeatureExtractor:function(){return j},ASTForAudioClassification:function(){return V},ASTModel:function(){return O},ASTPreTrainedModel:function(){return N},AlbertForMaskedLM:function(){return B},AlbertForQuestionAnswering:function(){return G},AlbertForSequenceClassification:function(){return R},AlbertModel:function(){return q},AlbertPreTrainedModel:function(){return $},AlbertTokenizer:function(){return W},ArceeForCausalLM:function(){return U},ArceeModel:function(){return Q},ArceePreTrainedModel:function(){return X},AudioClassificationPipeline:function(){return H},AutoConfig:function(){return J},AutoFeatureExtractor:function(){return Y},AutoImageProcessor:function(){return K},AutoModel:function(){return Z},AutoModelForAudioClassification:function(){return ee},AutoModelForAudioFrameClassification:function(){return et},AutoModelForAudioTextToText:function(){return er},AutoModelForCTC:function(){return en},AutoModelForCausalLM:function(){return eo},AutoModelForDepthEstimation:function(){return es},AutoModelForDocumentQuestionAnswering:function(){return ei},AutoModelForImageClassification:function(){return ea},AutoModelForImageFeatureExtraction:function(){return el},AutoModelForImageMatting:function(){return ec},AutoModelForImageSegmentation:function(){return eu},AutoModelForImageTextToText:function(){return ed},AutoModelForImageToImage:function(){return em},AutoModelForMaskGeneration:function(){return ep},AutoModelForMaskedLM:function(){return e_},AutoModelForNormalEstimation:function(){return eh},AutoModelForObjectDetection:function(){return ef},AutoModelForPoseEstimation:function(){return eg},AutoModelForQuestionAnswering:function(){return eM},AutoModelForSemanticSegmentation:function(){return ew},AutoModelForSeq2SeqLM:function(){return eT},AutoModelForSequenceClassification:function(){return ex},AutoModelForSpeechSeq2Seq:function(){return eP},AutoModelForTextToSpectrogram:function(){return eb},AutoModelForTextToWaveform:function(){return eF},AutoModelForTokenClassification:function(){return ek},AutoModelForUniversalSegmentation:function(){return ey},AutoModelForVision2Seq:function(){return ev},AutoModelForXVector:function(){return eC},AutoModelForZeroShotObjectDetection:function(){return eS},AutoProcessor:function(){return eE},AutoTokenizer:function(){return eA},AutomaticSpeechRecognitionPipeline:function(){return eL},BackgroundRemovalPipeline:function(){return eI},BartForConditionalGeneration:function(){return eD},BartForSequenceClassification:function(){return ez},BartModel:function(){return ej},BartPretrainedModel:function(){return eV},BartTokenizer:function(){return eO},BaseModelOutput:function(){return eN},BaseStreamer:function(){return eB},BeitFeatureExtractor:function(){return eG},BeitForImageClassification:function(){return eR},BeitModel:function(){return eq},BeitPreTrainedModel:function(){return e$},BertForMaskedLM:function(){return eW},BertForQuestionAnswering:function(){return eU},BertForSequenceClassification:function(){return eQ},BertForTokenClassification:function(){return eX},BertModel:function(){return eH},BertPreTrainedModel:function(){return eJ},BertTokenizer:function(){return eY},BitImageProcessor:function(){return eK},BlenderbotForConditionalGeneration:function(){return eZ},BlenderbotModel:function(){return e0},BlenderbotPreTrainedModel:function(){return e1},BlenderbotSmallForConditionalGeneration:function(){return e2},BlenderbotSmallModel:function(){return e3},BlenderbotSmallPreTrainedModel:function(){return e4},BlenderbotSmallTokenizer:function(){return e5},BlenderbotTokenizer:function(){return e8},BloomForCausalLM:function(){return e6},BloomModel:function(){return e9},BloomPreTrainedModel:function(){return e7},BloomTokenizer:function(){return te},CLIPFeatureExtractor:function(){return tt},CLIPImageProcessor:function(){return tr},CLIPModel:function(){return tn},CLIPPreTrainedModel:function(){return to},CLIPSegForImageSegmentation:function(){return ts},CLIPSegModel:function(){return ti},CLIPSegPreTrainedModel:function(){return ta},CLIPTextModel:function(){return tl},CLIPTextModelWithProjection:function(){return tc},CLIPTokenizer:function(){return tu},CLIPVisionModel:function(){return td},CLIPVisionModelWithProjection:function(){return tm},CamembertForMaskedLM:function(){return tp},CamembertForQuestionAnswering:function(){return t_},CamembertForSequenceClassification:function(){return th},CamembertForTokenClassification:function(){return tf},CamembertModel:function(){return tg},CamembertPreTrainedModel:function(){return tM},CamembertTokenizer:function(){return tw},CausalLMOutput:function(){return tT},CausalLMOutputWithPast:function(){return tx},ChineseCLIPFeatureExtractor:function(){return tP},ChineseCLIPModel:function(){return tb},ChineseCLIPPreTrainedModel:function(){return tF},ClapAudioModelWithProjection:function(){return tk},ClapFeatureExtractor:function(){return ty},ClapModel:function(){return tv},ClapPreTrainedModel:function(){return tC},ClapTextModelWithProjection:function(){return tS},ClassifierFreeGuidanceLogitsProcessor:function(){return tE},CodeGenForCausalLM:function(){return tA},CodeGenModel:function(){return tL},CodeGenPreTrainedModel:function(){return tI},CodeGenTokenizer:function(){return tD},CodeLlamaTokenizer:function(){return tz},CohereForCausalLM:function(){return tj},CohereModel:function(){return tV},CoherePreTrainedModel:function(){return tO},CohereTokenizer:function(){return tN},ConvBertForMaskedLM:function(){return tB},ConvBertForQuestionAnswering:function(){return tG},ConvBertForSequenceClassification:function(){return tR},ConvBertForTokenClassification:function(){return tq},ConvBertModel:function(){return t$},ConvBertPreTrainedModel:function(){return tW},ConvBertTokenizer:function(){return tU},ConvNextFeatureExtractor:function(){return tQ},ConvNextForImageClassification:function(){return tX},ConvNextImageProcessor:function(){return tH},ConvNextModel:function(){return tJ},ConvNextPreTrainedModel:function(){return tY},ConvNextV2ForImageClassification:function(){return tK},ConvNextV2Model:function(){return tZ},ConvNextV2PreTrainedModel:function(){return t0},DFineForObjectDetection:function(){return t1},DFineModel:function(){return t2},DFinePreTrainedModel:function(){return t3},DINOv3ConvNextModel:function(){return t4},DINOv3ConvNextPreTrainedModel:function(){return t5},DINOv3ViTImageProcessor:function(){return t8},DINOv3ViTModel:function(){return t6},DINOv3ViTPreTrainedModel:function(){return t9},DPTFeatureExtractor:function(){return t7},DPTForDepthEstimation:function(){return re},DPTImageProcessor:function(){return rt},DPTModel:function(){return rr},DPTPreTrainedModel:function(){return rn},DacDecoderModel:function(){return ro},DacDecoderOutput:function(){return rs},DacEncoderModel:function(){return ri},DacEncoderOutput:function(){return ra},DacFeatureExtractor:function(){return rl},DacModel:function(){return rc},DacPreTrainedModel:function(){return ru},DataTypeMap:function(){return rd},DebertaForMaskedLM:function(){return rm},DebertaForQuestionAnswering:function(){return rp},DebertaForSequenceClassification:function(){return r_},DebertaForTokenClassification:function(){return rh},DebertaModel:function(){return rf},DebertaPreTrainedModel:function(){return rg},DebertaTokenizer:function(){return rM},DebertaV2ForMaskedLM:function(){return rw},DebertaV2ForQuestionAnswering:function(){return rT},DebertaV2ForSequenceClassification:function(){return rx},DebertaV2ForTokenClassification:function(){return rP},DebertaV2Model:function(){return rb},DebertaV2PreTrainedModel:function(){return rF},DebertaV2Tokenizer:function(){return rk},DecisionTransformerModel:function(){return ry},DecisionTransformerPreTrainedModel:function(){return rv},DeiTFeatureExtractor:function(){return rC},DeiTForImageClassification:function(){return rS},DeiTImageProcessor:function(){return rE},DeiTModel:function(){return rA},DeiTPreTrainedModel:function(){return rL},DepthAnythingForDepthEstimation:function(){return rI},DepthAnythingPreTrainedModel:function(){return rD},DepthEstimationPipeline:function(){return rz},DepthProForDepthEstimation:function(){return rj},DepthProPreTrainedModel:function(){return rV},DetrFeatureExtractor:function(){return rO},DetrForObjectDetection:function(){return rN},DetrForSegmentation:function(){return rB},DetrImageProcessor:function(){return rG},DetrModel:function(){return rR},DetrObjectDetectionOutput:function(){return rq},DetrPreTrainedModel:function(){return r$},DetrSegmentationOutput:function(){return rW},Dinov2ForImageClassification:function(){return rU},Dinov2Model:function(){return rQ},Dinov2PreTrainedModel:function(){return rX},Dinov2WithRegistersForImageClassification:function(){return rH},Dinov2WithRegistersModel:function(){return rJ},Dinov2WithRegistersPreTrainedModel:function(){return rY},DistilBertForMaskedLM:function(){return rK},DistilBertForQuestionAnswering:function(){return rZ},DistilBertForSequenceClassification:function(){return r0},DistilBertForTokenClassification:function(){return r1},DistilBertModel:function(){return r2},DistilBertPreTrainedModel:function(){return r3},DistilBertTokenizer:function(){return r4},DocumentQuestionAnsweringPipeline:function(){return r5},DonutFeatureExtractor:function(){return r8},DonutImageProcessor:function(){return r6},DonutSwinModel:function(){return r9},DonutSwinPreTrainedModel:function(){return r7},EfficientNetForImageClassification:function(){return ne},EfficientNetImageProcessor:function(){return nt},EfficientNetModel:function(){return nr},EfficientNetPreTrainedModel:function(){return nn},ElectraForMaskedLM:function(){return no},ElectraForQuestionAnswering:function(){return ns},ElectraForSequenceClassification:function(){return ni},ElectraForTokenClassification:function(){return na},ElectraModel:function(){return nl},ElectraPreTrainedModel:function(){return nc},ElectraTokenizer:function(){return nu},EncodecFeatureExtractor:function(){return nd},EosTokenCriteria:function(){return nm},Ernie4_5_ForCausalLM:function(){return np},Ernie4_5_Model:function(){return n_},Ernie4_5_PretrainedModel:function(){return nh},Ernie4_5_Tokenizer:function(){return nf},EsmForMaskedLM:function(){return ng},EsmForSequenceClassification:function(){return nM},EsmForTokenClassification:function(){return nw},EsmModel:function(){return nT},EsmPreTrainedModel:function(){return nx},EsmTokenizer:function(){return nP},ExaoneForCausalLM:function(){return nb},ExaoneModel:function(){return nF},ExaonePreTrainedModel:function(){return nk},FFT:function(){return ny},FalconForCausalLM:function(){return nv},FalconModel:function(){return nC},FalconPreTrainedModel:function(){return nS},FalconTokenizer:function(){return nE},FastViTForImageClassification:function(){return nA},FastViTModel:function(){return nL},FastViTPreTrainedModel:function(){return nI},FeatureExtractionPipeline:function(){return nD},FeatureExtractor:function(){return nz},FillMaskPipeline:function(){return nj},Florence2ForConditionalGeneration:function(){return nV},Florence2PreTrainedModel:function(){return nO},Florence2Processor:function(){return nN},ForcedBOSTokenLogitsProcessor:function(){return nB},ForcedEOSTokenLogitsProcessor:function(){return nG},GLPNFeatureExtractor:function(){return nR},GLPNForDepthEstimation:function(){return nq},GLPNModel:function(){return n$},GLPNPreTrainedModel:function(){return nW},GPT2LMHeadModel:function(){return nU},GPT2Model:function(){return nQ},GPT2PreTrainedModel:function(){return nX},GPT2Tokenizer:function(){return nH},GPTBigCodeForCausalLM:function(){return nJ},GPTBigCodeModel:function(){return nY},GPTBigCodePreTrainedModel:function(){return nK},GPTJForCausalLM:function(){return nZ},GPTJModel:function(){return n0},GPTJPreTrainedModel:function(){return n1},GPTNeoForCausalLM:function(){return n2},GPTNeoModel:function(){return n3},GPTNeoPreTrainedModel:function(){return n4},GPTNeoXForCausalLM:function(){return n5},GPTNeoXModel:function(){return n8},GPTNeoXPreTrainedModel:function(){return n6},GPTNeoXTokenizer:function(){return n9},Gemma2ForCausalLM:function(){return n7},Gemma2Model:function(){return oe},Gemma2PreTrainedModel:function(){return ot},Gemma3ForCausalLM:function(){return or},Gemma3Model:function(){return on},Gemma3PreTrainedModel:function(){return oo},Gemma3nAudioFeatureExtractor:function(){return os},Gemma3nForConditionalGeneration:function(){return oi},Gemma3nPreTrainedModel:function(){return oa},Gemma3nProcessor:function(){return ol},GemmaForCausalLM:function(){return oc},GemmaModel:function(){return ou},GemmaPreTrainedModel:function(){return od},GemmaTokenizer:function(){return om},GlmForCausalLM:function(){return op},GlmModel:function(){return o_},GlmPreTrainedModel:function(){return oh},GraniteForCausalLM:function(){return of},GraniteModel:function(){return og},GranitePreTrainedModel:function(){return oM},Grok1Tokenizer:function(){return ow},GroundingDinoForObjectDetection:function(){return oT},GroundingDinoImageProcessor:function(){return ox},GroundingDinoPreTrainedModel:function(){return oP},GroundingDinoProcessor:function(){return ob},GroupViTModel:function(){return oF},GroupViTPreTrainedModel:function(){return ok},HeliumForCausalLM:function(){return oy},HeliumModel:function(){return ov},HeliumPreTrainedModel:function(){return oC},HerbertTokenizer:function(){return oS},HieraForImageClassification:function(){return oE},HieraModel:function(){return oA},HieraPreTrainedModel:function(){return oL},HubertForCTC:function(){return oI},HubertForSequenceClassification:function(){return oD},HubertModel:function(){return oz},HubertPreTrainedModel:function(){return oj},IJepaForImageClassification:function(){return oV},IJepaModel:function(){return oO},IJepaPreTrainedModel:function(){return oN},Idefics3ForConditionalGeneration:function(){return oB},Idefics3ImageProcessor:function(){return oG},Idefics3PreTrainedModel:function(){return oR},Idefics3Processor:function(){return oq},ImageClassificationPipeline:function(){return o$},ImageFeatureExtractionPipeline:function(){return oW},ImageFeatureExtractor:function(){return oU},ImageMattingOutput:function(){return oQ},ImageProcessor:function(){return oX},ImageSegmentationPipeline:function(){return oH},ImageToImagePipeline:function(){return oJ},ImageToTextPipeline:function(){return oY},InterruptableStoppingCriteria:function(){return oK},JAISLMHeadModel:function(){return oZ},JAISModel:function(){return o0},JAISPreTrainedModel:function(){return o1},JinaCLIPImageProcessor:function(){return o2},JinaCLIPModel:function(){return o3},JinaCLIPPreTrainedModel:function(){return o4},JinaCLIPProcessor:function(){return o5},JinaCLIPTextModel:function(){return o8},JinaCLIPVisionModel:function(){return o6},Lfm2ForCausalLM:function(){return o9},Lfm2Model:function(){return o7},Lfm2PreTrainedModel:function(){return se},LiteWhisperForConditionalGeneration:function(){return st},LlamaForCausalLM:function(){return sr},LlamaModel:function(){return sn},LlamaPreTrainedModel:function(){return so},LlamaTokenizer:function(){return ss},LlavaForConditionalGeneration:function(){return si},LlavaOnevisionForConditionalGeneration:function(){return sa},LlavaOnevisionImageProcessor:function(){return sl},LlavaPreTrainedModel:function(){return sc},LlavaProcessor:function(){return su},LlavaQwen2ForCausalLM:function(){return sd},LogitsProcessor:function(){return sm},LogitsProcessorList:function(){return sp},LogitsWarper:function(){return s_},LongT5ForConditionalGeneration:function(){return sh},LongT5Model:function(){return sf},LongT5PreTrainedModel:function(){return sg},M2M100ForConditionalGeneration:function(){return sM},M2M100Model:function(){return sw},M2M100PreTrainedModel:function(){return sT},M2M100Tokenizer:function(){return sx},MBart50Tokenizer:function(){return sP},MBartForCausalLM:function(){return sb},MBartForConditionalGeneration:function(){return sF},MBartForSequenceClassification:function(){return sk},MBartModel:function(){return sy},MBartPreTrainedModel:function(){return sv},MBartTokenizer:function(){return sC},MPNetForMaskedLM:function(){return sS},MPNetForQuestionAnswering:function(){return sE},MPNetForSequenceClassification:function(){return sA},MPNetForTokenClassification:function(){return sL},MPNetModel:function(){return sI},MPNetPreTrainedModel:function(){return sD},MPNetTokenizer:function(){return sz},MT5ForConditionalGeneration:function(){return sj},MT5Model:function(){return sV},MT5PreTrainedModel:function(){return sO},MarianMTModel:function(){return sN},MarianModel:function(){return sB},MarianPreTrainedModel:function(){return sG},MarianTokenizer:function(){return sR},Mask2FormerImageProcessor:function(){return sq},MaskFormerFeatureExtractor:function(){return s$},MaskFormerForInstanceSegmentation:function(){return sW},MaskFormerImageProcessor:function(){return sU},MaskFormerModel:function(){return sQ},MaskFormerPreTrainedModel:function(){return sX},MaskedLMOutput:function(){return sH},MaxLengthCriteria:function(){return sJ},Metric3DForDepthEstimation:function(){return sY},Metric3DPreTrainedModel:function(){return sK},Metric3Dv2ForDepthEstimation:function(){return sZ},Metric3Dv2PreTrainedModel:function(){return s0},MgpstrForSceneTextRecognition:function(){return s1},MgpstrModelOutput:function(){return s2},MgpstrPreTrainedModel:function(){return s3},MgpstrProcessor:function(){return s4},MgpstrTokenizer:function(){return s5},MimiDecoderModel:function(){return s8},MimiDecoderOutput:function(){return s6},MimiEncoderModel:function(){return s9},MimiEncoderOutput:function(){return s7},MimiModel:function(){return ie},MimiPreTrainedModel:function(){return it},MinLengthLogitsProcessor:function(){return ir},MinNewTokensLengthLogitsProcessor:function(){return io},MistralForCausalLM:function(){return is},MistralModel:function(){return ii},MistralPreTrainedModel:function(){return ia},MobileBertForMaskedLM:function(){return il},MobileBertForQuestionAnswering:function(){return ic},MobileBertForSequenceClassification:function(){return iu},MobileBertModel:function(){return id},MobileBertPreTrainedModel:function(){return im},MobileBertTokenizer:function(){return ip},MobileLLMForCausalLM:function(){return i_},MobileLLMModel:function(){return ih},MobileLLMPreTrainedModel:function(){return ig},MobileNetV1FeatureExtractor:function(){return iM},MobileNetV1ForImageClassification:function(){return iw},MobileNetV1ForSemanticSegmentation:function(){return iT},MobileNetV1ImageProcessor:function(){return ix},MobileNetV1Model:function(){return iP},MobileNetV1PreTrainedModel:function(){return ib},MobileNetV2FeatureExtractor:function(){return iF},MobileNetV2ForImageClassification:function(){return ik},MobileNetV2ForSemanticSegmentation:function(){return iy},MobileNetV2ImageProcessor:function(){return iv},MobileNetV2Model:function(){return iC},MobileNetV2PreTrainedModel:function(){return iS},MobileNetV3FeatureExtractor:function(){return iE},MobileNetV3ForImageClassification:function(){return iA},MobileNetV3ForSemanticSegmentation:function(){return iL},MobileNetV3ImageProcessor:function(){return iI},MobileNetV3Model:function(){return iD},MobileNetV3PreTrainedModel:function(){return iz},MobileNetV4FeatureExtractor:function(){return ij},MobileNetV4ForImageClassification:function(){return iV},MobileNetV4ForSemanticSegmentation:function(){return iO},MobileNetV4ImageProcessor:function(){return iN},MobileNetV4Model:function(){return iB},MobileNetV4PreTrainedModel:function(){return iG},MobileViTFeatureExtractor:function(){return iR},MobileViTForImageClassification:function(){return iq},MobileViTImageProcessor:function(){return i$},MobileViTModel:function(){return iW},MobileViTPreTrainedModel:function(){return iU},MobileViTV2ForImageClassification:function(){return iQ},MobileViTV2Model:function(){return iX},MobileViTV2PreTrainedModel:function(){return iH},ModelOutput:function(){return iJ},ModernBertDecoderForCausalLM:function(){return iY},ModernBertDecoderModel:function(){return iK},ModernBertDecoderPreTrainedModel:function(){return iZ},ModernBertForMaskedLM:function(){return i0},ModernBertForSequenceClassification:function(){return i1},ModernBertForTokenClassification:function(){return i2},ModernBertModel:function(){return i3},ModernBertPreTrainedModel:function(){return i4},Moondream1ForConditionalGeneration:function(){return i5},MoonshineFeatureExtractor:function(){return i8},MoonshineForConditionalGeneration:function(){return i6},MoonshineModel:function(){return i9},MoonshinePreTrainedModel:function(){return i7},MoonshineProcessor:function(){return ae},MptForCausalLM:function(){return at},MptModel:function(){return ar},MptPreTrainedModel:function(){return an},MultiModalityCausalLM:function(){return ao},MultiModalityPreTrainedModel:function(){return as},MusicgenForCausalLM:function(){return ai},MusicgenForConditionalGeneration:function(){return aa},MusicgenModel:function(){return al},MusicgenPreTrainedModel:function(){return ac},NeoBertForMaskedLM:function(){return au},NeoBertForQuestionAnswering:function(){return ad},NeoBertForSequenceClassification:function(){return am},NeoBertForTokenClassification:function(){return ap},NeoBertModel:function(){return a_},NeoBertPreTrainedModel:function(){return ah},NllbTokenizer:function(){return af},NoBadWordsLogitsProcessor:function(){return ag},NoRepeatNGramLogitsProcessor:function(){return aM},NomicBertModel:function(){return aw},NomicBertPreTrainedModel:function(){return aT},NougatImageProcessor:function(){return ax},NougatTokenizer:function(){return aP},OPTForCausalLM:function(){return ab},OPTModel:function(){return aF},OPTPreTrainedModel:function(){return ak},ObjectDetectionPipeline:function(){return ay},Olmo2ForCausalLM:function(){return av},Olmo2Model:function(){return aC},Olmo2PreTrainedModel:function(){return aS},OlmoForCausalLM:function(){return aE},OlmoModel:function(){return aA},OlmoPreTrainedModel:function(){return aL},OpenELMForCausalLM:function(){return aI},OpenELMModel:function(){return aD},OpenELMPreTrainedModel:function(){return az},OwlViTFeatureExtractor:function(){return aj},OwlViTForObjectDetection:function(){return aV},OwlViTImageProcessor:function(){return aO},OwlViTModel:function(){return aN},OwlViTPreTrainedModel:function(){return aB},OwlViTProcessor:function(){return aG},Owlv2ForObjectDetection:function(){return aR},Owlv2ImageProcessor:function(){return aq},Owlv2Model:function(){return a$},Owlv2PreTrainedModel:function(){return aW},PaliGemmaForConditionalGeneration:function(){return aU},PaliGemmaPreTrainedModel:function(){return aQ},PaliGemmaProcessor:function(){return aX},PatchTSMixerForPrediction:function(){return aH},PatchTSMixerModel:function(){return aJ},PatchTSMixerPreTrainedModel:function(){return aY},PatchTSTForPrediction:function(){return aK},PatchTSTModel:function(){return aZ},PatchTSTPreTrainedModel:function(){return a0},Phi3ForCausalLM:function(){return a1},Phi3Model:function(){return a2},Phi3PreTrainedModel:function(){return a3},Phi3VForCausalLM:function(){return a4},Phi3VImageProcessor:function(){return a5},Phi3VPreTrainedModel:function(){return a8},Phi3VProcessor:function(){return a6},PhiForCausalLM:function(){return a9},PhiModel:function(){return a7},PhiPreTrainedModel:function(){return le},Pipeline:function(){return lt},PreTrainedModel:function(){return lr},PreTrainedTokenizer:function(){return ln},PretrainedConfig:function(){return lo},PretrainedMixin:function(){return ls},Processor:function(){return li},PvtForImageClassification:function(){return la},PvtImageProcessor:function(){return ll},PvtModel:function(){return lc},PvtPreTrainedModel:function(){return lu},PyAnnoteFeatureExtractor:function(){return ld},PyAnnoteForAudioFrameClassification:function(){return lm},PyAnnoteModel:function(){return lp},PyAnnotePreTrainedModel:function(){return l_},PyAnnoteProcessor:function(){return lh},QuestionAnsweringModelOutput:function(){return lf},QuestionAnsweringPipeline:function(){return lg},Qwen2ForCausalLM:function(){return lM},Qwen2Model:function(){return lw},Qwen2PreTrainedModel:function(){return lT},Qwen2Tokenizer:function(){return lx},Qwen2VLForConditionalGeneration:function(){return lP},Qwen2VLImageProcessor:function(){return lb},Qwen2VLPreTrainedModel:function(){return lF},Qwen2VLProcessor:function(){return lk},Qwen3ForCausalLM:function(){return ly},Qwen3Model:function(){return lv},Qwen3PreTrainedModel:function(){return lC},RFDetrForObjectDetection:function(){return lS},RFDetrModel:function(){return lE},RFDetrObjectDetectionOutput:function(){return lA},RFDetrPreTrainedModel:function(){return lL},RTDetrForObjectDetection:function(){return lI},RTDetrImageProcessor:function(){return lD},RTDetrModel:function(){return lz},RTDetrObjectDetectionOutput:function(){return lj},RTDetrPreTrainedModel:function(){return lV},RTDetrV2ForObjectDetection:function(){return lO},RTDetrV2Model:function(){return lN},RTDetrV2ObjectDetectionOutput:function(){return lB},RTDetrV2PreTrainedModel:function(){return lG},RawAudio:function(){return lR},RawImage:function(){return lq},RawVideo:function(){return l$},RawVideoFrame:function(){return lW},RepetitionPenaltyLogitsProcessor:function(){return lU},ResNetForImageClassification:function(){return lQ},ResNetModel:function(){return lX},ResNetPreTrainedModel:function(){return lH},RoFormerForMaskedLM:function(){return lJ},RoFormerForQuestionAnswering:function(){return lY},RoFormerForSequenceClassification:function(){return lK},RoFormerForTokenClassification:function(){return lZ},RoFormerModel:function(){return l0},RoFormerPreTrainedModel:function(){return l1},RoFormerTokenizer:function(){return l2},RobertaForMaskedLM:function(){return l3},RobertaForQuestionAnswering:function(){return l4},RobertaForSequenceClassification:function(){return l5},RobertaForTokenClassification:function(){return l8},RobertaModel:function(){return l6},RobertaPreTrainedModel:function(){return l9},RobertaTokenizer:function(){return l7},SamImageProcessor:function(){return ce},SamImageSegmentationOutput:function(){return ct},SamModel:function(){return cr},SamPreTrainedModel:function(){return cn},SamProcessor:function(){return co},SapiensForDepthEstimation:function(){return cs},SapiensForNormalEstimation:function(){return ci},SapiensForSemanticSegmentation:function(){return ca},SapiensPreTrainedModel:function(){return cl},SeamlessM4TFeatureExtractor:function(){return cc},SegformerFeatureExtractor:function(){return cu},SegformerForImageClassification:function(){return cd},SegformerForSemanticSegmentation:function(){return cm},SegformerImageProcessor:function(){return cp},SegformerModel:function(){return c_},SegformerPreTrainedModel:function(){return ch},Seq2SeqLMOutput:function(){return cf},SequenceClassifierOutput:function(){return cg},SiglipImageProcessor:function(){return cM},SiglipModel:function(){return cw},SiglipPreTrainedModel:function(){return cT},SiglipTextModel:function(){return cx},SiglipTokenizer:function(){return cP},SiglipVisionModel:function(){return cb},SmolLM3ForCausalLM:function(){return cF},SmolLM3Model:function(){return ck},SmolLM3PreTrainedModel:function(){return cy},SmolVLMForConditionalGeneration:function(){return cv},SmolVLMImageProcessor:function(){return cC},SmolVLMProcessor:function(){return cS},SnacDecoderModel:function(){return cE},SnacEncoderModel:function(){return cA},SnacFeatureExtractor:function(){return cL},SnacModel:function(){return cI},SnacPreTrainedModel:function(){return cD},SpeechT5FeatureExtractor:function(){return cz},SpeechT5ForSpeechToText:function(){return cj},SpeechT5ForTextToSpeech:function(){return cV},SpeechT5HifiGan:function(){return cO},SpeechT5Model:function(){return cN},SpeechT5PreTrainedModel:function(){return cB},SpeechT5Processor:function(){return cG},SpeechT5Tokenizer:function(){return cR},SqueezeBertForMaskedLM:function(){return cq},SqueezeBertForQuestionAnswering:function(){return c$},SqueezeBertForSequenceClassification:function(){return cW},SqueezeBertModel:function(){return cU},SqueezeBertPreTrainedModel:function(){return cQ},SqueezeBertTokenizer:function(){return cX},StableLmForCausalLM:function(){return cH},StableLmModel:function(){return cJ},StableLmPreTrainedModel:function(){return cY},Starcoder2ForCausalLM:function(){return cK},Starcoder2Model:function(){return cZ},Starcoder2PreTrainedModel:function(){return c0},StoppingCriteria:function(){return c1},StoppingCriteriaList:function(){return c2},StyleTextToSpeech2Model:function(){return c3},StyleTextToSpeech2PreTrainedModel:function(){return c4},SummarizationPipeline:function(){return c5},SuppressTokensAtBeginLogitsProcessor:function(){return c8},Swin2SRForImageSuperResolution:function(){return c6},Swin2SRImageProcessor:function(){return c9},Swin2SRModel:function(){return c7},Swin2SRPreTrainedModel:function(){return ue},SwinForImageClassification:function(){return ut},SwinForSemanticSegmentation:function(){return ur},SwinModel:function(){return un},SwinPreTrainedModel:function(){return uo},T5ForConditionalGeneration:function(){return us},T5Model:function(){return ui},T5PreTrainedModel:function(){return ua},T5Tokenizer:function(){return ul},TableTransformerForObjectDetection:function(){return uc},TableTransformerModel:function(){return uu},TableTransformerObjectDetectionOutput:function(){return ud},TableTransformerPreTrainedModel:function(){return um},TemperatureLogitsWarper:function(){return up},Tensor:function(){return u_},Text2TextGenerationPipeline:function(){return uh},TextClassificationPipeline:function(){return uf},TextGenerationPipeline:function(){return ug},TextStreamer:function(){return uM},TextToAudioPipeline:function(){return uw},TokenClassificationPipeline:function(){return uT},TokenClassifierOutput:function(){return ux},TokenizerModel:function(){return uP},TopKLogitsWarper:function(){return ub},TopPLogitsWarper:function(){return uF},TrOCRForCausalLM:function(){return uk},TrOCRPreTrainedModel:function(){return uy},TranslationPipeline:function(){return uv},UltravoxModel:function(){return uC},UltravoxPreTrainedModel:function(){return uS},UltravoxProcessor:function(){return uE},UniSpeechForCTC:function(){return uA},UniSpeechForSequenceClassification:function(){return uL},UniSpeechModel:function(){return uI},UniSpeechPreTrainedModel:function(){return uD},UniSpeechSatForAudioFrameClassification:function(){return uz},UniSpeechSatForCTC:function(){return uj},UniSpeechSatForSequenceClassification:function(){return uV},UniSpeechSatModel:function(){return uO},UniSpeechSatPreTrainedModel:function(){return uN},VLChatProcessor:function(){return uB},VLMImageProcessor:function(){return uG},ViTFeatureExtractor:function(){return uR},ViTForImageClassification:function(){return uq},ViTImageProcessor:function(){return u$},ViTMAEModel:function(){return uW},ViTMAEPreTrainedModel:function(){return uU},ViTMSNForImageClassification:function(){return uQ},ViTMSNModel:function(){return uX},ViTMSNPreTrainedModel:function(){return uH},ViTModel:function(){return uJ},ViTPreTrainedModel:function(){return uY},VisionEncoderDecoderModel:function(){return uK},VitMatteForImageMatting:function(){return uZ},VitMatteImageProcessor:function(){return u0},VitMattePreTrainedModel:function(){return u1},VitPoseForPoseEstimation:function(){return u2},VitPoseImageProcessor:function(){return u3},VitPosePreTrainedModel:function(){return u4},VitsModel:function(){return u5},VitsModelOutput:function(){return u8},VitsPreTrainedModel:function(){return u6},VitsTokenizer:function(){return u9},VoxtralForConditionalGeneration:function(){return u7},VoxtralProcessor:function(){return de},Wav2Vec2BertForCTC:function(){return dt},Wav2Vec2BertForSequenceClassification:function(){return dr},Wav2Vec2BertModel:function(){return dn},Wav2Vec2BertPreTrainedModel:function(){return ds},Wav2Vec2CTCTokenizer:function(){return di},Wav2Vec2FeatureExtractor:function(){return da},Wav2Vec2ForAudioFrameClassification:function(){return dl},Wav2Vec2ForCTC:function(){return dc},Wav2Vec2ForSequenceClassification:function(){return du},Wav2Vec2Model:function(){return dd},Wav2Vec2PreTrainedModel:function(){return dm},Wav2Vec2Processor:function(){return dp},Wav2Vec2ProcessorWithLM:function(){return d_},WavLMForAudioFrameClassification:function(){return dh},WavLMForCTC:function(){return df},WavLMForSequenceClassification:function(){return dg},WavLMForXVector:function(){return dM},WavLMModel:function(){return dw},WavLMPreTrainedModel:function(){return dT},WeSpeakerFeatureExtractor:function(){return dx},WeSpeakerResNetModel:function(){return dP},WeSpeakerResNetPreTrainedModel:function(){return db},WhisperFeatureExtractor:function(){return dF},WhisperForConditionalGeneration:function(){return dk},WhisperModel:function(){return dy},WhisperPreTrainedModel:function(){return dv},WhisperProcessor:function(){return dC},WhisperTextStreamer:function(){return dS},WhisperTimeStampLogitsProcessor:function(){return dE},WhisperTokenizer:function(){return dA},XLMForQuestionAnswering:function(){return dL},XLMForSequenceClassification:function(){return dI},XLMForTokenClassification:function(){return dD},XLMModel:function(){return dz},XLMPreTrainedModel:function(){return dj},XLMRobertaForMaskedLM:function(){return dV},XLMRobertaForQuestionAnswering:function(){return dO},XLMRobertaForSequenceClassification:function(){return dN},XLMRobertaForTokenClassification:function(){return dB},XLMRobertaModel:function(){return dG},XLMRobertaPreTrainedModel:function(){return dR},XLMRobertaTokenizer:function(){return dq},XLMTokenizer:function(){return d$},XLMWithLMHeadModel:function(){return dW},XVectorOutput:function(){return dU},YolosFeatureExtractor:function(){return dQ},YolosForObjectDetection:function(){return dX},YolosImageProcessor:function(){return dH},YolosModel:function(){return dJ},YolosObjectDetectionOutput:function(){return dY},YolosPreTrainedModel:function(){return dK},ZeroShotAudioClassificationPipeline:function(){return dZ},ZeroShotClassificationPipeline:function(){return d0},ZeroShotImageClassificationPipeline:function(){return d1},ZeroShotObjectDetectionPipeline:function(){return d2},bankers_round:function(){return d3},cat:function(){return d4},cos_sim:function(){return d5},dot:function(){return d8},dynamic_time_warping:function(){return d6},env:function(){return d9},full:function(){return d7},full_like:function(){return me},getCacheShapes:function(){return mt},hamming:function(){return mr},hanning:function(){return mn},interpolate:function(){return mo},interpolate_4d:function(){return ms},interpolate_data:function(){return mi},is_chinese_char:function(){return ma},layer_norm:function(){return ml},load_image:function(){return mc},load_video:function(){return mu},log_softmax:function(){return md},magnitude:function(){return mm},matmul:function(){return mp},max:function(){return m_},mean:function(){return mh},mean_pooling:function(){return mf},medianFilter:function(){return mg},mel_filter_bank:function(){return mM},min:function(){return mw},ones:function(){return mT},ones_like:function(){return mx},permute:function(){return mP},permute_data:function(){return mb},pipeline:function(){return mF},quantize_embeddings:function(){return mk},rand:function(){return my},read_audio:function(){return mv},rfft:function(){return mC},round:function(){return mS},slice:function(){return mE},softmax:function(){return mA},spectrogram:function(){return mL},stack:function(){return mI},std_mean:function(){return mD},topk:function(){return mz},window_function:function(){return mj},zeros:function(){return mV},zeros_like:function(){return mO}});var n,o,s,i,a,l,c,u,d,m,p,_,h,f,g,M,w,T,x,P,b,F,k,y,v,C=r(38328),S=r(74057),E=r(83454),A=r(21876).Buffer,L={"onnxruntime-common":/*!*************************************!*\
  !*** external "onnxruntime-common" ***!
  \*************************************/e=>{e.exports=C},"onnxruntime-web":/*!**********************************!*\
  !*** external "onnxruntime-web" ***!
  \**********************************/e=>{e.exports=v||(v=r.t(S,2))},"?2ce3":/*!**********************************!*\
  !*** onnxruntime-node (ignored) ***!
  \**********************************/()=>{},"?7992":/*!*************************!*\
  !*** node:fs (ignored) ***!
  \*************************/()=>{},"?5af5":/*!***************************!*\
  !*** node:path (ignored) ***!
  \***************************/()=>{},"?2b25":/*!***********************!*\
  !*** sharp (ignored) ***!
  \***********************/()=>{},"?db59":/*!*************************!*\
  !*** node:fs (ignored) ***!
  \*************************/()=>{},"?383f":/*!***************************!*\
  !*** node:path (ignored) ***!
  \***************************/()=>{},"?fa4b":/*!**************************!*\
  !*** node:url (ignored) ***!
  \**************************/()=>{},"./node_modules/@huggingface/jinja/dist/index.js":/*!*******************************************************!*\
  !*** ./node_modules/@huggingface/jinja/dist/index.js ***!
  \*******************************************************/(e,t,r)=>{r.r(t),r.d(t,{Environment:()=>es,Interpreter:()=>ei,Template:()=>eu,parse:()=>G,tokenize:()=>c});var n=Object.freeze({Text:"Text",NumericLiteral:"NumericLiteral",StringLiteral:"StringLiteral",Identifier:"Identifier",Equals:"Equals",OpenParen:"OpenParen",CloseParen:"CloseParen",OpenStatement:"OpenStatement",CloseStatement:"CloseStatement",OpenExpression:"OpenExpression",CloseExpression:"CloseExpression",OpenSquareBracket:"OpenSquareBracket",CloseSquareBracket:"CloseSquareBracket",OpenCurlyBracket:"OpenCurlyBracket",CloseCurlyBracket:"CloseCurlyBracket",Comma:"Comma",Dot:"Dot",Colon:"Colon",Pipe:"Pipe",CallOperator:"CallOperator",AdditiveBinaryOperator:"AdditiveBinaryOperator",MultiplicativeBinaryOperator:"MultiplicativeBinaryOperator",ComparisonBinaryOperator:"ComparisonBinaryOperator",UnaryOperator:"UnaryOperator",Comment:"Comment"}),o=class{constructor(e,t){this.value=e,this.type=t}};function s(e){return/\w/.test(e)}function i(e){return/[0-9]/.test(e)}var a=[["{%",n.OpenStatement],["%}",n.CloseStatement],["{{",n.OpenExpression],["}}",n.CloseExpression],["(",n.OpenParen],[")",n.CloseParen],["{",n.OpenCurlyBracket],["}",n.CloseCurlyBracket],["[",n.OpenSquareBracket],["]",n.CloseSquareBracket],[",",n.Comma],[".",n.Dot],[":",n.Colon],["|",n.Pipe],["<=",n.ComparisonBinaryOperator],[">=",n.ComparisonBinaryOperator],["==",n.ComparisonBinaryOperator],["!=",n.ComparisonBinaryOperator],["<",n.ComparisonBinaryOperator],[">",n.ComparisonBinaryOperator],["+",n.AdditiveBinaryOperator],["-",n.AdditiveBinaryOperator],["~",n.AdditiveBinaryOperator],["*",n.MultiplicativeBinaryOperator],["/",n.MultiplicativeBinaryOperator],["%",n.MultiplicativeBinaryOperator],["=",n.Equals]],l=new Map([["n","\n"],["t","	"],["r","\r"],["b","\b"],["f","\f"],["v","\v"],["'","'"],['"','"'],["\\","\\"]]);function c(e,t={}){let r=[],c=function(e,t={}){return e.endsWith("\n")&&(e=e.slice(0,-1)),t.lstrip_blocks&&(e=e.replace(/^[ \t]*({[#%-])/gm,"$1")),t.trim_blocks&&(e=e.replace(/([#%-]})\n/g,"$1")),e.replace(/-%}\s*/g,"%}").replace(/\s*{%-/g,"{%").replace(/-}}\s*/g,"}}").replace(/\s*{{-/g,"{{").replace(/-#}\s*/g,"#}").replace(/\s*{#-/g,"{#").replace(/{%\s*(end)?generation\s*%}/gs,"")}(e,t),u=0,d=0,m=e=>{let t="";for(;e(c[u]);){if("\\"===c[u]){if(++u>=c.length)throw SyntaxError("Unexpected end of input");let e=c[u++],r=l.get(e);if(void 0===r)throw SyntaxError(`Unexpected escaped character: ${e}`);t+=r;continue}if(t+=c[u++],u>=c.length)throw SyntaxError("Unexpected end of input")}return t};e:for(;u<c.length;){let e=r.at(-1)?.type;if(void 0===e||e===n.CloseStatement||e===n.CloseExpression||e===n.Comment){let e="";for(;u<c.length&&!("{"===c[u]&&("%"===c[u+1]||"{"===c[u+1]||"#"===c[u+1]));)e+=c[u++];if(e.length>0){r.push(new o(e,n.Text));continue}}if("{"===c[u]&&"#"===c[u+1]){u+=2;let e="";for(;"#"!==c[u]||"}"!==c[u+1];){if(u+2>=c.length)throw SyntaxError("Missing end of comment tag");e+=c[u++]}r.push(new o(e,n.Comment)),u+=2;continue}m(e=>/\s/.test(e));let t=c[u];if("-"===t||"+"===t){let e=r.at(-1)?.type;if(e===n.Text||void 0===e)throw SyntaxError(`Unexpected character: ${t}`);switch(e){case n.Identifier:case n.NumericLiteral:case n.StringLiteral:case n.CloseParen:case n.CloseSquareBracket:break;default:{++u;let e=m(i);r.push(new o(`${t}${e}`,e.length>0?n.NumericLiteral:n.UnaryOperator));continue}}}for(let[e,t]of a)if(("}}"!==e||!(d>0))&&c.slice(u,u+e.length)===e){r.push(new o(e,t)),t===n.OpenExpression?d=0:t===n.OpenCurlyBracket?++d:t===n.CloseCurlyBracket&&--d,u+=e.length;continue e}if("'"===t||'"'===t){++u;let e=m(e=>e!==t);r.push(new o(e,n.StringLiteral)),++u;continue}if(i(t)){let e=m(i);if("."===c[u]&&i(c[u+1])){++u;let t=m(i);e=`${e}.${t}`}r.push(new o(e,n.NumericLiteral));continue}if(s(t)){let e=m(s);r.push(new o(e,n.Identifier));continue}throw SyntaxError(`Unexpected character: ${t}`)}return r}var u=class{type="Statement"},d=class extends u{constructor(e){super(),this.body=e}type="Program"},m=class extends u{constructor(e,t,r){super(),this.test=e,this.body=t,this.alternate=r}type="If"},p=class extends u{constructor(e,t,r,n){super(),this.loopvar=e,this.iterable=t,this.body=r,this.defaultBlock=n}type="For"},_=class extends u{type="Break"},h=class extends u{type="Continue"},f=class extends u{constructor(e,t,r){super(),this.assignee=e,this.value=t,this.body=r}type="Set"},g=class extends u{constructor(e,t,r){super(),this.name=e,this.args=t,this.body=r}type="Macro"},M=class extends u{constructor(e){super(),this.value=e}type="Comment"},w=class extends u{type="Expression"},T=class extends w{constructor(e,t,r){super(),this.object=e,this.property=t,this.computed=r}type="MemberExpression"},x=class extends w{constructor(e,t){super(),this.callee=e,this.args=t}type="CallExpression"},P=class extends w{constructor(e){super(),this.value=e}type="Identifier"},b=class extends w{constructor(e){super(),this.value=e}type="Literal"},F=class extends b{type="IntegerLiteral"},k=class extends b{type="FloatLiteral"},y=class extends b{type="StringLiteral"},v=class extends b{type="ArrayLiteral"},C=class extends b{type="TupleLiteral"},S=class extends b{type="ObjectLiteral"},E=class extends w{constructor(e,t,r){super(),this.operator=e,this.left=t,this.right=r}type="BinaryExpression"},A=class extends w{constructor(e,t){super(),this.operand=e,this.filter=t}type="FilterExpression"},L=class extends u{constructor(e,t){super(),this.filter=e,this.body=t}type="FilterStatement"},I=class extends w{constructor(e,t){super(),this.lhs=e,this.test=t}type="SelectExpression"},D=class extends w{constructor(e,t,r){super(),this.operand=e,this.negate=t,this.test=r}type="TestExpression"},z=class extends w{constructor(e,t){super(),this.operator=e,this.argument=t}type="UnaryExpression"},j=class extends w{constructor(e,t,r){super(),this.start=e,this.stop=t,this.step=r}type="SliceExpression"},V=class extends w{constructor(e,t){super(),this.key=e,this.value=t}type="KeywordArgumentExpression"},O=class extends w{constructor(e){super(),this.argument=e}type="SpreadExpression"},N=class extends u{constructor(e,t,r){super(),this.call=e,this.callerArgs=t,this.body=r}type="CallStatement"},B=class extends w{constructor(e,t,r){super(),this.condition=e,this.trueExpr=t,this.falseExpr=r}type="Ternary"};function G(e){let t=new d([]),r=0;function s(t,n){let o=e[r++];if(!o||o.type!==t)throw Error(`Parser Error: ${n}. ${o.type} !== ${t}.`);return o}function i(e){if(!c(e))throw SyntaxError(`Expected ${e}`);++r}function a(...t){return r+t.length<=e.length&&t.every((t,n)=>t===e[r+n].type)}function l(...t){return e[r]?.type===n.OpenStatement&&e[r+1]?.type===n.Identifier&&t.includes(e[r+1]?.value)}function c(...t){return r+t.length<=e.length&&t.every((t,n)=>"Identifier"===e[r+n].type&&t===e[r+n].value)}function u(e=!1){let t=e?H:w,o=[t()],s=a(n.Comma);for(;s&&(++r,o.push(t()),a(n.Comma)););return s?new C(o):o[0]}function w(){return function e(){let t=b();if(c("if")){++r;let n=b();return c("else")?(++r,new B(n,t,e())):new I(t,n)}return t}()}function b(){let t=G();for(;c("or");){let n=e[r];++r,t=new E(n,t,G())}return t}function G(){let t=R();for(;c("and");){let n=e[r];++r,t=new E(n,t,R())}return t}function R(){let t;for(;c("not");){let n=e[r];++r,t=new z(n,R())}return t??function(){let t=q();for(;;){let s;if(c("not","in"))s=new o("not in",n.Identifier),r+=2;else if(c("in"))s=e[r++];else if(a(n.ComparisonBinaryOperator))s=e[r++];else break;t=new E(s,t,q())}return t}()}function q(){let t=Q();for(;a(n.AdditiveBinaryOperator);){let n=e[r];++r,t=new E(n,t,Q())}return t}function $(e){let t=new x(e,W());return t=U(t),a(n.OpenParen)&&(t=$(t)),t}function W(){s(n.OpenParen,"Expected opening parenthesis for arguments list");let t=function(){let t=[];for(;!a(n.CloseParen);){let o;if(e[r].type===n.MultiplicativeBinaryOperator&&"*"===e[r].value)++r,o=new O(w());else if(o=w(),a(n.Equals)){if(++r,!(o instanceof P))throw SyntaxError("Expected identifier for keyword argument");o=new V(o,w())}t.push(o),a(n.Comma)&&++r}return t}();return s(n.CloseParen,"Expected closing parenthesis for arguments list"),t}function U(t){for(;a(n.Dot)||a(n.OpenSquareBracket);){let o;let i=e[r];++r;let l=i.type===n.OpenSquareBracket;if(l)o=function(){let e=[],t=!1;for(;!a(n.CloseSquareBracket);)a(n.Colon)?(e.push(void 0),++r,t=!0):(e.push(w()),a(n.Colon)&&(++r,t=!0));if(0===e.length)throw SyntaxError("Expected at least one argument for member/slice expression");if(t){if(e.length>3)throw SyntaxError("Expected 0-3 arguments for slice expression");return new j(...e)}return e[0]}(),s(n.CloseSquareBracket,"Expected closing square bracket");else if("Identifier"!==(o=H()).type)throw SyntaxError("Expected identifier following dot operator");t=new T(t,o,l)}return t}function Q(){let t=X();for(;a(n.MultiplicativeBinaryOperator);)t=new E(e[r++],t,X());return t}function X(){let e=function(){let e=function(){let e=U(H());return a(n.OpenParen)?$(e):e}();for(;a(n.Pipe);){++r;let t=H();if(!(t instanceof P))throw SyntaxError("Expected identifier for the filter");a(n.OpenParen)&&(t=$(t)),e=new A(e,t)}return e}();for(;c("is");){++r;let t=c("not");t&&++r;let n=H();if(!(n instanceof P))throw SyntaxError("Expected identifier for the test");e=new D(e,t,n)}return e}function H(){let t=e[r++];switch(t.type){case n.NumericLiteral:{let e=t.value;return e.includes(".")?new k(Number(e)):new F(Number(e))}case n.StringLiteral:{let o=t.value;for(;a(n.StringLiteral);)o+=e[r++].value;return new y(o)}case n.Identifier:return new P(t.value);case n.OpenParen:{let e=u();return s(n.CloseParen,"Expected closing parenthesis, got ${tokens[current].type} instead."),e}case n.OpenSquareBracket:{let e=[];for(;!a(n.CloseSquareBracket);)e.push(w()),a(n.Comma)&&++r;return++r,new v(e)}case n.OpenCurlyBracket:{let e=new Map;for(;!a(n.CloseCurlyBracket);){let t=w();s(n.Colon,"Expected colon between key and value in object literal");let o=w();e.set(t,o),a(n.Comma)&&++r}return++r,new S(e)}default:throw SyntaxError(`Unexpected token: ${t.type}`)}}for(;r<e.length;)t.body.push(function t(){switch(e[r].type){case n.Comment:return new M(e[r++].value);case n.Text:return new y(s(n.Text,"Expected text token").value);case n.OpenStatement:return function(){let o;if(s(n.OpenStatement,"Expected opening statement token"),e[r].type!==n.Identifier)throw SyntaxError(`Unknown statement, got ${e[r].type}`);let d=e[r].value;switch(d){case"set":++r,o=function(){let e=u(),o=null,c=[];if(a(n.Equals))++r,o=u();else{for(s(n.CloseStatement,"Expected %} token");!l("endset");)c.push(t());s(n.OpenStatement,"Expected {% token"),i("endset")}return s(n.CloseStatement,"Expected closing statement token"),new f(e,o,c)}();break;case"if":++r,o=function e(){let o=w();s(n.CloseStatement,"Expected closing statement token");let i=[],a=[];for(;!l("elif","else","endif");)i.push(t());if(l("elif")){++r,++r;let t=e();a.push(t)}else if(l("else"))for(++r,++r,s(n.CloseStatement,"Expected closing statement token");!l("endif");)a.push(t());return new m(o,i,a)}(),s(n.OpenStatement,"Expected {% token"),i("endif"),s(n.CloseStatement,"Expected %} token");break;case"macro":++r,o=function(){let e=H();if("Identifier"!==e.type)throw SyntaxError("Expected identifier following macro statement");let r=W();s(n.CloseStatement,"Expected closing statement token");let o=[];for(;!l("endmacro");)o.push(t());return new g(e,r,o)}(),s(n.OpenStatement,"Expected {% token"),i("endmacro"),s(n.CloseStatement,"Expected %} token");break;case"for":++r,o=function(){let e=u(!0);if(!(e instanceof P||e instanceof C))throw SyntaxError(`Expected identifier/tuple for the loop variable, got ${e.type} instead`);if(!c("in"))throw SyntaxError("Expected `in` keyword following loop variable");++r;let o=w();s(n.CloseStatement,"Expected closing statement token");let i=[];for(;!l("endfor","else");)i.push(t());let a=[];if(l("else"))for(++r,++r,s(n.CloseStatement,"Expected closing statement token");!l("endfor");)a.push(t());return new p(e,o,i,a)}(),s(n.OpenStatement,"Expected {% token"),i("endfor"),s(n.CloseStatement,"Expected %} token");break;case"call":{++r;let e=null;a(n.OpenParen)&&(e=W());let c=H();if("Identifier"!==c.type)throw SyntaxError("Expected identifier following call statement");let u=W();s(n.CloseStatement,"Expected closing statement token");let d=[];for(;!l("endcall");)d.push(t());s(n.OpenStatement,"Expected '{%'"),i("endcall"),s(n.CloseStatement,"Expected closing statement token"),o=new N(new x(c,u),e,d);break}case"break":++r,s(n.CloseStatement,"Expected closing statement token"),o=new _;break;case"continue":++r,s(n.CloseStatement,"Expected closing statement token"),o=new h;break;case"filter":{++r;let e=H();e instanceof P&&a(n.OpenParen)&&(e=$(e)),s(n.CloseStatement,"Expected closing statement token");let c=[];for(;!l("endfilter");)c.push(t());s(n.OpenStatement,"Expected '{%'"),i("endfilter"),s(n.CloseStatement,"Expected '%}'"),o=new L(e,c);break}default:throw SyntaxError(`Unknown statement type: ${d}`)}return o}();case n.OpenExpression:return function(){s(n.OpenExpression,"Expected opening expression token");let e=w();return s(n.CloseExpression,"Expected closing expression token"),e}();default:throw SyntaxError(`Unexpected token type: ${e[r].type}`)}}());return t}function R(e,t,r=1){void 0===t&&(t=e,e=0);let n=[];for(let o=e;o<t;o+=r)n.push(o);return n}function q(e,t,r,n=1){let o=Math.sign(n);o>=0?(t=(t??=0)<0?Math.max(e.length+t,0):Math.min(t,e.length),r=(r??=e.length)<0?Math.max(e.length+r,0):Math.min(r,e.length)):(t=(t??=e.length-1)<0?Math.max(e.length+t,-1):Math.min(t,e.length-1),r=(r??=-1)<-1?Math.max(e.length+r,-1):Math.min(r,e.length-1));let s=[];for(let i=t;o*i<o*r;i+=n)s.push(e[i]);return s}function $(e){return function(e,t){let r=new Intl.DateTimeFormat(void 0,{month:"long"}),n=new Intl.DateTimeFormat(void 0,{month:"short"}),o=e=>e<10?"0"+e:e.toString();return t.replace(/%[YmdbBHM%]/g,t=>{switch(t){case"%Y":return e.getFullYear().toString();case"%m":return o(e.getMonth()+1);case"%d":return o(e.getDate());case"%b":return n.format(e);case"%B":return r.format(e);case"%H":return o(e.getHours());case"%M":return o(e.getMinutes());case"%%":return"%";default:return t}})}(new Date,e)}var W=class extends Error{},U=class extends Error{},Q=class{type="RuntimeValue";value;builtins=new Map;constructor(e){this.value=e}__bool__(){return new Y(!!this.value)}toString(){return String(this.value)}},X=class extends Q{type="IntegerValue"},H=class extends Q{type="FloatValue";toString(){return this.value%1==0?this.value.toFixed(1):this.value.toString()}},J=class extends Q{type="StringValue";builtins=new Map([["upper",new er(()=>new J(this.value.toUpperCase()))],["lower",new er(()=>new J(this.value.toLowerCase()))],["strip",new er(()=>new J(this.value.trim()))],["title",new er(()=>new J(this.value.replace(/\b\w/g,e=>e.toUpperCase())))],["capitalize",new er(()=>new J(this.value.charAt(0).toUpperCase()+this.value.slice(1)))],["length",new X(this.value.length)],["rstrip",new er(()=>new J(this.value.trimEnd()))],["lstrip",new er(()=>new J(this.value.trimStart()))],["startswith",new er(e=>{if(0===e.length)throw Error("startswith() requires at least one argument");let t=e[0];if(t instanceof J)return new Y(this.value.startsWith(t.value));if(t instanceof ee){for(let e of t.value){if(!(e instanceof J))throw Error("startswith() tuple elements must be strings");if(this.value.startsWith(e.value))return new Y(!0)}return new Y(!1)}throw Error("startswith() argument must be a string or tuple of strings")})],["endswith",new er(e=>{if(0===e.length)throw Error("endswith() requires at least one argument");let t=e[0];if(t instanceof J)return new Y(this.value.endsWith(t.value));if(t instanceof ee){for(let e of t.value){if(!(e instanceof J))throw Error("endswith() tuple elements must be strings");if(this.value.endsWith(e.value))return new Y(!0)}return new Y(!1)}throw Error("endswith() argument must be a string or tuple of strings")})],["split",new er(e=>{let t=e[0]??new en;if(!(t instanceof J||t instanceof en))throw Error("sep argument must be a string or null");let r=e[1]??new X(-1);if(!(r instanceof X))throw Error("maxsplit argument must be a number");let n=[];if(t instanceof en){let e=this.value.trimStart();for(let{0:t,index:o}of e.matchAll(/\S+/g)){if(-1!==r.value&&n.length>=r.value&&void 0!==o){n.push(t+e.slice(o+t.length));break}n.push(t)}}else{if(""===t.value)throw Error("empty separator");n=this.value.split(t.value),-1!==r.value&&n.length>r.value&&n.push(n.splice(r.value).join(t.value))}return new ee(n.map(e=>new J(e)))})],["replace",new er(e=>{let t;if(e.length<2)throw Error("replace() requires at least two arguments");let r=e[0],n=e[1];if(!(r instanceof J&&n instanceof J))throw Error("replace() arguments must be strings");if(!((t=e.length>2?"KeywordArgumentsValue"===e[2].type?e[2].value.get("count")??new en:e[2]:new en)instanceof X||t instanceof en))throw Error("replace() count argument must be a number or null");return new J(function(e,t,r,n){if(0===n)return e;let o=null==n||n<0?1/0:n,s=0===t.length?RegExp("(?=)","gu"):RegExp(t.replace(/[.*+?^${}()|[\]\\]/g,"\\$&"),"gu");return e.replaceAll(s,e=>o>0?(--o,r):e)}(this.value,r.value,n.value,t.value))})]])},Y=class extends Q{type="BooleanValue"},K=class extends Q{type="ObjectValue";__bool__(){return new Y(this.value.size>0)}builtins=new Map([["get",new er(([e,t])=>{if(!(e instanceof J))throw Error(`Object key must be a string: got ${e.type}`);return this.value.get(e.value)??t??new en})],["items",new er(()=>this.items())],["keys",new er(()=>this.keys())],["values",new er(()=>this.values())]]);items(){return new ee(Array.from(this.value.entries()).map(([e,t])=>new ee([new J(e),t])))}keys(){return new ee(Array.from(this.value.keys()).map(e=>new J(e)))}values(){return new ee(Array.from(this.value.values()))}},Z=class extends K{type="KeywordArgumentsValue"},ee=class extends Q{type="ArrayValue";builtins=new Map([["length",new X(this.value.length)]]);__bool__(){return new Y(this.value.length>0)}},et=class extends ee{type="TupleValue"},er=class extends Q{type="FunctionValue"},en=class extends Q{type="NullValue"},eo=class extends Q{type="UndefinedValue"},es=class{constructor(e){this.parent=e}variables=new Map([["namespace",new er(e=>{if(0===e.length)return new K(new Map);if(1!==e.length||!(e[0]instanceof K))throw Error("`namespace` expects either zero arguments or a single object argument");return e[0]})]]);tests=new Map([["boolean",e=>"BooleanValue"===e.type],["callable",e=>e instanceof er],["odd",e=>{if(!(e instanceof X))throw Error(`cannot odd on ${e.type}`);return e.value%2!=0}],["even",e=>{if(!(e instanceof X))throw Error(`cannot even on ${e.type}`);return e.value%2==0}],["false",e=>"BooleanValue"===e.type&&!e.value],["true",e=>"BooleanValue"===e.type&&e.value],["none",e=>"NullValue"===e.type],["string",e=>"StringValue"===e.type],["number",e=>e instanceof X||e instanceof H],["integer",e=>e instanceof X],["iterable",e=>"ArrayValue"===e.type||"StringValue"===e.type],["mapping",e=>"ObjectValue"===e.type],["lower",e=>{let t=e.value;return"StringValue"===e.type&&t===t.toLowerCase()}],["upper",e=>{let t=e.value;return"StringValue"===e.type&&t===t.toUpperCase()}],["none",e=>"NullValue"===e.type],["defined",e=>"UndefinedValue"!==e.type],["undefined",e=>"UndefinedValue"===e.type],["equalto",(e,t)=>e.value===t.value],["eq",(e,t)=>e.value===t.value]]);set(e,t){return this.declareVariable(e,function e(t){switch(typeof t){case"number":return Number.isInteger(t)?new X(t):new H(t);case"string":return new J(t);case"boolean":return new Y(t);case"undefined":return new eo;case"object":if(null===t)return new en;if(Array.isArray(t))return new ee(t.map(e));return new K(new Map(Object.entries(t).map(([t,r])=>[t,e(r)])));case"function":return new er((r,n)=>e(t(...r.map(e=>e.value))??null));default:throw Error(`Cannot convert to runtime value: ${t}`)}}(t))}declareVariable(e,t){if(this.variables.has(e))throw SyntaxError(`Variable already declared: ${e}`);return this.variables.set(e,t),t}setVariable(e,t){return this.variables.set(e,t),t}resolve(e){if(this.variables.has(e))return this;if(this.parent)return this.parent.resolve(e);throw Error(`Unknown variable: ${e}`)}lookupVariable(e){try{return this.resolve(e).variables.get(e)??new eo}catch{return new eo}}},ei=class{global;constructor(e){this.global=e??new es}run(e){return this.evaluate(e,this.global)}evaluateBinaryExpression(e,t){let r=this.evaluate(e.left,t);switch(e.operator.value){case"and":return r.__bool__().value?this.evaluate(e.right,t):r;case"or":return r.__bool__().value?r:this.evaluate(e.right,t)}let n=this.evaluate(e.right,t);switch(e.operator.value){case"==":return new Y(r.value==n.value);case"!=":return new Y(r.value!=n.value)}if(r instanceof eo||n instanceof eo){if(n instanceof eo&&["in","not in"].includes(e.operator.value))return new Y("not in"===e.operator.value);throw Error(`Cannot perform operation ${e.operator.value} on undefined values`)}if(r instanceof en||n instanceof en)throw Error("Cannot perform operation on null values");if("~"===e.operator.value)return new J(r.value.toString()+n.value.toString());if((r instanceof X||r instanceof H)&&(n instanceof X||n instanceof H)){let t=r.value,o=n.value;switch(e.operator.value){case"+":case"-":case"*":{let s="+"===e.operator.value?t+o:"-"===e.operator.value?t-o:t*o;return r instanceof H||n instanceof H?new H(s):new X(s)}case"/":return new H(t/o);case"%":{let e=t%o;return r instanceof H||n instanceof H?new H(e):new X(e)}case"<":return new Y(t<o);case">":return new Y(t>o);case">=":return new Y(t>=o);case"<=":return new Y(t<=o)}}else if(r instanceof ee&&n instanceof ee){if("+"===e.operator.value)return new ee(r.value.concat(n.value))}else if(n instanceof ee){let t=void 0!==n.value.find(e=>e.value===r.value);switch(e.operator.value){case"in":return new Y(t);case"not in":return new Y(!t)}}if((r instanceof J||n instanceof J)&&"+"===e.operator.value)return new J(r.value.toString()+n.value.toString());if(r instanceof J&&n instanceof J)switch(e.operator.value){case"in":return new Y(n.value.includes(r.value));case"not in":return new Y(!n.value.includes(r.value))}if(r instanceof J&&n instanceof K)switch(e.operator.value){case"in":return new Y(n.value.has(r.value));case"not in":return new Y(!n.value.has(r.value))}throw SyntaxError(`Unknown operator "${e.operator.value}" between ${r.type} and ${n.type}`)}evaluateArguments(e,t){let r=[],n=new Map;for(let o of e)if("SpreadExpression"===o.type){let e=this.evaluate(o.argument,t);if(!(e instanceof ee))throw Error(`Cannot unpack non-iterable type: ${e.type}`);for(let t of e.value)r.push(t)}else if("KeywordArgumentExpression"===o.type)n.set(o.key.value,this.evaluate(o.value,t));else{if(n.size>0)throw Error("Positional arguments must come before keyword arguments");r.push(this.evaluate(o,t))}return[r,n]}applyFilter(e,t,r){if("Identifier"===t.type){if("tojson"===t.value)return new J(ea(e));if(e instanceof ee)switch(t.value){case"list":return e;case"first":return e.value[0];case"last":return e.value[e.value.length-1];case"length":return new X(e.value.length);case"reverse":return new ee(e.value.reverse());case"sort":return new ee(e.value.sort((e,t)=>{if(e.type!==t.type)throw Error(`Cannot compare different types: ${e.type} and ${t.type}`);switch(e.type){case"IntegerValue":case"FloatValue":return e.value-t.value;case"StringValue":return e.value.localeCompare(t.value);default:throw Error(`Cannot compare type: ${e.type}`)}}));case"join":return new J(e.value.map(e=>e.value).join(""));case"string":return new J(ea(e));case"unique":{let t=new Set,r=[];for(let n of e.value)t.has(n.value)||(t.add(n.value),r.push(n));return new ee(r)}default:throw Error(`Unknown ArrayValue filter: ${t.value}`)}else if(e instanceof J)switch(t.value){case"length":case"upper":case"lower":case"title":case"capitalize":{let n=e.builtins.get(t.value);if(n instanceof er)return n.value([],r);if(n instanceof X)return n;throw Error(`Unknown StringValue filter: ${t.value}`)}case"trim":return new J(e.value.trim());case"indent":return new J(e.value.split("\n").map((e,t)=>0===t||0===e.length?e:"    "+e).join("\n"));case"join":case"string":return e;case"int":{let t=parseInt(e.value,10);return new X(isNaN(t)?0:t)}case"float":{let t=parseFloat(e.value);return new H(isNaN(t)?0:t)}default:throw Error(`Unknown StringValue filter: ${t.value}`)}else if(e instanceof X||e instanceof H)switch(t.value){case"abs":return e instanceof X?new X(Math.abs(e.value)):new H(Math.abs(e.value));case"int":return new X(Math.floor(e.value));case"float":return new H(e.value);default:throw Error(`Unknown NumericValue filter: ${t.value}`)}else if(e instanceof K)switch(t.value){case"items":return new ee(Array.from(e.value.entries()).map(([e,t])=>new ee([new J(e),t])));case"length":return new X(e.value.size);default:throw Error(`Unknown ObjectValue filter: ${t.value}`)}else if(e instanceof Y)switch(t.value){case"bool":return new Y(e.value);case"int":return new X(e.value?1:0);case"float":return new H(e.value?1:0);case"string":return new J(e.value?"true":"false");default:throw Error(`Unknown BooleanValue filter: ${t.value}`)}throw Error(`Cannot apply filter "${t.value}" to type: ${e.type}`)}if("CallExpression"===t.type){if("Identifier"!==t.callee.type)throw Error(`Unknown filter: ${t.callee.type}`);let n=t.callee.value;if("tojson"===n){let[,n]=this.evaluateArguments(t.args,r),o=n.get("indent")??new en;if(!(o instanceof X||o instanceof en))throw Error("If set, indent must be a number");return new J(ea(e,o.value))}if("join"===n){let o;if(e instanceof J)o=Array.from(e.value);else if(e instanceof ee)o=e.value.map(e=>e.value);else throw Error(`Cannot apply filter "${n}" to type: ${e.type}`);let[s,i]=this.evaluateArguments(t.args,r),a=s.at(0)??i.get("separator")??new J("");if(!(a instanceof J))throw Error("separator must be a string");return new J(o.join(a.value))}if("int"===n||"float"===n){let[o,s]=this.evaluateArguments(t.args,r),i=o.at(0)??s.get("default")??("int"===n?new X(0):new H(0));if(e instanceof J){let t="int"===n?parseInt(e.value,10):parseFloat(e.value);return isNaN(t)?i:"int"===n?new X(t):new H(t)}if(e instanceof X||e instanceof H)return e;if(e instanceof Y)return"int"===n?new X(e.value?1:0):new H(e.value?1:0);throw Error(`Cannot apply filter "${n}" to type: ${e.type}`)}if("default"===n){let[n,o]=this.evaluateArguments(t.args,r),s=n[0]??new J(""),i=n[1]??o.get("boolean")??new Y(!1);if(!(i instanceof Y))throw Error("`default` filter flag must be a boolean");return e instanceof eo||i.value&&!e.__bool__().value?s:e}if(e instanceof ee){switch(n){case"selectattr":case"rejectattr":{let o;let s="selectattr"===n;if(e.value.some(e=>!(e instanceof K)))throw Error(`\`${n}\` can only be applied to array of objects`);if(t.args.some(e=>"StringLiteral"!==e.type))throw Error(`arguments of \`${n}\` must be strings`);let[i,a,l]=t.args.map(e=>this.evaluate(e,r));if(a){let e=r.tests.get(a.value);if(!e)throw Error(`Unknown test: ${a.value}`);o=e}else o=(...e)=>e[0].__bool__().value;return new ee(e.value.filter(e=>{let t=e.value.get(i.value),r=!!t&&o(t,l);return s?r:!r}))}case"map":{let[,n]=this.evaluateArguments(t.args,r);if(n.has("attribute")){let t=n.get("attribute");if(!(t instanceof J))throw Error("attribute must be a string");let r=n.get("default");return new ee(e.value.map(e=>{if(!(e instanceof K))throw Error("items in map must be an object");return e.value.get(t.value)??r??new eo}))}throw Error("`map` expressions without `attribute` set are not currently supported.")}}throw Error(`Unknown ArrayValue filter: ${n}`)}if(e instanceof J){switch(n){case"indent":{let[n,o]=this.evaluateArguments(t.args,r),s=n.at(0)??o.get("width")??new X(4);if(!(s instanceof X))throw Error("width must be a number");let i=n.at(1)??o.get("first")??new Y(!1),a=n.at(2)??o.get("blank")??new Y(!1),l=e.value.split("\n"),c=" ".repeat(s.value);return new J(l.map((e,t)=>(i.value||0!==t)&&(a.value||0!==e.length)?c+e:e).join("\n"))}case"replace":{let n=e.builtins.get("replace");if(!(n instanceof er))throw Error("replace filter not available");let[o,s]=this.evaluateArguments(t.args,r);return n.value([...o,new Z(s)],r)}}throw Error(`Unknown StringValue filter: ${n}`)}throw Error(`Cannot apply filter "${n}" to type: ${e.type}`)}throw Error(`Unknown filter: ${t.type}`)}evaluateFilterExpression(e,t){let r=this.evaluate(e.operand,t);return this.applyFilter(r,e.filter,t)}evaluateTestExpression(e,t){let r=this.evaluate(e.operand,t),n=t.tests.get(e.test.value);if(!n)throw Error(`Unknown test: ${e.test.value}`);let o=n(r);return new Y(e.negate?!o:o)}evaluateSelectExpression(e,t){return this.evaluate(e.test,t).__bool__().value?this.evaluate(e.lhs,t):new eo}evaluateUnaryExpression(e,t){let r=this.evaluate(e.argument,t);if("not"===e.operator.value)return new Y(!r.value);throw SyntaxError(`Unknown operator: ${e.operator.value}`)}evaluateTernaryExpression(e,t){return this.evaluate(e.condition,t).__bool__().value?this.evaluate(e.trueExpr,t):this.evaluate(e.falseExpr,t)}evalProgram(e,t){return this.evaluateBlock(e.body,t)}evaluateBlock(e,t){let r="";for(let n of e){let e=this.evaluate(n,t);"NullValue"!==e.type&&"UndefinedValue"!==e.type&&(r+=e.toString())}return new J(r)}evaluateIdentifier(e,t){return t.lookupVariable(e.value)}evaluateCallExpression(e,t){let[r,n]=this.evaluateArguments(e.args,t);n.size>0&&r.push(new Z(n));let o=this.evaluate(e.callee,t);if("FunctionValue"!==o.type)throw Error(`Cannot call something that is not a function: got ${o.type}`);return o.value(r,t)}evaluateSliceExpression(e,t,r){if(!(e instanceof ee||e instanceof J))throw Error("Slice object must be an array or string");let n=this.evaluate(t.start,r),o=this.evaluate(t.stop,r),s=this.evaluate(t.step,r);if(!(n instanceof X||n instanceof eo))throw Error("Slice start must be numeric or undefined");if(!(o instanceof X||o instanceof eo))throw Error("Slice stop must be numeric or undefined");if(!(s instanceof X||s instanceof eo))throw Error("Slice step must be numeric or undefined");return e instanceof ee?new ee(q(e.value,n.value,o.value,s.value)):new J(q(Array.from(e.value),n.value,o.value,s.value).join(""))}evaluateMemberExpression(e,t){let r,n;let o=this.evaluate(e.object,t);if(e.computed){if("SliceExpression"===e.property.type)return this.evaluateSliceExpression(o,e.property,t);r=this.evaluate(e.property,t)}else r=new J(e.property.value);if(o instanceof K){if(!(r instanceof J))throw Error(`Cannot access property with non-string: got ${r.type}`);n=o.value.get(r.value)??o.builtins.get(r.value)}else if(o instanceof ee||o instanceof J){if(r instanceof X)n=o.value.at(r.value),o instanceof J&&(n=new J(o.value.at(r.value)));else if(r instanceof J)n=o.builtins.get(r.value);else throw Error(`Cannot access property with non-string/non-number: got ${r.type}`)}else{if(!(r instanceof J))throw Error(`Cannot access property with non-string: got ${r.type}`);n=o.builtins.get(r.value)}return n instanceof Q?n:new eo}evaluateSet(e,t){let r=e.value?this.evaluate(e.value,t):this.evaluateBlock(e.body,t);if("Identifier"===e.assignee.type){let n=e.assignee.value;t.setVariable(n,r)}else if("TupleLiteral"===e.assignee.type){let n=e.assignee;if(!(r instanceof ee))throw Error(`Cannot unpack non-iterable type in set: ${r.type}`);let o=r.value;if(o.length!==n.value.length)throw Error(`Too ${n.value.length>o.length?"few":"many"} items to unpack in set`);for(let e=0;e<n.value.length;++e){let r=n.value[e];if("Identifier"!==r.type)throw Error(`Cannot unpack to non-identifier in set: ${r.type}`);t.setVariable(r.value,o[e])}}else if("MemberExpression"===e.assignee.type){let n=e.assignee,o=this.evaluate(n.object,t);if(!(o instanceof K))throw Error("Cannot assign to member of non-object");if("Identifier"!==n.property.type)throw Error("Cannot assign to member with non-identifier property");o.value.set(n.property.value,r)}else throw Error(`Invalid LHS inside assignment expression: ${JSON.stringify(e.assignee)}`);return new en}evaluateIf(e,t){let r=this.evaluate(e.test,t);return this.evaluateBlock(r.__bool__().value?e.body:e.alternate,t)}evaluateFor(e,t){let r,n;let o=new es(t);if("SelectExpression"===e.iterable.type){let t=e.iterable;n=this.evaluate(t.lhs,o),r=t.test}else n=this.evaluate(e.iterable,o);if(!(n instanceof ee||n instanceof K))throw Error(`Expected iterable or object type in for loop: got ${n.type}`);n instanceof K&&(n=n.keys());let s=[],i=[];for(let t=0;t<n.value.length;++t){let a;let l=new es(o),c=n.value[t];if("Identifier"===e.loopvar.type)a=t=>t.setVariable(e.loopvar.value,c);else if("TupleLiteral"===e.loopvar.type){let t=e.loopvar;if("ArrayValue"!==c.type)throw Error(`Cannot unpack non-iterable type: ${c.type}`);if(t.value.length!==c.value.length)throw Error(`Too ${t.value.length>c.value.length?"few":"many"} items to unpack`);a=e=>{for(let r=0;r<t.value.length;++r){if("Identifier"!==t.value[r].type)throw Error(`Cannot unpack non-identifier type: ${t.value[r].type}`);e.setVariable(t.value[r].value,c.value[r])}}}else throw Error(`Invalid loop variable(s): ${e.loopvar.type}`);(!r||(a(l),this.evaluate(r,l).__bool__().value))&&(s.push(c),i.push(a))}let a="",l=!0;for(let t=0;t<s.length;++t){let r=new Map([["index",new X(t+1)],["index0",new X(t)],["revindex",new X(s.length-t)],["revindex0",new X(s.length-t-1)],["first",new Y(0===t)],["last",new Y(t===s.length-1)],["length",new X(s.length)],["previtem",t>0?s[t-1]:new eo],["nextitem",t<s.length-1?s[t+1]:new eo]]);o.setVariable("loop",new K(r)),i[t](o);try{let t=this.evaluateBlock(e.body,o);a+=t.value}catch(e){if(e instanceof U)continue;if(e instanceof W)break;throw e}l=!1}return l&&(a+=this.evaluateBlock(e.defaultBlock,o).value),new J(a)}evaluateMacro(e,t){return t.setVariable(e.name.value,new er((t,r)=>{let n;let o=new es(r);t=t.slice(),t.at(-1)?.type==="KeywordArgumentsValue"&&(n=t.pop());for(let r=0;r<e.args.length;++r){let s=e.args[r],i=t[r];if("Identifier"===s.type){if(!i)throw Error(`Missing positional argument: ${s.value}`);o.setVariable(s.value,i)}else if("KeywordArgumentExpression"===s.type){let e=i??n?.value.get(s.key.value)??this.evaluate(s.value,o);o.setVariable(s.key.value,e)}else throw Error(`Unknown argument type: ${s.type}`)}return this.evaluateBlock(e.body,o)})),new en}evaluateCallStatement(e,t){let r=new er((t,r)=>{let n=new es(r);if(e.callerArgs)for(let r=0;r<e.callerArgs.length;++r){let o=e.callerArgs[r];if("Identifier"!==o.type)throw Error(`Caller parameter must be an identifier, got ${o.type}`);n.setVariable(o.value,t[r]??new eo)}return this.evaluateBlock(e.body,n)}),[n,o]=this.evaluateArguments(e.call.args,t);n.push(new Z(o));let s=this.evaluate(e.call.callee,t);if("FunctionValue"!==s.type)throw Error(`Cannot call something that is not a function: got ${s.type}`);let i=new es(t);return i.setVariable("caller",r),s.value(n,i)}evaluateFilterStatement(e,t){let r=this.evaluateBlock(e.body,t);return this.applyFilter(r,e.filter,t)}evaluate(e,t){if(!e)return new eo;switch(e.type){case"Program":return this.evalProgram(e,t);case"Set":return this.evaluateSet(e,t);case"If":return this.evaluateIf(e,t);case"For":return this.evaluateFor(e,t);case"Macro":return this.evaluateMacro(e,t);case"CallStatement":return this.evaluateCallStatement(e,t);case"Break":throw new W;case"Continue":throw new U;case"IntegerLiteral":return new X(e.value);case"FloatLiteral":return new H(e.value);case"StringLiteral":return new J(e.value);case"ArrayLiteral":return new ee(e.value.map(e=>this.evaluate(e,t)));case"TupleLiteral":return new et(e.value.map(e=>this.evaluate(e,t)));case"ObjectLiteral":{let r=new Map;for(let[n,o]of e.value){let e=this.evaluate(n,t);if(!(e instanceof J))throw Error(`Object keys must be strings: got ${e.type}`);r.set(e.value,this.evaluate(o,t))}return new K(r)}case"Identifier":return this.evaluateIdentifier(e,t);case"CallExpression":return this.evaluateCallExpression(e,t);case"MemberExpression":return this.evaluateMemberExpression(e,t);case"UnaryExpression":return this.evaluateUnaryExpression(e,t);case"BinaryExpression":return this.evaluateBinaryExpression(e,t);case"FilterExpression":return this.evaluateFilterExpression(e,t);case"FilterStatement":return this.evaluateFilterStatement(e,t);case"TestExpression":return this.evaluateTestExpression(e,t);case"SelectExpression":return this.evaluateSelectExpression(e,t);case"Ternary":return this.evaluateTernaryExpression(e,t);case"Comment":return new en;default:throw SyntaxError(`Unknown node type: ${e.type}`)}}};function ea(e,t,r){let n=r??0;switch(e.type){case"NullValue":case"UndefinedValue":return"null";case"IntegerValue":case"FloatValue":case"StringValue":case"BooleanValue":return JSON.stringify(e.value);case"ArrayValue":case"ObjectValue":{let r=t?" ".repeat(t):"",o="\n"+r.repeat(n),s=o+r;if("ArrayValue"===e.type){let r=e.value.map(e=>ea(e,t,n+1));return t?`[${s}${r.join(`,${s}`)}${o}]`:`[${r.join(", ")}]`}{let r=Array.from(e.value.entries()).map(([e,r])=>{let o=`"${e}": ${ea(r,t,n+1)}`;return t?`${s}${o}`:o});return t?`{${r.join(",")}${o}}`:`{${r.join(", ")}}`}}default:throw Error(`Cannot convert to JSON: ${e.type}`)}}function el(...e){return"{%- "+e.join(" ")+" -%}"}function ec(e,t=-1){switch(e.type){case"SpreadExpression":return`*${ec(e.argument)}`;case"Identifier":return e.value;case"IntegerLiteral":case"FloatLiteral":return`${e.value}`;case"StringLiteral":return JSON.stringify(e.value);case"BinaryExpression":{let r=function(e){switch(e.operator.type){case"MultiplicativeBinaryOperator":return 4;case"AdditiveBinaryOperator":return 3;case"ComparisonBinaryOperator":return 2;case"Identifier":if("and"===e.operator.value)return 1;if("in"===e.operator.value||"not in"===e.operator.value)return 2}return 0}(e),n=ec(e.left,r),o=ec(e.right,r+1),s=`${n} ${e.operator.value} ${o}`;return r<t?`(${s})`:s}case"UnaryExpression":return e.operator.value+("not"===e.operator.value?" ":"")+ec(e.argument,1/0);case"CallExpression":{let t=e.args.map(ec).join(", ");return`${ec(e.callee)}(${t})`}case"MemberExpression":{let t=ec(e.object);["Identifier","MemberExpression","CallExpression","StringLiteral","IntegerLiteral","FloatLiteral","ArrayLiteral","TupleLiteral","ObjectLiteral"].includes(e.object.type)||(t=`(${t})`);let r=ec(e.property);return e.computed||"Identifier"===e.property.type||(r=`(${r})`),e.computed?`${t}[${r}]`:`${t}.${r}`}case"FilterExpression":{let t=ec(e.operand,1/0);if("CallExpression"===e.filter.type)return`${t} | ${ec(e.filter)}`;return`${t} | ${e.filter.value}`}case"SelectExpression":return`${ec(e.lhs)} if ${ec(e.test)}`;case"TestExpression":return`${ec(e.operand)} is${e.negate?" not":""} ${e.test.value}`;case"ArrayLiteral":case"TupleLiteral":{let t=e.value.map(ec),r="ArrayLiteral"===e.type?"[]":"()";return`${r[0]}${t.join(", ")}${r[1]}`}case"ObjectLiteral":{let t=Array.from(e.value.entries()).map(([e,t])=>`${ec(e)}: ${ec(t)}`);return`{${t.join(", ")}}`}case"SliceExpression":{let t=e.start?ec(e.start):"",r=e.stop?ec(e.stop):"",n=e.step?`:${ec(e.step)}`:"";return`${t}:${r}${n}`}case"KeywordArgumentExpression":return`${e.key.value}=${ec(e.value)}`;case"Ternary":{let r=`${ec(e.trueExpr)} if ${ec(e.condition,0)} else ${ec(e.falseExpr)}`;return t>-1?`(${r})`:r}default:throw Error(`Unknown expression type: ${e.type}`)}}var eu=class{parsed;constructor(e){let t=c(e,{lstrip_blocks:!0,trim_blocks:!0});this.parsed=G(t)}render(e){let t=new es;if(t.set("false",!1),t.set("true",!0),t.set("none",null),t.set("raise_exception",e=>{throw Error(e)}),t.set("range",R),t.set("strftime_now",$),t.set("True",!0),t.set("False",!1),t.set("None",null),e)for(let[r,n]of Object.entries(e))t.set(r,n);return new ei(t).run(this.parsed).value}format(e){return function(e,t="	"){let r="number"==typeof t?" ".repeat(t):t;return(function e(t,r,n){return t.map(t=>(function(t,r,n){let o=n.repeat(r);switch(t.type){case"Program":return e(t.body,r,n);case"If":return function(t,r,n){let o=n.repeat(r),s=[],i=t;for(;i;)if(s.push({test:i.test,body:i.body}),1===i.alternate.length&&"If"===i.alternate[0].type)i=i.alternate[0];else break;let a=o+el("if",ec(s[0].test))+"\n"+e(s[0].body,r+1,n);for(let t=1;t<s.length;++t)a+="\n"+o+el("elif",ec(s[t].test))+"\n"+e(s[t].body,r+1,n);return i&&i.alternate.length>0&&(a+="\n"+o+el("else")+"\n"+e(i.alternate,r+1,n)),a+="\n"+o+el("endif")}(t,r,n);case"For":return function(t,r,n){let o=n.repeat(r),s="";if("SelectExpression"===t.iterable.type){let e=t.iterable;s=`${ec(e.lhs)} if ${ec(e.test)}`}else s=ec(t.iterable);let i=o+el("for",ec(t.loopvar),"in",s)+"\n"+e(t.body,r+1,n);return t.defaultBlock.length>0&&(i+="\n"+o+el("else")+"\n"+e(t.defaultBlock,r+1,n)),i+="\n"+o+el("endfor")}(t,r,n);case"Set":return function(t,r,n){let o=n.repeat(r),s=ec(t.assignee),i=t.value?ec(t.value):"",a=o+el("set",`${s}${t.value?" = "+i:""}`);return 0===t.body.length?a:a+"\n"+e(t.body,r+1,n)+"\n"+o+el("endset")}(t,r,n);case"Macro":return function(t,r,n){let o=n.repeat(r),s=t.args.map(ec).join(", ");return o+el("macro",`${t.name.value}(${s})`)+"\n"+e(t.body,r+1,n)+"\n"+o+el("endmacro")}(t,r,n);case"Break":return o+el("break");case"Continue":return o+el("continue");case"CallStatement":return function(t,r,n){let o=n.repeat(r),s=t.callerArgs&&t.callerArgs.length>0?`(${t.callerArgs.map(ec).join(", ")})`:"";return o+el(`call${s}`,ec(t.call))+"\n"+(e(t.body,r+1,n)+"\n")+(o+el("endcall"))}(t,r,n);case"FilterStatement":return function(t,r,n){let o=n.repeat(r);return o+el("filter","Identifier"===t.filter.type?t.filter.value:ec(t.filter))+"\n"+(e(t.body,r+1,n)+"\n")+(o+el("endfilter"))}(t,r,n);case"Comment":return o+"{# "+t.value+" #}";default:return o+"{{- "+ec(t)+" -}}"}})(t,r,n)).join("\n")})(e.body,0,r).replace(/\n$/,"")}(this.parsed,e?.indent||"	")}}},"./src/backends/onnx.js":/*!******************************!*\
  !*** ./src/backends/onnx.js ***!
  \******************************/(e,t,r)=>{let n,o;r.r(t),r.d(t,{Tensor:()=>c.Tensor,createInferenceSession:()=>f,deviceToExecutionProviders:()=>_,isONNXProxy:()=>w,isONNXTensor:()=>g});var s,i=r(/*! ../env.js */"./src/env.js"),a=r(/*! onnxruntime-node */"?2ce3"),l=r(/*! onnxruntime-web */"onnxruntime-web"),c=r(/*! onnxruntime-common */"onnxruntime-common");let u=Object.freeze({auto:null,gpu:null,cpu:"cpu",wasm:"wasm",webgpu:"webgpu",cuda:"cuda",dml:"dml",webnn:{name:"webnn",deviceType:"cpu"},"webnn-npu":{name:"webnn",deviceType:"npu"},"webnn-gpu":{name:"webnn",deviceType:"gpu"},"webnn-cpu":{name:"webnn",deviceType:"cpu"}}),d=[],m=Symbol.for("onnxruntime");if(m in globalThis)o=globalThis[m];else if(i.apis.IS_NODE_ENV){switch(o=a??(s||(s=r.t(a,2))),E.platform){case"win32":d.push("dml");break;case"linux":"x64"===E.arch&&d.push("cuda")}d.push("cpu"),n=["cpu"]}else o=l,i.apis.IS_WEBNN_AVAILABLE&&d.push("webnn-npu","webnn-gpu","webnn-cpu","webnn"),i.apis.IS_WEBGPU_AVAILABLE&&d.push("webgpu"),d.push("wasm"),n=["wasm"];let p=o.InferenceSession;function _(e=null){if(!e)return n;switch(e){case"auto":return d;case"gpu":return d.filter(e=>["webgpu","cuda","dml","webnn-gpu"].includes(e))}if(d.includes(e))return[u[e]??e];throw Error(`Unsupported device: "${e}". Should be one of: ${d.join(", ")}.`)}let h=null;async function f(e,t,r){h&&await h;let n=p.create(e,t);h??=n;let o=await n;return o.config=r,o}function g(e){return e instanceof o.Tensor}let M=o?.env;function w(){return M?.wasm?.proxy}M?.wasm&&("undefined"!=typeof ServiceWorkerGlobalScope&&self instanceof ServiceWorkerGlobalScope||M.wasm.wasmPaths||(M.wasm.wasmPaths=`https://cdn.jsdelivr.net/npm/@huggingface/transformers@${i.env.version}/dist/`),M.wasm.proxy=!1),M?.webgpu&&(M.webgpu.powerPreference="high-performance"),i.env.backends.onnx=M},"./src/base/feature_extraction_utils.js":/*!**********************************************!*\
  !*** ./src/base/feature_extraction_utils.js ***!
  \**********************************************/(e,t,r)=>{r.r(t),r.d(t,{FeatureExtractor:()=>i,validate_audio_inputs:()=>a});var n=r(/*! ../utils/constants.js */"./src/utils/constants.js"),o=r(/*! ../utils/generic.js */"./src/utils/generic.js"),s=r(/*! ../utils/hub.js */"./src/utils/hub.js");class i extends o.Callable{constructor(e){super(),this.config=e}static async from_pretrained(e,t={}){return new this(await (0,s.getModelJSON)(e,n.FEATURE_EXTRACTOR_NAME,!0,t))}}function a(e,t){if(!(e instanceof Float32Array||e instanceof Float64Array))throw Error(`${t} expects input to be a Float32Array or a Float64Array, but got ${e?.constructor?.name??typeof e} instead. If using the feature extractor directly, remember to use \`read_audio(url, sampling_rate)\` to obtain the raw audio data of the file/url.`)}},"./src/base/image_processors_utils.js":/*!********************************************!*\
  !*** ./src/base/image_processors_utils.js ***!
  \********************************************/(e,t,r)=>{r.r(t),r.d(t,{ImageProcessor:()=>f,center_to_corners_format:()=>d,post_process_instance_segmentation:()=>h,post_process_object_detection:()=>m,post_process_panoptic_segmentation:()=>_,post_process_semantic_segmentation:()=>p});var n=r(/*! ../utils/generic.js */"./src/utils/generic.js"),o=r(/*! ../utils/tensor.js */"./src/utils/tensor.js"),s=r(/*! ../utils/maths.js */"./src/utils/maths.js");r(/*! ../utils/image.js */"./src/utils/image.js");var i=r(/*! ../utils/core.js */"./src/utils/core.js"),a=r(/*! ../utils/hub.js */"./src/utils/hub.js"),l=r(/*! ../utils/constants.js */"./src/utils/constants.js");function c(e,t,r=0,n=null){let o=e/t,i=(0,s.bankers_round)(o)*t;return null!==n&&i>n&&(i=Math.floor(o)*t),i<r&&(i=Math.ceil(o)*t),i}function u([e,t],r){return[Math.max(Math.floor(e/r),1)*r,Math.max(Math.floor(t/r),1)*r]}function d([e,t,r,n]){return[e-r/2,t-n/2,e+r/2,t+n/2]}function m(e,t=.5,r=null,n=!1){let o=e.logits,i=e.pred_boxes,[a,l,c]=o.dims;if(null!==r&&r.length!==a)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let u=[];for(let e=0;e<a;++e){let a=null!==r?r[e]:null,m={boxes:[],classes:[],scores:[]},p=o[e],_=i[e];for(let e=0;e<l;++e){let r,o=p[e],i=[];if(n){r=o.sigmoid().data;for(let e=0;e<r.length;++e)r[e]>t&&i.push(e)}else{let e=(0,s.max)(o.data)[1];if(e===c-1||(r=(0,s.softmax)(o.data))[e]<t)continue;i.push(e)}for(let t of i){let n=_[e].data;n=d(n),null!==a&&(n=n.map((e,t)=>e*a[(t+1)%2])),m.boxes.push(n),m.classes.push(t),m.scores.push(r[t])}}u.push(m)}return u}function p(e,t=null){let r=e.logits,n=r.dims[0];if(null!==t&&t.length!==n)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let s=[];for(let e=0;e<n;++e){let n=null!==t?t[e]:null,i=r[e];null!==n&&(i=(0,o.interpolate)(i,n,"bilinear",!1));let[a,l]=n??i.dims.slice(-2),c=new o.Tensor("int32",new Int32Array(a*l),[a,l]),u=i[0].data,d=c.data;for(let e=1;e<i.dims[0];++e){let t=i[e].data;for(let r=0;r<t.length;++r)t[r]>u[r]&&(u[r]=t[r],d[r]=e)}let m=Array(i.dims[0]);for(let e=0;e<d.length;++e){let t=d[e];m[t]=t}let p=m.filter(e=>void 0!==e);s.push({segmentation:c,labels:p})}return s}function _(e,t=.5,r=.5,n=.8,i=null,a=null){null===i&&(console.warn("`label_ids_to_fuse` unset. No instance will be fused."),i=new Set);let l=e.class_queries_logits??e.logits,c=(e.masks_queries_logits??e.pred_masks).sigmoid(),[u,d,m]=l.dims;if(m-=1,null!==a&&a.length!==u)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let p=[];for(let e=0;e<u;++e){let u=null!==a?a[e]:null,d=l[e],_=c[e],[h,f,g]=function(e,t,r,n){let o=[],i=[],a=[];for(let l=0;l<e.dims[0];++l){let c=e[l],u=t[l],d=(0,s.max)(c.data)[1];if(d===n)continue;let m=(0,s.softmax)(c.data)[d];m>r&&(o.push(u),i.push(m),a.push(d))}return[o,i,a]}(d,_,t,m);if(0===g.length){let[e,t]=u??_.dims.slice(-2),r=new o.Tensor("int32",new Int32Array(e*t).fill(-1),[e,t]);p.push({segmentation:r,segments_info:[]});continue}let[M,w]=function(e,t,r,n,s,i=null,a=null){let[l,c]=a??e[0].dims,u=new o.Tensor("int32",new Int32Array(l*c),[l,c]),d=[];if(null!==a)for(let t=0;t<e.length;++t)e[t]=(0,o.interpolate)(e[t],a,"bilinear",!1);let m=new Int32Array(e[0].data.length),p=new Float32Array(e[0].data.length);for(let r=0;r<e.length;++r){let n=t[r],o=e[r].data;for(let e=0;e<o.length;++e)o[e]*=n,o[e]>p[e]&&(m[e]=r,p[e]=o[e])}let _=0,h=u.data;for(let o=0;o<r.length;++o){let i=r[o],[a,l]=function(e,t,r,n=.5,o=.8){let s=[],i=0,a=0,l=t[r].data;for(let t=0;t<e.length;++t)e[t]===r&&(s.push(t),++i),l[t]>=n&&++a;let c=i>0&&a>0;return c&&(c=i/a>o),[c,s]}(m,e,o,n,s);if(a){for(let e of(++_,l))h[e]=_;d.push({id:_,label_id:i,score:t[o]})}}return[u,d]}(h,f,g,r,n,i,u);p.push({segmentation:M,segments_info:w})}return p}function h(e,t=.5,r=null){throw Error("`post_process_instance_segmentation` is not yet implemented.")}class f extends n.Callable{constructor(e){super(),this.image_mean=e.image_mean??e.mean,this.image_std=e.image_std??e.std,this.resample=e.resample??2,this.do_rescale=e.do_rescale??!0,this.rescale_factor=e.rescale_factor??1/255,this.do_normalize=e.do_normalize,this.do_thumbnail=e.do_thumbnail,this.size=e.size??e.image_size,this.do_resize=e.do_resize??void 0!==this.size,this.size_divisibility=e.size_divisibility??e.size_divisor,this.do_center_crop=e.do_center_crop,this.crop_size=e.crop_size,this.do_convert_rgb=e.do_convert_rgb??!0,this.do_crop_margin=e.do_crop_margin,this.pad_size=e.pad_size,this.do_pad=e.do_pad,this.min_pixels=e.min_pixels,this.max_pixels=e.max_pixels,this.do_pad&&!this.pad_size&&this.size&&void 0!==this.size.width&&void 0!==this.size.height&&(this.pad_size=this.size),this.do_flip_channel_order=e.do_flip_channel_order??!1,this.config=e}async thumbnail(e,t,r=2){let n=e.height,o=e.width,s=t.height,i=t.width,a=Math.min(n,s),l=Math.min(o,i);return a===n&&l===o?e:(n>o?l=Math.floor(o*a/n):o>n&&(a=Math.floor(n*l/o)),await e.resize(l,a,{resample:r}))}async crop_margin(e,t=200){let r=e.clone().grayscale(),n=(0,s.min)(r.data)[0],o=(0,s.max)(r.data)[0]-n;if(0===o)return e;let i=t/255,a=r.width,l=r.height,c=0,u=0,d=r.data;for(let e=0;e<r.height;++e){let t=e*r.width;for(let s=0;s<r.width;++s)(d[t+s]-n)/o<i&&(a=Math.min(a,s),l=Math.min(l,e),c=Math.max(c,s),u=Math.max(u,e))}return e=await e.crop([a,l,c,u])}pad_image(e,t,r,{mode:n="constant",center:o=!1,constant_values:s=0}={}){let a,l;let[c,u,d]=t;if("number"==typeof r?(a=r,l=r):"square"===r?a=l=Math.max(c,u):(a=r.width,l=r.height),a!==u||l!==c){let r=new Float32Array(a*l*d);if(Array.isArray(s))for(let e=0;e<r.length;++e)r[e]=s[e%d];else 0!==s&&r.fill(s);let[m,p]=o?[Math.floor((a-u)/2),Math.floor((l-c)/2)]:[0,0];for(let t=0;t<c;++t){let n=(t+p)*a,o=t*u;for(let t=0;t<u;++t){let s=(n+t+m)*d,i=(o+t)*d;for(let t=0;t<d;++t)r[s+t]=e[i+t]}}if("symmetric"===n){if(o)throw Error("`center` padding is not supported when `mode` is set to `symmetric`.");let t=c-1,n=u-1;for(let o=0;o<l;++o){let s=o*a,l=(0,i.calculateReflectOffset)(o,t)*u;for(let t=0;t<a;++t){if(o<c&&t<u)continue;let a=(s+t)*d,m=(l+(0,i.calculateReflectOffset)(t,n))*d;for(let t=0;t<d;++t)r[a+t]=e[m+t]}}}e=r,t=[l,a,d]}return[e,t]}rescale(e){for(let t=0;t<e.length;++t)e[t]=this.rescale_factor*e[t]}get_resize_output_image_size(e,t){let r,n;let[o,s]=e.size;if(this.do_thumbnail){let{height:e,width:n}=t;r=Math.min(e,n)}else Number.isInteger(t)?(r=t,n=this.config.max_size??r):void 0!==t&&(r=t.shortest_edge,n=t.longest_edge);if(void 0!==r||void 0!==n){let e=void 0===r?1:Math.max(r/o,r/s),t=o*e,i=s*e,a=void 0===n?1:Math.min(n/t,n/i),l=Math.floor(Number((t*a).toFixed(2))),c=Math.floor(Number((i*a).toFixed(2)));return void 0!==this.size_divisibility&&([l,c]=u([l,c],this.size_divisibility)),[l,c]}if(void 0!==t&&void 0!==t.width&&void 0!==t.height){let e=t.width,r=t.height;if(this.config.keep_aspect_ratio&&this.config.ensure_multiple_of){let t=r/s,n=e/o;Math.abs(1-n)<Math.abs(1-t)?t=n:n=t,r=c(t*s,this.config.ensure_multiple_of),e=c(n*o,this.config.ensure_multiple_of)}return[e,r]}if(void 0!==this.size_divisibility)return u([o,s],this.size_divisibility);if(void 0!==this.min_pixels&&void 0!==this.max_pixels)return function(e,t,r=28,n=3136,o=1003520){if(e<r||t<r)throw Error(`height:${e} or width:${t} must be larger than factor:${r}`);if(Math.max(e,t)/Math.min(e,t)>200)throw Error(`absolute aspect ratio must be smaller than 200, got ${Math.max(e,t)/Math.min(e,t)}`);let s=Math.round(e/r)*r,i=Math.round(t/r)*r;if(s*i>o){let n=Math.sqrt(e*t/o);s=Math.floor(e/n/r)*r,i=Math.floor(t/n/r)*r}else if(s*i<n){let o=Math.sqrt(n/(e*t));s=Math.ceil(e*o/r)*r,i=Math.ceil(t*o/r)*r}return[s,i]}(s,o,this.config.patch_size*this.config.merge_size,this.min_pixels,this.max_pixels);throw Error(`Could not resize image due to unsupported \`this.size\` option in config: ${JSON.stringify(t)}`)}async resize(e){let[t,r]=this.get_resize_output_image_size(e,this.size);return await e.resize(t,r,{resample:this.resample})}async preprocess(e,{do_normalize:t=null,do_pad:r=null,do_convert_rgb:n=null,do_convert_grayscale:s=null,do_flip_channel_order:i=null}={}){this.do_crop_margin&&(e=await this.crop_margin(e));let[a,l]=e.size;if(n??this.do_convert_rgb?e=e.rgb():s&&(e=e.grayscale()),this.do_resize&&(e=await this.resize(e)),this.do_thumbnail&&(e=await this.thumbnail(e,this.size,this.resample)),this.do_center_crop){let t,r;Number.isInteger(this.crop_size)?(t=this.crop_size,r=this.crop_size):(t=this.crop_size.width,r=this.crop_size.height),e=await e.center_crop(t,r)}let c=[e.height,e.width],d=Float32Array.from(e.data),m=[e.height,e.width,e.channels];if(this.do_rescale&&this.rescale(d),t??this.do_normalize){let t=this.image_mean;Array.isArray(this.image_mean)||(t=Array(e.channels).fill(t));let r=this.image_std;if(Array.isArray(this.image_std)||(r=Array(e.channels).fill(t)),t.length!==e.channels||r.length!==e.channels)throw Error(`When set to arrays, the length of \`image_mean\` (${t.length}) and \`image_std\` (${r.length}) must match the number of channels in the image (${e.channels}).`);for(let n=0;n<d.length;n+=e.channels)for(let o=0;o<e.channels;++o)d[n+o]=(d[n+o]-t[o])/r[o]}if(r??this.do_pad){if(this.pad_size){let t=this.pad_image(d,[e.height,e.width,e.channels],this.pad_size);[d,m]=t}else if(this.size_divisibility){let[e,t]=u([m[1],m[0]],this.size_divisibility);[d,m]=this.pad_image(d,m,{width:e,height:t})}}if(i??this.do_flip_channel_order){if(3!==m[2])throw Error("Flipping channel order is only supported for RGB images.");for(let e=0;e<d.length;e+=3){let t=d[e];d[e]=d[e+2],d[e+2]=t}}return{original_size:[l,a],reshaped_input_size:c,pixel_values:new o.Tensor("float32",d,m).permute(2,0,1)}}async _call(e,...t){Array.isArray(e)||(e=[e]);let r=await Promise.all(e.map(e=>this.preprocess(e)));return{pixel_values:(0,o.stack)(r.map(e=>e.pixel_values),0),original_sizes:r.map(e=>e.original_size),reshaped_input_sizes:r.map(e=>e.reshaped_input_size)}}static async from_pretrained(e,t={}){return new this(await (0,a.getModelJSON)(e,l.IMAGE_PROCESSOR_NAME,!0,t))}}},"./src/base/processing_utils.js":/*!**************************************!*\
  !*** ./src/base/processing_utils.js ***!
  \**************************************/(e,t,r)=>{r.r(t),r.d(t,{Processor:()=>i});var n=r(/*! ../utils/constants.js */"./src/utils/constants.js"),o=r(/*! ../utils/generic.js */"./src/utils/generic.js"),s=r(/*! ../utils/hub.js */"./src/utils/hub.js");class i extends o.Callable{static classes=["image_processor_class","tokenizer_class","feature_extractor_class"];static uses_processor_config=!1;static uses_chat_template_file=!1;constructor(e,t,r){super(),this.config=e,this.components=t,this.chat_template=r}get image_processor(){return this.components.image_processor}get tokenizer(){return this.components.tokenizer}get feature_extractor(){return this.components.feature_extractor}apply_chat_template(e,t={}){if(!this.tokenizer)throw Error("Unable to apply chat template without a tokenizer.");return this.tokenizer.apply_chat_template(e,{tokenize:!1,chat_template:this.chat_template??void 0,...t})}batch_decode(...e){if(!this.tokenizer)throw Error("Unable to decode without a tokenizer.");return this.tokenizer.batch_decode(...e)}decode(...e){if(!this.tokenizer)throw Error("Unable to decode without a tokenizer.");return this.tokenizer.decode(...e)}async _call(e,...t){for(let r of[this.image_processor,this.feature_extractor,this.tokenizer])if(r)return r(e,...t);throw Error("No image processor, feature extractor, or tokenizer found.")}static async from_pretrained(e,t={}){let[r,o,i]=await Promise.all([this.uses_processor_config?(0,s.getModelJSON)(e,n.PROCESSOR_NAME,!0,t):{},Promise.all(this.classes.filter(e=>e in this).map(async r=>{let n=await this[r].from_pretrained(e,t);return[r.replace(/_class$/,""),n]})).then(Object.fromEntries),this.uses_chat_template_file?(0,s.getModelText)(e,n.CHAT_TEMPLATE_NAME,!0,t):null]);return new this(r,o,i)}}},"./src/configs.js":/*!************************!*\
  !*** ./src/configs.js ***!
  \************************/(e,t,r)=>{r.r(t),r.d(t,{AutoConfig:()=>l,PretrainedConfig:()=>a,getCacheShapes:()=>i});var n=r(/*! ./utils/core.js */"./src/utils/core.js"),o=r(/*! ./utils/hub.js */"./src/utils/hub.js");async function s(e,t){return await (0,o.getModelJSON)(e,"config.json",!0,t)}function i(e,t){if("lfm2"===e.model_type){let r=t?.prefix??"past_key_values",n="present"===r?"present":"past",o={},{layer_types:s,num_attention_heads:i,num_key_value_heads:a,hidden_size:l,conv_L_cache:c}=e,u=l/i,d=t?.batch_size??1;for(let e=0;e<s.length;++e)if("full_attention"===s[e])for(let t of["key","value"])o[`${r}.${e}.${t}`]=[d,a,0,u];else if("conv"===s[e])o[`${n}_conv.${e}`]=[d,l,c];else throw Error(`Unsupported layer type: ${s[e]}`);return o}return function(e,{prefix:t="past_key_values",batch_size:r=1}={}){let n={},o=e.normalized_config;if(o.is_encoder_decoder&&"num_encoder_heads"in o&&"num_decoder_heads"in o){let e=o.encoder_dim_kv??o.encoder_hidden_size/o.num_encoder_heads,s=o.decoder_dim_kv??o.decoder_hidden_size/o.num_decoder_heads,i=[r,o.num_encoder_heads,0,e],a=[r,o.num_decoder_heads,0,s];for(let e=0;e<o.num_decoder_layers;++e)n[`${t}.${e}.encoder.key`]=i,n[`${t}.${e}.encoder.value`]=i,n[`${t}.${e}.decoder.key`]=a,n[`${t}.${e}.decoder.value`]=a}else{let e=o.num_heads,s=o.num_layers,i=o.dim_kv??o.hidden_size/(o.num_attention_heads??e);if("falcon"===o.model_type){let o=[r*e,0,i];for(let e=0;e<s;++e)n[`${t}.${e}.key`]=o,n[`${t}.${e}.value`]=o}else if(o.multi_query){let o=[r*e,0,2*i];for(let e=0;e<s;++e)n[`${t}.${e}.key_value`]=o}else if("bloom"===o.model_type){let o=[r*e,i,0],a=[r*e,0,i];for(let e=0;e<s;++e)n[`${t}.${e}.key`]=o,n[`${t}.${e}.value`]=a}else if("openelm"===o.model_type)for(let o=0;o<s;++o){let s=[r,e[o],0,i];n[`${t}.${o}.key`]=s,n[`${t}.${o}.value`]=s}else{let o=[r,e,0,i];for(let e=0;e<s;++e)n[`${t}.${e}.key`]=o,n[`${t}.${e}.value`]=o}}return n}(e,t)}class a{model_type=null;is_encoder_decoder=!1;max_position_embeddings;"transformers.js_config";constructor(e){Object.assign(this,e),this.normalized_config=function e(t){let r={},o={};switch(t.model_type){case"llava":case"paligemma":case"gemma3":case"florence2":case"llava_onevision":case"idefics3":case"ultravox":case"voxtral":case"smolvlm":case"gemma3n":o=e(t.text_config);break;case"moondream1":o=e(t.phi_config);break;case"musicgen":o=e(t.decoder);break;case"multi_modality":o=e(t.language_config);break;case"gpt2":case"gptj":case"jais":case"codegen":case"gpt_bigcode":r.num_heads="n_head",r.num_layers="n_layer",r.hidden_size="n_embd";break;case"gpt_neox":case"stablelm":case"opt":case"falcon":case"modernbert-decoder":r.num_heads="num_attention_heads",r.num_layers="num_hidden_layers",r.hidden_size="hidden_size";break;case"llama":case"arcee":case"lfm2":case"smollm3":case"olmo":case"olmo2":case"mobilellm":case"granite":case"cohere":case"mistral":case"starcoder2":case"qwen2":case"qwen2_vl":case"phi":case"phi3":case"phi3_v":case"llava_qwen2":r.num_heads="num_key_value_heads",r.num_layers="num_hidden_layers",r.hidden_size="hidden_size",r.num_attention_heads="num_attention_heads",r.dim_kv="head_dim";break;case"qwen3":case"gemma":case"gemma2":case"gemma3_text":case"gemma3n_text":case"glm":case"helium":case"ernie4_5":r.num_heads="num_key_value_heads",r.num_layers="num_hidden_layers",r.dim_kv="head_dim";break;case"openelm":r.num_heads="num_kv_heads",r.num_layers="num_transformer_layers",r.dim_kv="head_dim";break;case"gpt_neo":case"donut-swin":r.num_heads="num_heads",r.num_layers="num_layers",r.hidden_size="hidden_size";break;case"bloom":r.num_heads="n_head",r.num_layers="n_layer",r.hidden_size="hidden_size";break;case"mpt":r.num_heads="n_heads",r.num_layers="n_layers",r.hidden_size="d_model";break;case"exaone":r.num_heads="num_key_value_heads",r.num_layers="num_layers",r.dim_kv="head_dim",r.num_attention_heads="num_attention_heads";break;case"t5":case"mt5":case"longt5":r.num_decoder_layers="num_decoder_layers",r.num_decoder_heads="num_heads",r.decoder_dim_kv="d_kv",r.num_encoder_layers="num_layers",r.num_encoder_heads="num_heads",r.encoder_dim_kv="d_kv";break;case"bart":case"mbart":case"marian":case"whisper":case"lite-whisper":case"m2m_100":case"blenderbot":case"blenderbot-small":case"florence2_language":r.num_decoder_layers="decoder_layers",r.num_decoder_heads="decoder_attention_heads",r.decoder_hidden_size="d_model",r.num_encoder_layers="encoder_layers",r.num_encoder_heads="encoder_attention_heads",r.encoder_hidden_size="d_model";break;case"speecht5":r.num_decoder_layers="decoder_layers",r.num_decoder_heads="decoder_attention_heads",r.decoder_hidden_size="hidden_size",r.num_encoder_layers="encoder_layers",r.num_encoder_heads="encoder_attention_heads",r.encoder_hidden_size="hidden_size";break;case"trocr":r.num_encoder_layers=r.num_decoder_layers="decoder_layers",r.num_encoder_heads=r.num_decoder_heads="decoder_attention_heads",r.encoder_hidden_size=r.decoder_hidden_size="d_model";break;case"musicgen_decoder":r.num_encoder_layers=r.num_decoder_layers="num_hidden_layers",r.num_encoder_heads=r.num_decoder_heads="num_attention_heads",r.encoder_hidden_size=r.decoder_hidden_size="hidden_size";break;case"moonshine":r.num_decoder_layers="decoder_num_hidden_layers",r.num_decoder_heads="decoder_num_key_value_heads",r.num_encoder_layers="encoder_num_hidden_layers",r.num_encoder_heads="encoder_num_key_value_heads",r.encoder_hidden_size=r.decoder_hidden_size="hidden_size";break;case"vision-encoder-decoder":let s=e(t.decoder),i=(0,n.pick)(t,["model_type","is_encoder_decoder"]);return"num_decoder_layers"in s?(i.num_decoder_layers=s.num_decoder_layers,i.num_decoder_heads=s.num_decoder_heads,i.decoder_hidden_size=s.decoder_hidden_size,i.num_encoder_layers=s.num_encoder_layers,i.num_encoder_heads=s.num_encoder_heads,i.encoder_hidden_size=s.encoder_hidden_size):(i.num_layers=s.num_layers,i.num_heads=s.num_heads,i.hidden_size=s.hidden_size),i}let a={...o,...(0,n.pick)(t,["model_type","multi_query","is_encoder_decoder"])};for(let e in r)a[e]=t[r[e]];return a}(this)}static async from_pretrained(e,{progress_callback:t=null,config:r=null,cache_dir:n=null,local_files_only:o=!1,revision:i="main"}={}){return!r||r instanceof a||(r=new a(r)),new this(r??await s(e,{progress_callback:t,config:r,cache_dir:n,local_files_only:o,revision:i}))}}class l{static async from_pretrained(...e){return a.from_pretrained(...e)}}},"./src/env.js":/*!********************!*\
  !*** ./src/env.js ***!
  \********************/(e,t,r)=>{r.r(t),r.d(t,{apis:()=>f,env:()=>x});var n=r(/*! node:fs */"?db59"),o=r(/*! node:path */"?383f"),s=r(/*! node:url */"?fa4b");let i="undefined"!=typeof window&&void 0!==window.document,a="undefined"!=typeof self&&["DedicatedWorkerGlobalScope","ServiceWorkerGlobalScope","SharedWorkerGlobalScope"].includes(self.constructor?.name),l="undefined"!=typeof self&&"caches"in self,c="undefined"!=typeof navigator&&"gpu"in navigator,u="undefined"!=typeof navigator&&"ml"in navigator,d=void 0!==E,m=d&&E?.release?.name==="node",p=!P(n),_=!P(o),h=void 0!==globalThis.Deno,f=Object.freeze({IS_BROWSER_ENV:i,IS_WEBWORKER_ENV:a,IS_WEB_CACHE_AVAILABLE:l,IS_WEBGPU_AVAILABLE:c,IS_WEBNN_AVAILABLE:u,IS_PROCESS_AVAILABLE:d,IS_NODE_ENV:m,IS_FS_AVAILABLE:p,IS_PATH_AVAILABLE:_}),g=p&&_,M="./";if(g){let e=Object({}).url;e?M=o.dirname(o.dirname(s.fileURLToPath(e))):"undefined"!=typeof __dirname&&(M=o.dirname(__dirname))}let w=g?o.join(M,"/.cache/"):null,T="/models/",x={version:"3.7.2",backends:{onnx:{}},allowRemoteModels:!0,remoteHost:"https://huggingface.co/",remotePathTemplate:"{model}/resolve/{revision}/",allowLocalModels:!(i||a),localModelPath:g?o.join(M,T):T,useFS:p,useBrowserCache:l&&!h,useFSCache:p,cacheDir:w,useCustomCache:!1,customCache:null};function P(e){return 0===Object.keys(e).length}},"./src/generation/configuration_utils.js":/*!***********************************************!*\
  !*** ./src/generation/configuration_utils.js ***!
  \***********************************************/(e,t,r)=>{r.r(t),r.d(t,{GenerationConfig:()=>o});var n=r(/*! ../utils/core.js */"./src/utils/core.js");class o{max_length=20;max_new_tokens=null;min_length=0;min_new_tokens=null;early_stopping=!1;max_time=null;do_sample=!1;num_beams=1;num_beam_groups=1;penalty_alpha=null;use_cache=!0;temperature=1;top_k=50;top_p=1;typical_p=1;epsilon_cutoff=0;eta_cutoff=0;diversity_penalty=0;repetition_penalty=1;encoder_repetition_penalty=1;length_penalty=1;no_repeat_ngram_size=0;bad_words_ids=null;force_words_ids=null;renormalize_logits=!1;constraints=null;forced_bos_token_id=null;forced_eos_token_id=null;remove_invalid_values=!1;exponential_decay_length_penalty=null;suppress_tokens=null;streamer=null;begin_suppress_tokens=null;forced_decoder_ids=null;guidance_scale=null;num_return_sequences=1;output_attentions=!1;output_hidden_states=!1;output_scores=!1;return_dict_in_generate=!1;pad_token_id=null;bos_token_id=null;eos_token_id=null;encoder_no_repeat_ngram_size=0;decoder_start_token_id=null;generation_kwargs={};constructor(e){Object.assign(this,(0,n.pick)(e,Object.getOwnPropertyNames(this)))}}},"./src/generation/logits_process.js":/*!******************************************!*\
  !*** ./src/generation/logits_process.js ***!
  \******************************************/(e,t,r)=>{r.r(t),r.d(t,{ClassifierFreeGuidanceLogitsProcessor:()=>g,ForcedBOSTokenLogitsProcessor:()=>l,ForcedEOSTokenLogitsProcessor:()=>c,LogitsProcessor:()=>s,LogitsProcessorList:()=>a,LogitsWarper:()=>i,MinLengthLogitsProcessor:()=>_,MinNewTokensLengthLogitsProcessor:()=>h,NoBadWordsLogitsProcessor:()=>f,NoRepeatNGramLogitsProcessor:()=>m,RepetitionPenaltyLogitsProcessor:()=>p,SuppressTokensAtBeginLogitsProcessor:()=>u,TemperatureLogitsWarper:()=>M,TopKLogitsWarper:()=>T,TopPLogitsWarper:()=>w,WhisperTimeStampLogitsProcessor:()=>d});var n=r(/*! ../utils/generic.js */"./src/utils/generic.js");r(/*! ../utils/tensor.js */"./src/utils/tensor.js");var o=r(/*! ../utils/maths.js */"./src/utils/maths.js");class s extends n.Callable{_call(e,t){throw Error("`_call` should be implemented in a subclass")}}class i extends n.Callable{_call(e,t){throw Error("`_call` should be implemented in a subclass")}}class a extends n.Callable{constructor(){super(),this.processors=[]}push(e){this.processors.push(e)}extend(e){this.processors.push(...e)}_call(e,t){let r=t;for(let t of this.processors)r=t(e,r);return r}[Symbol.iterator](){return this.processors.values()}}class l extends s{constructor(e){super(),this.bos_token_id=e}_call(e,t){for(let r=0;r<e.length;++r)if(1===e[r].length){let e=t[r].data;e.fill(-1/0),e[this.bos_token_id]=0}return t}}class c extends s{constructor(e,t){super(),this.max_length=e,this.eos_token_id=Array.isArray(t)?t:[t]}_call(e,t){for(let r=0;r<e.length;++r)if(e[r].length===this.max_length-1){let e=t[r].data;for(let t of(e.fill(-1/0),this.eos_token_id))e[t]=0}return t}}class u extends s{constructor(e,t){super(),this.begin_suppress_tokens=e,this.begin_index=t}_call(e,t){for(let r=0;r<e.length;++r)if(e[r].length===this.begin_index){let e=t[r].data;for(let t of this.begin_suppress_tokens)e[t]=-1/0}return t}}class d extends s{constructor(e,t){super(),this.eos_token_id=Array.isArray(e.eos_token_id)?e.eos_token_id[0]:e.eos_token_id,this.no_timestamps_token_id=e.no_timestamps_token_id,this.timestamp_begin=this.no_timestamps_token_id+1,this.begin_index=t.length,t.at(-1)===this.no_timestamps_token_id&&(this.begin_index-=1),this.max_initial_timestamp_index=e.max_initial_timestamp_index}_call(e,t){for(let r=0;r<e.length;++r){let n=t[r].data;if(n[this.no_timestamps_token_id]=-1/0,e[r].length===this.begin_index-1){n.fill(-1/0),n[this.timestamp_begin]=0;continue}let s=e[r].slice(this.begin_index),i=s.length>=1&&s[s.length-1]>=this.timestamp_begin,a=s.length<2||s[s.length-2]>=this.timestamp_begin;if(i&&(a?n.subarray(this.timestamp_begin).fill(-1/0):n.subarray(0,this.eos_token_id).fill(-1/0)),e[r].length===this.begin_index&&null!==this.max_initial_timestamp_index){let e=this.timestamp_begin+this.max_initial_timestamp_index;n.subarray(e+1).fill(-1/0)}let l=(0,o.log_softmax)(n);Math.log(l.subarray(this.timestamp_begin).map(Math.exp).reduce((e,t)=>e+t))>(0,o.max)(l.subarray(0,this.timestamp_begin))[0]&&n.subarray(0,this.timestamp_begin).fill(-1/0)}return t}}class m extends s{constructor(e){super(),this.no_repeat_ngram_size=e}getNgrams(e){let t=e.length,r=[];for(let n=0;n<t+1-this.no_repeat_ngram_size;++n){let t=[];for(let r=0;r<this.no_repeat_ngram_size;++r)t.push(e[n+r]);r.push(t.map(Number))}let n=new Map;for(let e of r){let t=JSON.stringify(e.slice(0,e.length-1)),r=n.get(t)??[];r.push(e[e.length-1]),n.set(t,r)}return n}getGeneratedNgrams(e,t){let r=t.slice(t.length+1-this.no_repeat_ngram_size,t.length);return e.get(JSON.stringify(r.map(Number)))??[]}calcBannedNgramTokens(e){if(e.length+1<this.no_repeat_ngram_size)return[];{let t=this.getNgrams(e);return this.getGeneratedNgrams(t,e)}}_call(e,t){for(let r=0;r<e.length;++r){let n=t[r].data;for(let t of this.calcBannedNgramTokens(e[r]))n[t]=-1/0}return t}}class p extends s{constructor(e){super(),this.penalty=e}_call(e,t){for(let r=0;r<e.length;++r){let n=t[r].data;for(let t of new Set(e[r])){let e=Number(t);n[e]<0?n[e]*=this.penalty:n[e]/=this.penalty}}return t}}class _ extends s{constructor(e,t){super(),this.min_length=e,this.eos_token_id=Array.isArray(t)?t:[t]}_call(e,t){for(let r=0;r<e.length;++r)if(e[r].length<this.min_length){let e=t[r].data;for(let t of this.eos_token_id)e[t]=-1/0}return t}}class h extends s{constructor(e,t,r){super(),this.prompt_length_to_skip=e,this.min_new_tokens=t,this.eos_token_id=Array.isArray(r)?r:[r]}_call(e,t){for(let r=0;r<e.length;++r)if(e[r].length-this.prompt_length_to_skip<this.min_new_tokens){let e=t[r].data;for(let t of this.eos_token_id)e[t]=-1/0}return t}}class f extends s{constructor(e,t){super(),this.bad_words_ids=e,this.eos_token_id=Array.isArray(t)?t:[t]}_call(e,t){for(let r=0;r<e.length;++r){let n=t[r].data,o=e[r];for(let e of this.bad_words_ids){if(o.length<e.length-1)continue;let t=!0;for(let r=1;r<=e.length-1;++r)if(e.at(-r-1)!=o.at(-r)){t=!1;break}t&&(n[e.at(-1)]=-1/0)}}return t}}class g extends s{constructor(e){if(super(),e<=1)throw Error(`Require guidance scale >1 to use the classifier free guidance processor, got guidance scale ${e}.`);this.guidance_scale=e}_call(e,t){if(t.dims[0]!==2*e.length)throw Error(`Logits should have twice the batch size of the input ids, the first half of batches corresponding to the conditional inputs, and the second half of batches corresponding to the unconditional inputs. Got batch size ${t.dims[0]} for the logits and ${e.length} for the input ids.`);let r=e.length,n=t.slice([0,r],null),o=t.slice([r,t.dims[0]],null);for(let e=0;e<o.data.length;++e)o.data[e]+=(n.data[e]-o.data[e])*this.guidance_scale;return o}}class M extends i{constructor(e){super(),this.temperature=e}_call(e,t){let r=t.data;for(let e=0;e<r.length;++e)r[e]/=this.temperature;return t}}class w extends i{constructor(e,{filter_value:t=-1/0,min_tokens_to_keep:r=1}={}){if(super(),e<0||e>1)throw Error(`\`top_p\` must be a float > 0 and < 1, but is ${e}`);if(!Number.isInteger(r)||r<1)throw Error(`\`min_tokens_to_keep\` must be a positive integer, but is ${r}`);this.top_p=e,this.filter_value=t,this.min_tokens_to_keep=r}}class T extends i{constructor(e,{filter_value:t=-1/0,min_tokens_to_keep:r=1}={}){if(super(),!Number.isInteger(e)||e<0)throw Error(`\`top_k\` must be a positive integer, but is ${e}`);this.top_k=Math.max(e,r),this.filter_value=t}}},"./src/generation/logits_sampler.js":/*!******************************************!*\
  !*** ./src/generation/logits_sampler.js ***!
  \******************************************/(e,t,r)=>{r.r(t),r.d(t,{LogitsSampler:()=>i});var n=r(/*! ../utils/generic.js */"./src/utils/generic.js"),o=r(/*! ../utils/tensor.js */"./src/utils/tensor.js"),s=r(/*! ../utils/maths.js */"./src/utils/maths.js");r(/*! ../generation/configuration_utils.js */"./src/generation/configuration_utils.js");class i extends n.Callable{constructor(e){super(),this.generation_config=e}async _call(e){return this.sample(e)}async sample(e){throw Error("sample should be implemented in subclasses.")}getLogits(e,t){let r=e.dims.at(-1),n=e.data;if(-1===t)n=n.slice(-r);else{let e=t*r;n=n.slice(e,e+r)}return n}randomSelect(e){let t=0;for(let r=0;r<e.length;++r)t+=e[r];let r=Math.random()*t;for(let t=0;t<e.length;++t)if((r-=e[t])<=0)return t;return 0}static getSampler(e){if(e.do_sample)return new l(e);if(e.num_beams>1)return new c(e);if(e.num_return_sequences>1)throw Error(`num_return_sequences has to be 1 when doing greedy search, but is ${e.num_return_sequences}.`);return new a(e)}}class a extends i{async sample(e){return[[BigInt((0,s.max)(e.data)[1]),0]]}}class l extends i{async sample(e){let t=e.dims.at(-1);this.generation_config.top_k>0&&(t=Math.min(this.generation_config.top_k,t));let[r,n]=await (0,o.topk)(e,t),i=(0,s.softmax)(r.data);return Array.from({length:this.generation_config.num_beams},()=>{let e=this.randomSelect(i);return[n.data[e],Math.log(i[e])]})}}class c extends i{async sample(e){let t=e.dims.at(-1);this.generation_config.top_k>0&&(t=Math.min(this.generation_config.top_k,t));let[r,n]=await (0,o.topk)(e,t),i=(0,s.softmax)(r.data);return Array.from({length:this.generation_config.num_beams},(e,t)=>[n.data[t],Math.log(i[t])])}}},"./src/generation/stopping_criteria.js":/*!*********************************************!*\
  !*** ./src/generation/stopping_criteria.js ***!
  \*********************************************/(e,t,r)=>{r.r(t),r.d(t,{EosTokenCriteria:()=>a,InterruptableStoppingCriteria:()=>l,MaxLengthCriteria:()=>i,StoppingCriteria:()=>o,StoppingCriteriaList:()=>s});var n=r(/*! ../utils/generic.js */"./src/utils/generic.js");class o extends n.Callable{_call(e,t){throw Error("StoppingCriteria needs to be subclassed")}}class s extends n.Callable{constructor(){super(),this.criteria=[]}push(e){this.criteria.push(e)}extend(e){e instanceof s?e=e.criteria:e instanceof o&&(e=[e]),this.criteria.push(...e)}_call(e,t){let r=Array(e.length).fill(!1);for(let n of this.criteria){let o=n(e,t);for(let e=0;e<r.length;++e)r[e]||=o[e]}return r}[Symbol.iterator](){return this.criteria.values()}}class i extends o{constructor(e,t=null){super(),this.max_length=e,this.max_position_embeddings=t}_call(e){return e.map(e=>e.length>=this.max_length)}}class a extends o{constructor(e){super(),Array.isArray(e)||(e=[e]),this.eos_token_id=e}_call(e,t){return e.map(e=>{let t=e.at(-1);return this.eos_token_id.some(e=>t==e)})}}class l extends o{constructor(){super(),this.interrupted=!1}interrupt(){this.interrupted=!0}reset(){this.interrupted=!1}_call(e,t){return Array(e.length).fill(this.interrupted)}}},"./src/generation/streamers.js":/*!*************************************!*\
  !*** ./src/generation/streamers.js ***!
  \*************************************/(e,t,r)=>{r.r(t),r.d(t,{BaseStreamer:()=>i,TextStreamer:()=>l,WhisperTextStreamer:()=>c});var n=r(/*! ../utils/core.js */"./src/utils/core.js"),o=r(/*! ../tokenizers.js */"./src/tokenizers.js"),s=r(/*! ../env.js */"./src/env.js");class i{put(e){throw Error("Not implemented")}end(){throw Error("Not implemented")}}let a=s.apis.IS_PROCESS_AVAILABLE?e=>E.stdout.write(e):e=>console.log(e);class l extends i{constructor(e,{skip_prompt:t=!1,callback_function:r=null,token_callback_function:n=null,skip_special_tokens:o=!0,decode_kwargs:s={},...i}={}){super(),this.tokenizer=e,this.skip_prompt=t,this.callback_function=r??a,this.token_callback_function=n,this.decode_kwargs={skip_special_tokens:o,...s,...i},this.token_cache=[],this.print_len=0,this.next_tokens_are_prompt=!0}put(e){let t;if(e.length>1)throw Error("TextStreamer only supports batch size of 1");let r=this.next_tokens_are_prompt;if(r&&(this.next_tokens_are_prompt=!1,this.skip_prompt))return;let s=e[0];this.token_callback_function?.(s),this.token_cache=(0,n.mergeArrays)(this.token_cache,s);let i=this.tokenizer.decode(this.token_cache,this.decode_kwargs);r||i.endsWith("\n")?(t=i.slice(this.print_len),this.token_cache=[],this.print_len=0):(t=i.length>0&&(0,o.is_chinese_char)(i.charCodeAt(i.length-1))?i.slice(this.print_len):i.slice(this.print_len,i.lastIndexOf(" ")+1),this.print_len+=t.length),this.on_finalized_text(t,!1)}end(){let e;this.token_cache.length>0?(e=this.tokenizer.decode(this.token_cache,this.decode_kwargs).slice(this.print_len),this.token_cache=[],this.print_len=0):e="",this.next_tokens_are_prompt=!0,this.on_finalized_text(e,!0)}on_finalized_text(e,t){e.length>0&&this.callback_function?.(e),t&&this.callback_function===a&&s.apis.IS_PROCESS_AVAILABLE&&this.callback_function?.("\n")}}class c extends l{constructor(e,{skip_prompt:t=!1,callback_function:r=null,token_callback_function:n=null,on_chunk_start:o=null,on_chunk_end:s=null,on_finalize:i=null,time_precision:a=.02,skip_special_tokens:l=!0,decode_kwargs:c={}}={}){super(e,{skip_prompt:t,skip_special_tokens:l,callback_function:r,token_callback_function:n,decode_kwargs:c}),this.timestamp_begin=e.timestamp_begin,this.on_chunk_start=o,this.on_chunk_end=s,this.on_finalize=i,this.time_precision=a,this.waiting_for_timestamp=!1}put(e){if(e.length>1)throw Error("WhisperTextStreamer only supports batch size of 1");let t=e[0];if(1===t.length){let e=Number(t[0])-this.timestamp_begin;if(e>=0){let r=e*this.time_precision;this.waiting_for_timestamp?this.on_chunk_end?.(r):this.on_chunk_start?.(r),this.waiting_for_timestamp=!this.waiting_for_timestamp,this.token_callback_function?.(t);return}}return super.put(e)}end(){super.end(),this.on_finalize?.()}}},"./src/models.js":/*!***********************!*\
  !*** ./src/models.js ***!
  \***********************/(e,t,r)=>{r.r(t),r.d(t,{ASTForAudioClassification:()=>rt,ASTModel:()=>re,ASTPreTrainedModel:()=>t7,AlbertForMaskedLM:()=>tT,AlbertForQuestionAnswering:()=>tw,AlbertForSequenceClassification:()=>tM,AlbertModel:()=>tg,AlbertPreTrainedModel:()=>tf,ArceeForCausalLM:()=>na,ArceeModel:()=>ni,ArceePreTrainedModel:()=>ns,AutoModel:()=>lH,AutoModelForAudioClassification:()=>co,AutoModelForAudioFrameClassification:()=>ci,AutoModelForAudioTextToText:()=>ch,AutoModelForCTC:()=>cn,AutoModelForCausalLM:()=>l2,AutoModelForDepthEstimation:()=>cu,AutoModelForDocumentQuestionAnswering:()=>ca,AutoModelForImageClassification:()=>l8,AutoModelForImageFeatureExtraction:()=>cp,AutoModelForImageMatting:()=>cl,AutoModelForImageSegmentation:()=>l6,AutoModelForImageTextToText:()=>c_,AutoModelForImageToImage:()=>cc,AutoModelForMaskGeneration:()=>cr,AutoModelForMaskedLM:()=>l3,AutoModelForNormalEstimation:()=>cd,AutoModelForObjectDetection:()=>ce,AutoModelForPoseEstimation:()=>cm,AutoModelForQuestionAnswering:()=>l4,AutoModelForSemanticSegmentation:()=>l9,AutoModelForSeq2SeqLM:()=>lK,AutoModelForSequenceClassification:()=>lJ,AutoModelForSpeechSeq2Seq:()=>lZ,AutoModelForTextToSpectrogram:()=>l0,AutoModelForTextToWaveform:()=>l1,AutoModelForTokenClassification:()=>lY,AutoModelForUniversalSegmentation:()=>l7,AutoModelForVision2Seq:()=>l5,AutoModelForXVector:()=>cs,AutoModelForZeroShotObjectDetection:()=>ct,BartForConditionalGeneration:()=>tL,BartForSequenceClassification:()=>tI,BartModel:()=>tA,BartPretrainedModel:()=>tE,BaseModelOutput:()=>X,BeitForImageClassification:()=>oU,BeitModel:()=>oW,BeitPreTrainedModel:()=>o$,BertForMaskedLM:()=>Y,BertForQuestionAnswering:()=>ee,BertForSequenceClassification:()=>K,BertForTokenClassification:()=>Z,BertModel:()=>J,BertPreTrainedModel:()=>H,BlenderbotForConditionalGeneration:()=>tG,BlenderbotModel:()=>tB,BlenderbotPreTrainedModel:()=>tN,BlenderbotSmallForConditionalGeneration:()=>t$,BlenderbotSmallModel:()=>tq,BlenderbotSmallPreTrainedModel:()=>tR,BloomForCausalLM:()=>or,BloomModel:()=>ot,BloomPreTrainedModel:()=>oe,CLIPModel:()=>rv,CLIPPreTrainedModel:()=>ry,CLIPSegForImageSegmentation:()=>r$,CLIPSegModel:()=>rq,CLIPSegPreTrainedModel:()=>rR,CLIPTextModel:()=>rC,CLIPTextModelWithProjection:()=>rS,CLIPVisionModel:()=>rE,CLIPVisionModelWithProjection:()=>rA,CamembertForMaskedLM:()=>eV,CamembertForQuestionAnswering:()=>eB,CamembertForSequenceClassification:()=>eO,CamembertForTokenClassification:()=>eN,CamembertModel:()=>ej,CamembertPreTrainedModel:()=>ez,CausalLMOutput:()=>cP,CausalLMOutputWithPast:()=>cb,ChineseCLIPModel:()=>rV,ChineseCLIPPreTrainedModel:()=>rj,ClapAudioModelWithProjection:()=>ac,ClapModel:()=>aa,ClapPreTrainedModel:()=>ai,ClapTextModelWithProjection:()=>al,CodeGenForCausalLM:()=>nt,CodeGenModel:()=>ne,CodeGenPreTrainedModel:()=>r7,CohereForCausalLM:()=>nV,CohereModel:()=>nj,CoherePreTrainedModel:()=>nz,ConvBertForMaskedLM:()=>ek,ConvBertForQuestionAnswering:()=>eC,ConvBertForSequenceClassification:()=>ey,ConvBertForTokenClassification:()=>ev,ConvBertModel:()=>eF,ConvBertPreTrainedModel:()=>eb,ConvNextForImageClassification:()=>sH,ConvNextModel:()=>sX,ConvNextPreTrainedModel:()=>sQ,ConvNextV2ForImageClassification:()=>sK,ConvNextV2Model:()=>sY,ConvNextV2PreTrainedModel:()=>sJ,DFineForObjectDetection:()=>sn,DFineModel:()=>sr,DFinePreTrainedModel:()=>st,DINOv3ConvNextModel:()=>s9,DINOv3ConvNextPreTrainedModel:()=>s6,DINOv3ViTModel:()=>s8,DINOv3ViTPreTrainedModel:()=>s5,DPTForDepthEstimation:()=>sy,DPTModel:()=>sk,DPTPreTrainedModel:()=>sF,DacDecoderModel:()=>ls,DacDecoderOutput:()=>lr,DacEncoderModel:()=>lo,DacEncoderOutput:()=>lt,DacModel:()=>ln,DacPreTrainedModel:()=>le,DebertaForMaskedLM:()=>eq,DebertaForQuestionAnswering:()=>eU,DebertaForSequenceClassification:()=>e$,DebertaForTokenClassification:()=>eW,DebertaModel:()=>eR,DebertaPreTrainedModel:()=>eG,DebertaV2ForMaskedLM:()=>eH,DebertaV2ForQuestionAnswering:()=>eK,DebertaV2ForSequenceClassification:()=>eJ,DebertaV2ForTokenClassification:()=>eY,DebertaV2Model:()=>eX,DebertaV2PreTrainedModel:()=>eQ,DecisionTransformerModel:()=>aq,DecisionTransformerPreTrainedModel:()=>aR,DeiTForImageClassification:()=>su,DeiTModel:()=>sc,DeiTPreTrainedModel:()=>sl,DepthAnythingForDepthEstimation:()=>sC,DepthAnythingPreTrainedModel:()=>sv,DepthProForDepthEstimation:()=>sD,DepthProPreTrainedModel:()=>sI,DetrForObjectDetection:()=>oH,DetrForSegmentation:()=>oJ,DetrModel:()=>oX,DetrObjectDetectionOutput:()=>oY,DetrPreTrainedModel:()=>oQ,DetrSegmentationOutput:()=>oK,Dinov2ForImageClassification:()=>s1,Dinov2Model:()=>s0,Dinov2PreTrainedModel:()=>sZ,Dinov2WithRegistersForImageClassification:()=>s4,Dinov2WithRegistersModel:()=>s3,Dinov2WithRegistersPreTrainedModel:()=>s2,DistilBertForMaskedLM:()=>e4,DistilBertForQuestionAnswering:()=>e3,DistilBertForSequenceClassification:()=>e1,DistilBertForTokenClassification:()=>e2,DistilBertModel:()=>e0,DistilBertPreTrainedModel:()=>eZ,DonutSwinModel:()=>sU,DonutSwinPreTrainedModel:()=>sW,EfficientNetForImageClassification:()=>ax,EfficientNetModel:()=>aT,EfficientNetPreTrainedModel:()=>aw,ElectraForMaskedLM:()=>eA,ElectraForQuestionAnswering:()=>eD,ElectraForSequenceClassification:()=>eL,ElectraForTokenClassification:()=>eI,ElectraModel:()=>eE,ElectraPreTrainedModel:()=>eS,Ernie4_5_ForCausalLM:()=>i7,Ernie4_5_Model:()=>i9,Ernie4_5_PretrainedModel:()=>i6,EsmForMaskedLM:()=>e6,EsmForSequenceClassification:()=>e9,EsmForTokenClassification:()=>e7,EsmModel:()=>e8,EsmPreTrainedModel:()=>e5,ExaoneForCausalLM:()=>nP,ExaoneModel:()=>nx,ExaonePreTrainedModel:()=>nT,FalconForCausalLM:()=>as,FalconModel:()=>ao,FalconPreTrainedModel:()=>an,FastViTForImageClassification:()=>oS,FastViTModel:()=>oC,FastViTPreTrainedModel:()=>ov,Florence2ForConditionalGeneration:()=>rh,Florence2PreTrainedModel:()=>r_,GLPNForDepthEstimation:()=>s$,GLPNModel:()=>sq,GLPNPreTrainedModel:()=>sR,GPT2LMHeadModel:()=>rQ,GPT2Model:()=>rU,GPT2PreTrainedModel:()=>rW,GPTBigCodeForCausalLM:()=>r9,GPTBigCodeModel:()=>r6,GPTBigCodePreTrainedModel:()=>r8,GPTJForCausalLM:()=>r5,GPTJModel:()=>r4,GPTJPreTrainedModel:()=>r3,GPTNeoForCausalLM:()=>rZ,GPTNeoModel:()=>rK,GPTNeoPreTrainedModel:()=>rY,GPTNeoXForCausalLM:()=>r2,GPTNeoXModel:()=>r1,GPTNeoXPreTrainedModel:()=>r0,Gemma2ForCausalLM:()=>nq,Gemma2Model:()=>nR,Gemma2PreTrainedModel:()=>nG,Gemma3ForCausalLM:()=>nU,Gemma3Model:()=>nW,Gemma3PreTrainedModel:()=>n$,Gemma3nForConditionalGeneration:()=>rT,Gemma3nPreTrainedModel:()=>rw,GemmaForCausalLM:()=>nB,GemmaModel:()=>nN,GemmaPreTrainedModel:()=>nO,GlmForCausalLM:()=>nw,GlmModel:()=>nM,GlmPreTrainedModel:()=>ng,GraniteForCausalLM:()=>nD,GraniteModel:()=>nI,GranitePreTrainedModel:()=>nL,GroundingDinoForObjectDetection:()=>ie,GroundingDinoPreTrainedModel:()=>s7,GroupViTModel:()=>oy,GroupViTPreTrainedModel:()=>ok,HeliumForCausalLM:()=>nf,HeliumModel:()=>nh,HeliumPreTrainedModel:()=>n_,HieraForImageClassification:()=>sp,HieraModel:()=>sm,HieraPreTrainedModel:()=>sd,HubertForCTC:()=>iG,HubertForSequenceClassification:()=>iR,HubertModel:()=>iB,HubertPreTrainedModel:()=>iN,IJepaForImageClassification:()=>o_,IJepaModel:()=>op,IJepaPreTrainedModel:()=>om,Idefics3ForConditionalGeneration:()=>rP,Idefics3PreTrainedModel:()=>rx,ImageMattingOutput:()=>cF,JAISLMHeadModel:()=>rJ,JAISModel:()=>rH,JAISPreTrainedModel:()=>rX,JinaCLIPModel:()=>rN,JinaCLIPPreTrainedModel:()=>rO,JinaCLIPTextModel:()=>rB,JinaCLIPVisionModel:()=>rG,Lfm2ForCausalLM:()=>nu,Lfm2Model:()=>nc,Lfm2PreTrainedModel:()=>nl,LiteWhisperForConditionalGeneration:()=>rs,LlamaForCausalLM:()=>no,LlamaModel:()=>nn,LlamaPreTrainedModel:()=>nr,LlavaForConditionalGeneration:()=>rd,LlavaOnevisionForConditionalGeneration:()=>rm,LlavaPreTrainedModel:()=>ru,LlavaQwen2ForCausalLM:()=>rM,LongT5ForConditionalGeneration:()=>ty,LongT5Model:()=>tk,LongT5PreTrainedModel:()=>tF,M2M100ForConditionalGeneration:()=>i_,M2M100Model:()=>ip,M2M100PreTrainedModel:()=>im,MBartForCausalLM:()=>tO,MBartForConditionalGeneration:()=>tj,MBartForSequenceClassification:()=>tV,MBartModel:()=>tz,MBartPreTrainedModel:()=>tD,MPNetForMaskedLM:()=>ta,MPNetForQuestionAnswering:()=>tu,MPNetForSequenceClassification:()=>tl,MPNetForTokenClassification:()=>tc,MPNetModel:()=>ti,MPNetPreTrainedModel:()=>ts,MT5ForConditionalGeneration:()=>tS,MT5Model:()=>tC,MT5PreTrainedModel:()=>tv,MarianMTModel:()=>id,MarianModel:()=>iu,MarianPreTrainedModel:()=>ic,MaskFormerForInstanceSegmentation:()=>sG,MaskFormerModel:()=>sB,MaskFormerPreTrainedModel:()=>sN,MaskedLMOutput:()=>cT,Metric3DForDepthEstimation:()=>sj,Metric3DPreTrainedModel:()=>sz,Metric3Dv2ForDepthEstimation:()=>sO,Metric3Dv2PreTrainedModel:()=>sV,MgpstrForSceneTextRecognition:()=>aX,MgpstrModelOutput:()=>aU,MgpstrPreTrainedModel:()=>aQ,MimiDecoderModel:()=>a7,MimiDecoderOutput:()=>a8,MimiEncoderModel:()=>a9,MimiEncoderOutput:()=>a5,MimiModel:()=>a6,MimiPreTrainedModel:()=>a4,MistralForCausalLM:()=>i8,MistralModel:()=>i5,MistralPreTrainedModel:()=>i4,MobileBertForMaskedLM:()=>tr,MobileBertForQuestionAnswering:()=>to,MobileBertForSequenceClassification:()=>tn,MobileBertModel:()=>tt,MobileBertPreTrainedModel:()=>te,MobileLLMForCausalLM:()=>nk,MobileLLMModel:()=>nF,MobileLLMPreTrainedModel:()=>nb,MobileNetV1ForImageClassification:()=>aC,MobileNetV1ForSemanticSegmentation:()=>aS,MobileNetV1Model:()=>av,MobileNetV1PreTrainedModel:()=>ay,MobileNetV2ForImageClassification:()=>aL,MobileNetV2ForSemanticSegmentation:()=>aI,MobileNetV2Model:()=>aA,MobileNetV2PreTrainedModel:()=>aE,MobileNetV3ForImageClassification:()=>aj,MobileNetV3ForSemanticSegmentation:()=>aV,MobileNetV3Model:()=>az,MobileNetV3PreTrainedModel:()=>aD,MobileNetV4ForImageClassification:()=>aB,MobileNetV4ForSemanticSegmentation:()=>aG,MobileNetV4Model:()=>aN,MobileNetV4PreTrainedModel:()=>aO,MobileViTForImageClassification:()=>oD,MobileViTModel:()=>oI,MobileViTPreTrainedModel:()=>oL,MobileViTV2ForImageClassification:()=>oV,MobileViTV2Model:()=>oj,MobileViTV2PreTrainedModel:()=>oz,ModelOutput:()=>Q,ModernBertDecoderForCausalLM:()=>e_,ModernBertDecoderModel:()=>ep,ModernBertDecoderPreTrainedModel:()=>em,ModernBertForMaskedLM:()=>ec,ModernBertForSequenceClassification:()=>eu,ModernBertForTokenClassification:()=>ed,ModernBertModel:()=>el,ModernBertPreTrainedModel:()=>ea,Moondream1ForConditionalGeneration:()=>rp,MoonshineForConditionalGeneration:()=>rl,MoonshineModel:()=>ra,MoonshinePreTrainedModel:()=>ri,MptForCausalLM:()=>os,MptModel:()=>oo,MptPreTrainedModel:()=>on,MultiModalityCausalLM:()=>aW,MultiModalityPreTrainedModel:()=>a$,MusicgenForCausalLM:()=>aF,MusicgenForConditionalGeneration:()=>ak,MusicgenModel:()=>ab,MusicgenPreTrainedModel:()=>aP,NeoBertForMaskedLM:()=>en,NeoBertForQuestionAnswering:()=>ei,NeoBertForSequenceClassification:()=>eo,NeoBertForTokenClassification:()=>es,NeoBertModel:()=>er,NeoBertPreTrainedModel:()=>et,NomicBertModel:()=>ef,NomicBertPreTrainedModel:()=>eh,OPTForCausalLM:()=>ol,OPTModel:()=>oa,OPTPreTrainedModel:()=>oi,Olmo2ForCausalLM:()=>nA,Olmo2Model:()=>nE,Olmo2PreTrainedModel:()=>nS,OlmoForCausalLM:()=>nC,OlmoModel:()=>nv,OlmoPreTrainedModel:()=>ny,OpenELMForCausalLM:()=>nH,OpenELMModel:()=>nX,OpenELMPreTrainedModel:()=>nQ,OwlViTForObjectDetection:()=>oB,OwlViTModel:()=>oN,OwlViTPreTrainedModel:()=>oO,Owlv2ForObjectDetection:()=>oq,Owlv2Model:()=>oR,Owlv2PreTrainedModel:()=>oG,PaliGemmaForConditionalGeneration:()=>rg,PaliGemmaPreTrainedModel:()=>rf,PatchTSMixerForPrediction:()=>a0,PatchTSMixerModel:()=>aZ,PatchTSMixerPreTrainedModel:()=>aK,PatchTSTForPrediction:()=>aY,PatchTSTModel:()=>aJ,PatchTSTPreTrainedModel:()=>aH,Phi3ForCausalLM:()=>n7,Phi3Model:()=>n9,Phi3PreTrainedModel:()=>n6,Phi3VForCausalLM:()=>rk,Phi3VPreTrainedModel:()=>rF,PhiForCausalLM:()=>n8,PhiModel:()=>n5,PhiPreTrainedModel:()=>n4,PreTrainedModel:()=>U,PretrainedMixin:()=>lu,PvtForImageClassification:()=>ow,PvtModel:()=>oM,PvtPreTrainedModel:()=>og,PyAnnoteForAudioFrameClassification:()=>ib,PyAnnoteModel:()=>iP,PyAnnotePreTrainedModel:()=>ix,QuestionAnsweringModelOutput:()=>cx,Qwen2ForCausalLM:()=>nK,Qwen2Model:()=>nY,Qwen2PreTrainedModel:()=>nJ,Qwen2VLForConditionalGeneration:()=>n3,Qwen2VLPreTrainedModel:()=>n2,Qwen3ForCausalLM:()=>n1,Qwen3Model:()=>n0,Qwen3PreTrainedModel:()=>nZ,RFDetrForObjectDetection:()=>o7,RFDetrModel:()=>o9,RFDetrObjectDetectionOutput:()=>se,RFDetrPreTrainedModel:()=>o6,RTDetrForObjectDetection:()=>o1,RTDetrModel:()=>o0,RTDetrObjectDetectionOutput:()=>o2,RTDetrPreTrainedModel:()=>oZ,RTDetrV2ForObjectDetection:()=>o5,RTDetrV2Model:()=>o4,RTDetrV2ObjectDetectionOutput:()=>o8,RTDetrV2PreTrainedModel:()=>o3,ResNetForImageClassification:()=>sf,ResNetModel:()=>sh,ResNetPreTrainedModel:()=>s_,RoFormerForMaskedLM:()=>ew,RoFormerForQuestionAnswering:()=>eP,RoFormerForSequenceClassification:()=>eT,RoFormerForTokenClassification:()=>ex,RoFormerModel:()=>eM,RoFormerPreTrainedModel:()=>eg,RobertaForMaskedLM:()=>tQ,RobertaForQuestionAnswering:()=>tJ,RobertaForSequenceClassification:()=>tX,RobertaForTokenClassification:()=>tH,RobertaModel:()=>tU,RobertaPreTrainedModel:()=>tW,SamImageSegmentationOutput:()=>il,SamModel:()=>ia,SamPreTrainedModel:()=>ii,SapiensForDepthEstimation:()=>sA,SapiensForNormalEstimation:()=>sL,SapiensForSemanticSegmentation:()=>sE,SapiensPreTrainedModel:()=>sS,SegformerForImageClassification:()=>a_,SegformerForSemanticSegmentation:()=>ah,SegformerModel:()=>ap,SegformerPreTrainedModel:()=>am,Seq2SeqLMOutput:()=>cf,SequenceClassifierOutput:()=>cg,SiglipModel:()=>rI,SiglipPreTrainedModel:()=>rL,SiglipTextModel:()=>rD,SiglipVisionModel:()=>rz,SmolLM3ForCausalLM:()=>np,SmolLM3Model:()=>nm,SmolLM3PreTrainedModel:()=>nd,SmolVLMForConditionalGeneration:()=>rb,SnacDecoderModel:()=>lc,SnacEncoderModel:()=>ll,SnacModel:()=>la,SnacPreTrainedModel:()=>li,SpeechT5ForSpeechToText:()=>iZ,SpeechT5ForTextToSpeech:()=>i0,SpeechT5HifiGan:()=>i1,SpeechT5Model:()=>iK,SpeechT5PreTrainedModel:()=>iY,SqueezeBertForMaskedLM:()=>tp,SqueezeBertForQuestionAnswering:()=>th,SqueezeBertForSequenceClassification:()=>t_,SqueezeBertModel:()=>tm,SqueezeBertPreTrainedModel:()=>td,StableLmForCausalLM:()=>aM,StableLmModel:()=>ag,StableLmPreTrainedModel:()=>af,Starcoder2ForCausalLM:()=>ar,Starcoder2Model:()=>at,Starcoder2PreTrainedModel:()=>ae,StyleTextToSpeech2Model:()=>iJ,StyleTextToSpeech2PreTrainedModel:()=>iH,Swin2SRForImageSuperResolution:()=>sb,Swin2SRModel:()=>sP,Swin2SRPreTrainedModel:()=>sx,SwinForImageClassification:()=>sw,SwinForSemanticSegmentation:()=>sT,SwinModel:()=>sM,SwinPreTrainedModel:()=>sg,T5ForConditionalGeneration:()=>tb,T5Model:()=>tP,T5PreTrainedModel:()=>tx,TableTransformerForObjectDetection:()=>si,TableTransformerModel:()=>ss,TableTransformerObjectDetectionOutput:()=>sa,TableTransformerPreTrainedModel:()=>so,TokenClassifierOutput:()=>cw,TrOCRForCausalLM:()=>i3,TrOCRPreTrainedModel:()=>i2,UltravoxModel:()=>a2,UltravoxPreTrainedModel:()=>a1,UniSpeechForCTC:()=>iC,UniSpeechForSequenceClassification:()=>iS,UniSpeechModel:()=>iv,UniSpeechPreTrainedModel:()=>iy,UniSpeechSatForAudioFrameClassification:()=>iD,UniSpeechSatForCTC:()=>iL,UniSpeechSatForSequenceClassification:()=>iI,UniSpeechSatModel:()=>iA,UniSpeechSatPreTrainedModel:()=>iE,ViTForImageClassification:()=>od,ViTMAEModel:()=>ox,ViTMAEPreTrainedModel:()=>oT,ViTMSNForImageClassification:()=>oF,ViTMSNModel:()=>ob,ViTMSNPreTrainedModel:()=>oP,ViTModel:()=>ou,ViTPreTrainedModel:()=>oc,VisionEncoderDecoderModel:()=>rc,VitMatteForImageMatting:()=>oA,VitMattePreTrainedModel:()=>oE,VitPoseForPoseEstimation:()=>of,VitPosePreTrainedModel:()=>oh,VitsModel:()=>ad,VitsModelOutput:()=>ck,VitsPreTrainedModel:()=>au,VoxtralForConditionalGeneration:()=>a3,Wav2Vec2BertForCTC:()=>iV,Wav2Vec2BertForSequenceClassification:()=>iO,Wav2Vec2BertModel:()=>ij,Wav2Vec2BertPreTrainedModel:()=>iz,Wav2Vec2ForAudioFrameClassification:()=>iT,Wav2Vec2ForCTC:()=>iM,Wav2Vec2ForSequenceClassification:()=>iw,Wav2Vec2Model:()=>ig,Wav2Vec2PreTrainedModel:()=>ih,WavLMForAudioFrameClassification:()=>iX,WavLMForCTC:()=>iW,WavLMForSequenceClassification:()=>iU,WavLMForXVector:()=>iQ,WavLMModel:()=>i$,WavLMPreTrainedModel:()=>iq,WeSpeakerResNetModel:()=>ik,WeSpeakerResNetPreTrainedModel:()=>iF,WhisperForConditionalGeneration:()=>ro,WhisperModel:()=>rn,WhisperPreTrainedModel:()=>rr,XLMForQuestionAnswering:()=>t2,XLMForSequenceClassification:()=>t0,XLMForTokenClassification:()=>t1,XLMModel:()=>tK,XLMPreTrainedModel:()=>tY,XLMRobertaForMaskedLM:()=>t5,XLMRobertaForQuestionAnswering:()=>t9,XLMRobertaForSequenceClassification:()=>t8,XLMRobertaForTokenClassification:()=>t6,XLMRobertaModel:()=>t4,XLMRobertaPreTrainedModel:()=>t3,XLMWithLMHeadModel:()=>tZ,XVectorOutput:()=>cM,YolosForObjectDetection:()=>io,YolosModel:()=>ir,YolosObjectDetectionOutput:()=>is,YolosPreTrainedModel:()=>it});var n=r(/*! ./configs.js */"./src/configs.js"),o=r(/*! ./backends/onnx.js */"./src/backends/onnx.js"),s=r(/*! ./utils/dtypes.js */"./src/utils/dtypes.js"),i=r(/*! ./utils/generic.js */"./src/utils/generic.js"),a=r(/*! ./utils/core.js */"./src/utils/core.js"),l=r(/*! ./utils/hub.js */"./src/utils/hub.js"),c=r(/*! ./utils/constants.js */"./src/utils/constants.js"),u=r(/*! ./generation/logits_process.js */"./src/generation/logits_process.js"),d=r(/*! ./generation/configuration_utils.js */"./src/generation/configuration_utils.js"),m=r(/*! ./utils/tensor.js */"./src/utils/tensor.js"),p=r(/*! ./utils/image.js */"./src/utils/image.js"),_=r(/*! ./utils/maths.js */"./src/utils/maths.js"),h=r(/*! ./generation/stopping_criteria.js */"./src/generation/stopping_criteria.js"),f=r(/*! ./generation/logits_sampler.js */"./src/generation/logits_sampler.js"),g=r(/*! ./env.js */"./src/env.js"),M=r(/*! ./models/whisper/generation_whisper.js */"./src/models/whisper/generation_whisper.js"),w=r(/*! ./models/whisper/common_whisper.js */"./src/models/whisper/common_whisper.js");let T={EncoderOnly:0,EncoderDecoder:1,Seq2Seq:2,Vision2Seq:3,DecoderOnly:4,MaskGeneration:5,ImageTextToText:6,Musicgen:7,MultiModality:8,Phi3V:9,AudioTextToText:10,AutoEncoder:11,ImageAudioTextToText:12},x=new Map,P=new Map,b=new Map;async function F(e,t,r){let i=r.config?.["transformers.js_config"]??{},a=r.device??i.device;a&&"string"!=typeof a&&(a.hasOwnProperty(t)?a=a[t]:(console.warn(`device not specified for "${t}". Using the default device.`),a=null));let c=a??(g.apis.IS_NODE_ENV?"cpu":"wasm"),u=(0,o.deviceToExecutionProviders)(c),d=i.device_config??{};d.hasOwnProperty(c)&&(i={...i,...d[c]});let m=r.dtype??i.dtype;if("string"!=typeof m&&(m&&m.hasOwnProperty(t)?m=m[t]:(m=s.DEFAULT_DEVICE_DTYPE_MAPPING[c]??s.DATA_TYPES.fp32,console.warn(`dtype not specified for "${t}". Using the default dtype (${m}) for this device (${c}).`))),m===s.DATA_TYPES.auto){let e=i.dtype;"string"!=typeof e&&(e=e?.[t]),m=e&&e!==s.DATA_TYPES.auto&&s.DATA_TYPES.hasOwnProperty(e)?e:s.DEFAULT_DEVICE_DTYPE_MAPPING[c]??s.DATA_TYPES.fp32}let p=m;if(s.DEFAULT_DTYPE_SUFFIX_MAPPING.hasOwnProperty(p)){if(p===s.DATA_TYPES.fp16&&"webgpu"===c&&!await (0,s.isWebGpuFp16Supported)())throw Error(`The device (${c}) does not support fp16.`)}else throw Error(`Invalid dtype: ${p}. Should be one of: ${Object.keys(s.DATA_TYPES).join(", ")}`);let _=i.kv_cache_dtype,h=_?"string"==typeof _?_:_[p]??"float32":void 0;if(h&&!["float32","float16"].includes(h))throw Error(`Invalid kv_cache_dtype: ${h}. Should be one of: float32, float16`);let f=s.DEFAULT_DTYPE_SUFFIX_MAPPING[p],M=`${t}${f}.onnx`,w=`${r.subfolder??""}/${M}`,T={...r.session_options};T.executionProviders??=u;let x=i.free_dimension_overrides;x?T.freeDimensionOverrides??=x:c.startsWith("webnn")&&!T.freeDimensionOverrides&&console.warn(`WebNN does not currently support dynamic shapes and requires 'free_dimension_overrides' to be set in config.json, preferably as a field within config["transformers.js_config"]["device_config"]["${c}"]. When 'free_dimension_overrides' is not set, you may experience significant performance degradation.`);let P=g.apis.IS_NODE_ENV&&g.env.useFSCache,b=(0,l.getModelFile)(e,w,!0,r,P),F=r.use_external_data_format??i.use_external_data_format,k=[];if(F){let n=+("object"==typeof F?F.hasOwnProperty(M)?F[M]:!!F.hasOwnProperty(t)&&F[t]:F);if(n>l.MAX_EXTERNAL_DATA_CHUNKS)throw Error(`The number of external data chunks (${n}) exceeds the maximum allowed value (${l.MAX_EXTERNAL_DATA_CHUNKS}).`);for(let t=0;t<n;++t){let n=`${M}_data${0===t?"":"_"+t}`,o=`${r.subfolder??""}/${n}`;k.push(new Promise(async(t,s)=>{let i=await (0,l.getModelFile)(e,o,!0,r,P);t(i instanceof Uint8Array?{path:n,data:i}:n)}))}}else void 0!==T.externalData&&(k=T.externalData.map(async t=>{if("string"==typeof t.data){let n=await (0,l.getModelFile)(e,t.data,!0,r);return{...t,data:n}}return t}));if(k.length>0){let e=await Promise.all(k);g.apis.IS_NODE_ENV||(T.externalData=e)}if("webgpu"===c){let e=(0,n.getCacheShapes)(r.config,{prefix:"present"});if(Object.keys(e).length>0&&!(0,o.isONNXProxy)()){let t={};for(let r in e)t[r]="gpu-buffer";T.preferredOutputLocation=t}}return{buffer_or_path:await b,session_options:T,session_config:{dtype:p,kv_cache_dtype:h,device:c}}}async function k(e,t,r){return Object.fromEntries(await Promise.all(Object.keys(t).map(async n=>{let{buffer_or_path:s,session_options:i,session_config:a}=await F(e,t[n],r);return[n,await (0,o.createInferenceSession)(s,i,a)]})))}async function y(e,t,r){return Object.fromEntries(await Promise.all(Object.keys(t).map(async n=>{let o=await (0,l.getModelJSON)(e,t[n],!1,r);return[n,o]})))}let v=Promise.resolve();async function C(e,t){let r=function(e,t){let r=Object.create(null),n=[];for(let s of e.inputNames){let e=t[s];if(!(e instanceof m.Tensor)){n.push(s);continue}r[s]=(0,o.isONNXProxy)()?e.clone():e}if(n.length>0)throw Error(`An error occurred during model execution: "Missing the following inputs: ${n.join(", ")}.`);let s=Object.keys(t).length,i=e.inputNames.length;if(s>i){let r=Object.keys(t).filter(t=>!e.inputNames.includes(t));console.warn(`WARNING: Too many inputs were provided (${s} > ${i}). The following inputs will be ignored: "${r.join(", ")}".`)}return r}(e,t);try{let t=Object.fromEntries(Object.entries(r).map(([e,t])=>[e,t.ort_tensor])),n=()=>e.run(t),s=await (g.apis.IS_BROWSER_ENV||g.apis.IS_WEBWORKER_ENV?v=v.then(n):n());return function e(t){for(let r in t)(0,o.isONNXTensor)(t[r])?t[r]=new m.Tensor(t[r]):"object"==typeof t[r]&&e(t[r]);return t}(s)}catch(t){let e=Object.fromEntries(Object.entries(r).map(([e,t])=>{let r={type:t.type,dims:t.dims,location:t.location};return"gpu-buffer"!==r.location&&(r.data=t.data),[e,r]}));throw console.error(`An error occurred during model execution: "${t}".`),console.error("Inputs given to model:",e),t}}function S(e){if(e instanceof m.Tensor)return e;if(0===e.length)throw Error("items must be non-empty");if(!Array.isArray(e[0]))return new m.Tensor("int64",BigInt64Array.from(e.map(e=>BigInt(e))),[1,e.length]);if(e.some(t=>t.length!==e[0].length))throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' and/or 'truncation=True' to have batched tensors with the same length.");return new m.Tensor("int64",BigInt64Array.from(e.flat().map(e=>BigInt(e))),[e.length,e[0].length])}function E(e){return new m.Tensor("bool",[e],[1])}async function A(e,t){let{encoder_outputs:r,input_ids:n,decoder_input_ids:o,...s}=t;if(!r){let n=(0,a.pick)(t,e.sessions.model.inputNames);r=(await L(e,n)).last_hidden_state}return s.input_ids=o,s.encoder_hidden_states=r,e.sessions.decoder_model_merged.inputNames.includes("encoder_attention_mask")&&(s.encoder_attention_mask=t.attention_mask),await D(e,s,!0)}async function L(e,t){let r=e.sessions.model,n=(0,a.pick)(t,r.inputNames);if(r.inputNames.includes("inputs_embeds")&&!n.inputs_embeds){if(!t.input_ids)throw Error("Both `input_ids` and `inputs_embeds` are missing in the model inputs.");n.inputs_embeds=await e.encode_text({input_ids:t.input_ids})}if(r.inputNames.includes("token_type_ids")&&!n.token_type_ids){if(!n.input_ids)throw Error("Both `input_ids` and `token_type_ids` are missing in the model inputs.");n.token_type_ids=(0,m.zeros_like)(n.input_ids)}if(r.inputNames.includes("pixel_mask")&&!n.pixel_mask){if(!n.pixel_values)throw Error("Both `pixel_values` and `pixel_mask` are missing in the model inputs.");let e=n.pixel_values.dims;n.pixel_mask=(0,m.ones)([e[0],e[2],e[3]])}return await C(r,n)}async function I(e,t){let r=await e.encode(t);return await e.decode(r)}async function D(e,t,r=!1){let n=e.sessions[r?"decoder_model_merged":"model"],{past_key_values:o,...s}=t;if(n.inputNames.includes("use_cache_branch")&&(s.use_cache_branch=E(!!o)),n.inputNames.includes("position_ids")&&s.attention_mask&&!s.position_ids){let t=["paligemma","gemma3_text","gemma3"].includes(e.config.model_type)?1:0;s.position_ids=function(e,t=null,r=0){let{input_ids:n,inputs_embeds:o,attention_mask:s}=e,{data:i,dims:a}=G(s,r),l=new m.Tensor("int64",i,a);if(t){let e=-(n??o).dims.at(1);l=l.slice(null,[e,null])}return l}(s,o,t)}e.addPastKeyValues(s,o);let i=(0,a.pick)(s,n.inputNames);return await C(n,i)}function z({modality_token_id:e,inputs_embeds:t,modality_features:r,input_ids:n,attention_mask:o}){let s=n.tolist().map(t=>t.reduce((t,r,n)=>(r==e&&t.push(n),t),[])),i=s.reduce((e,t)=>e+t.length,0),a=r.dims[0];if(i!==a)throw Error(`Number of tokens and features do not match: tokens: ${i}, features ${a}`);let l=0;for(let e=0;e<s.length;++e){let n=s[e],o=t[e];for(let e=0;e<n.length;++e)o[n[e]].data.set(r[l++].data)}return{inputs_embeds:t,attention_mask:o}}function j({image_token_id:e,inputs_embeds:t,image_features:r,input_ids:n,attention_mask:o}){return z({modality_token_id:e,inputs_embeds:t,modality_features:r,input_ids:n,attention_mask:o})}function V({audio_token_id:e,inputs_embeds:t,audio_features:r,input_ids:n,attention_mask:o}){return z({modality_token_id:e,inputs_embeds:t,modality_features:r,input_ids:n,attention_mask:o})}async function O(e,{encode_function:t,merge_function:r,modality_input_name:n,modality_output_name:o,input_ids:s=null,attention_mask:i=null,position_ids:a=null,inputs_embeds:l=null,past_key_values:c=null,generation_config:u=null,logits_processor:d=null,...p}){let _=p[n];if(!l){if(l=await e.encode_text({input_ids:s,...p}),_&&1!==s.dims[1]){let e=await t({[n]:_,...p});({inputs_embeds:l,attention_mask:i}=r({[o]:e,inputs_embeds:l,input_ids:s,attention_mask:i}))}else if(c&&_&&1===s.dims[1]){let e=s.dims[1],t=Object.values(c)[0].dims.at(-2);i=(0,m.cat)([(0,m.ones)([s.dims[0],t]),i.slice(null,[i.dims[1]-e,i.dims[1]])],1)}}if(!a&&"qwen2_vl"===e.config.model_type){let{image_grid_thw:t,video_grid_thw:r}=p;[a]=e.get_rope_index(s,t,r,i)}return await D(e,{inputs_embeds:l,past_key_values:c,attention_mask:i,position_ids:a,generation_config:u,logits_processor:d},!0)}async function N(e,t){return await O(e,{...t,modality_input_name:"audio_values",modality_output_name:"audio_features",encode_function:e.encode_audio.bind(e),merge_function:e._merge_input_ids_with_audio_features.bind(e)})}async function B(e,t){return await O(e,{...t,modality_input_name:"pixel_values",modality_output_name:"image_features",encode_function:e.encode_image.bind(e),merge_function:e._merge_input_ids_with_image_features.bind(e)})}function G(e,t=0){let[r,n]=e.dims,o=e.data,s=new BigInt64Array(o.length);for(let e=0;e<r;++e){let r=e*n,i=BigInt(t);for(let e=0;e<n;++e){let t=r+e;0n===o[t]?s[t]=BigInt(1):(s[t]=i,i+=o[t])}}return{data:s,dims:e.dims}}function R(e,t,r,n){let o=r.past_key_values?Object.values(r.past_key_values)[0].dims.at(-2):0;if(!r.attention_mask){let e;for(let t of["input_ids","inputs_embeds","position_ids"])if(r[t]){e=r[t].dims;break}if(!e)throw Error("attention_mask is not provided, and unable to infer its shape from model inputs.");r.attention_mask=(0,m.ones)([e[0],o+e[1]])}if(r.past_key_values){let{input_ids:e,attention_mask:t}=r;t&&t.dims[1]>e.dims[1]||o<e.dims[1]&&(r.input_ids=e.slice(null,[o,null]))}return r}function q(e,t,r,n){return r.past_key_values&&(t=t.map(e=>[e.at(-1)])),{...r,decoder_input_ids:S(t)}}function $(e,...t){return e.config.is_encoder_decoder?q(e,...t):R(e,...t)}function W(e,t,r,n){let o=!!r.past_key_values;return null!==n.guidance_scale&&n.guidance_scale>1&&(o?r.input_ids=(0,m.cat)([r.input_ids,r.input_ids],0):(r.input_ids=(0,m.cat)([r.input_ids,(0,m.full_like)(r.input_ids,BigInt(n.pad_token_id))],0),r.attention_mask=(0,m.cat)([r.attention_mask,(0,m.full_like)(r.attention_mask,0n)],0))),(o||!r.pixel_values)&&(r.pixel_values=(0,m.full)([0,0,3,384,384],1)),o&&(r.images_seq_mask=new m.Tensor("bool",[,].fill(!0).fill(!1,0,1),[1,1]),r.images_emb_mask=new m.Tensor("bool",[].fill(!1),[1,1,0])),r}class U extends i.Callable{main_input_name="input_ids";forward_params=["input_ids","attention_mask"];constructor(e,t,r){super(),this.config=e,this.sessions=t,this.configs=r;let n=b.get(this.constructor),o=x.get(n);switch(this.can_generate=!1,this._forward=null,this._prepare_inputs_for_generation=null,o){case T.DecoderOnly:this.can_generate=!0,this._forward=D,this._prepare_inputs_for_generation=R;break;case T.Seq2Seq:case T.Vision2Seq:case T.Musicgen:this.can_generate=!0,this._forward=A,this._prepare_inputs_for_generation=q;break;case T.EncoderDecoder:this._forward=A;break;case T.ImageTextToText:this.can_generate=!0,this._forward=B,this._prepare_inputs_for_generation=$;break;case T.AudioTextToText:this.can_generate=!0,this._forward=N,this._prepare_inputs_for_generation=$;break;case T.Phi3V:case T.ImageAudioTextToText:this.can_generate=!0,this._prepare_inputs_for_generation=$;break;case T.MultiModality:this.can_generate=!0,this._prepare_inputs_for_generation=W;break;case T.AutoEncoder:this._forward=I;break;default:this._forward=L}this.can_generate&&this.forward_params.push("past_key_values"),this.custom_config=this.config["transformers.js_config"]??{}}async dispose(){let e=[];for(let t of Object.values(this.sessions))t?.handler?.dispose&&e.push(t.handler.dispose());return await Promise.all(e)}static async from_pretrained(e,{progress_callback:t=null,config:r=null,cache_dir:o=null,local_files_only:s=!1,revision:i="main",model_file_name:a=null,subfolder:l="onnx",device:u=null,dtype:d=null,use_external_data_format:m=null,session_options:p={}}={}){let _,h={progress_callback:t,config:r,cache_dir:o,local_files_only:s,revision:i,model_file_name:a,subfolder:l,device:u,dtype:d,use_external_data_format:m,session_options:p},f=b.get(this),g=x.get(f);if(r=h.config=await n.AutoConfig.from_pretrained(e,h),g===T.DecoderOnly)_=await Promise.all([k(e,{model:h.model_file_name??"model"},h),y(e,{generation_config:"generation_config.json"},h)]);else if(g===T.Seq2Seq||g===T.Vision2Seq)_=await Promise.all([k(e,{model:"encoder_model",decoder_model_merged:"decoder_model_merged"},h),y(e,{generation_config:"generation_config.json"},h)]);else if(g===T.MaskGeneration)_=await Promise.all([k(e,{model:"vision_encoder",prompt_encoder_mask_decoder:"prompt_encoder_mask_decoder"},h)]);else if(g===T.EncoderDecoder)_=await Promise.all([k(e,{model:"encoder_model",decoder_model_merged:"decoder_model_merged"},h)]);else if(g===T.ImageTextToText){let t={embed_tokens:"embed_tokens",vision_encoder:"vision_encoder",decoder_model_merged:"decoder_model_merged"};r.is_encoder_decoder&&(t.model="encoder_model"),_=await Promise.all([k(e,t,h),y(e,{generation_config:"generation_config.json"},h)])}else if(g===T.AudioTextToText)_=await Promise.all([k(e,{embed_tokens:"embed_tokens",audio_encoder:"audio_encoder",decoder_model_merged:"decoder_model_merged"},h),y(e,{generation_config:"generation_config.json"},h)]);else if(g===T.ImageAudioTextToText)_=await Promise.all([k(e,{embed_tokens:"embed_tokens",audio_encoder:"audio_encoder",vision_encoder:"vision_encoder",decoder_model_merged:"decoder_model_merged"},h),y(e,{generation_config:"generation_config.json"},h)]);else if(g===T.Musicgen)_=await Promise.all([k(e,{model:"text_encoder",decoder_model_merged:"decoder_model_merged",encodec_decode:"encodec_decode"},h),y(e,{generation_config:"generation_config.json"},h)]);else if(g===T.MultiModality)_=await Promise.all([k(e,{prepare_inputs_embeds:"prepare_inputs_embeds",model:"language_model",lm_head:"lm_head",gen_head:"gen_head",gen_img_embeds:"gen_img_embeds",image_decode:"image_decode"},h),y(e,{generation_config:"generation_config.json"},h)]);else if(g===T.Phi3V)_=await Promise.all([k(e,{prepare_inputs_embeds:"prepare_inputs_embeds",model:"model",vision_encoder:"vision_encoder"},h),y(e,{generation_config:"generation_config.json"},h)]);else if(g===T.AutoEncoder)_=await Promise.all([k(e,{encoder_model:"encoder_model",decoder_model:"decoder_model"},h)]);else{if(g!==T.EncoderOnly){let e=f??r?.model_type;"custom"!==e&&console.warn(`Model type for '${e}' not found, assuming encoder-only architecture. Please report this at ${c.GITHUB_ISSUE_URL}.`)}_=await Promise.all([k(e,{model:h.model_file_name??"model"},h)])}return new this(r,..._)}async _call(e){return await this.forward(e)}async forward(e){return await this._forward(this,e)}get generation_config(){return this.configs?.generation_config??null}_get_logits_warper(e){let t=new u.LogitsProcessorList;return null!==e.temperature&&1!==e.temperature&&t.push(new u.TemperatureLogitsWarper(e.temperature)),null!==e.top_k&&0!==e.top_k&&t.push(new u.TopKLogitsWarper(e.top_k)),null!==e.top_p&&e.top_p<1&&t.push(new u.TopPLogitsWarper(e.top_p)),t}_get_logits_processor(e,t,r=null){let n=new u.LogitsProcessorList;if(null!==e.repetition_penalty&&1!==e.repetition_penalty&&n.push(new u.RepetitionPenaltyLogitsProcessor(e.repetition_penalty)),null!==e.no_repeat_ngram_size&&e.no_repeat_ngram_size>0&&n.push(new u.NoRepeatNGramLogitsProcessor(e.no_repeat_ngram_size)),null!==e.bad_words_ids&&n.push(new u.NoBadWordsLogitsProcessor(e.bad_words_ids,e.eos_token_id)),null!==e.min_length&&null!==e.eos_token_id&&e.min_length>0&&n.push(new u.MinLengthLogitsProcessor(e.min_length,e.eos_token_id)),null!==e.min_new_tokens&&null!==e.eos_token_id&&e.min_new_tokens>0&&n.push(new u.MinNewTokensLengthLogitsProcessor(t,e.min_new_tokens,e.eos_token_id)),null!==e.forced_bos_token_id&&n.push(new u.ForcedBOSTokenLogitsProcessor(e.forced_bos_token_id)),null!==e.forced_eos_token_id&&n.push(new u.ForcedEOSTokenLogitsProcessor(e.max_length,e.forced_eos_token_id)),null!==e.begin_suppress_tokens){let r=t>1||null===e.forced_bos_token_id?t:t+1;n.push(new u.SuppressTokensAtBeginLogitsProcessor(e.begin_suppress_tokens,r))}return null!==e.guidance_scale&&e.guidance_scale>1&&n.push(new u.ClassifierFreeGuidanceLogitsProcessor(e.guidance_scale)),null!==r&&n.extend(r),n}_prepare_generation_config(e,t,r=d.GenerationConfig){let n={...this.config};for(let e of["decoder","generator","text_config"])e in n&&Object.assign(n,n[e]);let o=new r(n);return Object.assign(o,this.generation_config??{}),e&&Object.assign(o,e),t&&Object.assign(o,(0,a.pick)(t,Object.getOwnPropertyNames(o))),o}_get_stopping_criteria(e,t=null){let r=new h.StoppingCriteriaList;return null!==e.max_length&&r.push(new h.MaxLengthCriteria(e.max_length,this.config.max_position_embeddings??null)),null!==e.eos_token_id&&r.push(new h.EosTokenCriteria(e.eos_token_id)),t&&r.extend(t),r}_validate_model_class(){if(!this.can_generate){let e=b.get(this.constructor),t=new Set,r=this.config.model_type;for(let e of[lx,lk,lT,lh]){let n=e.get(r);n&&t.add(n[0])}let n=`The current model class (${e}) is not compatible with \`.generate()\`, as it doesn't have a language model head.`;throw t.size>0&&(n+=` Please use the following class instead: ${[...t].join(", ")}`),Error(n)}}prepare_inputs_for_generation(...e){return this._prepare_inputs_for_generation(this,...e)}_update_model_kwargs_for_generation({generated_input_ids:e,outputs:t,model_inputs:r,is_encoder_decoder:n}){return r.past_key_values=this.getPastKeyValues(t,r.past_key_values),r.input_ids=new m.Tensor("int64",e.flat(),[e.length,1]),n||(r.attention_mask=(0,m.cat)([r.attention_mask,(0,m.ones)([r.attention_mask.dims[0],1])],1)),r.position_ids=null,r}_prepare_model_inputs({inputs:e,bos_token_id:t,model_kwargs:r}){let n=(0,a.pick)(r,this.forward_params),o=this.main_input_name;if(o in n){if(e)throw Error("`inputs`: {inputs}` were passed alongside {input_name} which is not allowed. Make sure to either pass {inputs} or {input_name}=...")}else n[o]=e;return{inputs_tensor:n[o],model_inputs:n,model_input_name:o}}async _prepare_encoder_decoder_kwargs_for_generation({inputs_tensor:e,model_inputs:t,model_input_name:r,generation_config:n}){if(this.sessions.model.inputNames.includes("inputs_embeds")&&!t.inputs_embeds&&"_prepare_inputs_embeds"in this){let{input_ids:e,pixel_values:r,attention_mask:n,...o}=t,s=await this._prepare_inputs_embeds(t);t={...o,...(0,a.pick)(s,["inputs_embeds","attention_mask"])}}let{last_hidden_state:o}=await L(this,t);if(null!==n.guidance_scale&&n.guidance_scale>1)o=(0,m.cat)([o,(0,m.full_like)(o,0)],0),"attention_mask"in t&&(t.attention_mask=(0,m.cat)([t.attention_mask,(0,m.zeros_like)(t.attention_mask)],0));else if(t.decoder_input_ids){let e=S(t.decoder_input_ids).dims[0];if(e!==o.dims[0]){if(1!==o.dims[0])throw Error(`The encoder outputs have a different batch size (${o.dims[0]}) than the decoder inputs (${e}).`);o=(0,m.cat)(Array.from({length:e},()=>o),0)}}return t.encoder_outputs=o,t}_prepare_decoder_input_ids_for_generation({batch_size:e,model_input_name:t,model_kwargs:r,decoder_start_token_id:n,bos_token_id:o,generation_config:s}){let{decoder_input_ids:i,...a}=r;if(!(i instanceof m.Tensor)){if(i)Array.isArray(i[0])||(i=Array.from({length:e},()=>i));else if(n??=o,"musicgen"===this.config.model_type)i=Array.from({length:e*this.config.decoder.num_codebooks},()=>[n]);else if(Array.isArray(n)){if(n.length!==e)throw Error(`\`decoder_start_token_id\` expcted to have length ${e} but got ${n.length}`);i=n}else i=Array.from({length:e},()=>[n]);i=S(i)}return r.decoder_attention_mask=(0,m.ones_like)(i),{input_ids:i,model_inputs:a}}async generate({inputs:e=null,generation_config:t=null,logits_processor:r=null,stopping_criteria:n=null,streamer:o=null,...s}){let i,a;this._validate_model_class(),t=this._prepare_generation_config(t,s);let{inputs_tensor:l,model_inputs:c,model_input_name:u}=this._prepare_model_inputs({inputs:e,model_kwargs:s}),d=this.config.is_encoder_decoder;d&&("encoder_outputs"in c||(c=await this._prepare_encoder_decoder_kwargs_for_generation({inputs_tensor:l,model_inputs:c,model_input_name:u,generation_config:t}))),d?{input_ids:i,model_inputs:c}=this._prepare_decoder_input_ids_for_generation({batch_size:c[u].dims.at(0),model_input_name:u,model_kwargs:c,decoder_start_token_id:t.decoder_start_token_id,bos_token_id:t.bos_token_id,generation_config:t}):i=c[u];let p=i.dims.at(-1);null!==t.max_new_tokens&&(t.max_length=p+t.max_new_tokens);let _=this._get_logits_processor(t,p,r),h=this._get_stopping_criteria(t,n),g=c[u].dims.at(0),M=f.LogitsSampler.getSampler(t),w=Array(g).fill(0),T=i.tolist();o&&o.put(T);let x={};for(;;){if(c=this.prepare_inputs_for_generation(T,c,t),a=await this.forward(c),t.output_attentions&&t.return_dict_in_generate){let e=this.getAttentions(a);for(let t in e)t in x||(x[t]=[]),x[t].push(e[t])}let e=_(T,a.logits.slice(null,-1,null)),r=[];for(let t=0;t<e.dims.at(0);++t){let n=e[t];for(let[e,o]of(await M(n))){let n=BigInt(e);w[t]+=o,T[t].push(n),r.push([n]);break}}if(o&&o.put(r),h(T).every(e=>e))break;c=this._update_model_kwargs_for_generation({generated_input_ids:r,outputs:a,model_inputs:c,is_encoder_decoder:d})}o&&o.end();let P=this.getPastKeyValues(a,c.past_key_values,!0),b=new m.Tensor("int64",T.flat(),[T.length,T[0].length]);if(t.return_dict_in_generate)return{sequences:b,past_key_values:P,...x};for(let e of Object.values(a))"gpu-buffer"===e.location&&e.dispose();return b}getPastKeyValues(e,t,r=!1){let n=Object.create(null);for(let o in e)if(o.startsWith("present")){let s=o.replace("present_conv","past_conv").replace("present","past_key_values"),i=o.includes("encoder");if(i&&t?n[s]=t[s]:n[s]=e[o],t&&(!i||r)){let e=t[s];"gpu-buffer"===e.location&&e.dispose()}}return n}getAttentions(e){let t={};for(let r of["cross_attentions","encoder_attentions","decoder_attentions"])for(let n in e)n.startsWith(r)&&(r in t||(t[r]=[]),t[r].push(e[n]));return t}addPastKeyValues(e,t){if(t)Object.assign(e,t);else{let t=this.sessions.decoder_model_merged??this.sessions.model,r=(e[this.main_input_name]??e.attention_mask)?.dims?.[0]??1,o=t?.config?.kv_cache_dtype??"float32",s="float16"===o?m.DataTypeMap.float16:m.DataTypeMap.float32,i=(0,n.getCacheShapes)(this.config,{batch_size:r});for(let t in i){let r=i[t].reduce((e,t)=>e*t,1);e[t]=new m.Tensor(o,new s(r),i[t])}}}async encode_image({pixel_values:e}){return(await C(this.sessions.vision_encoder,{pixel_values:e})).image_features}async encode_text({input_ids:e}){return(await C(this.sessions.embed_tokens,{input_ids:e})).inputs_embeds}async encode_audio({audio_values:e}){return(await C(this.sessions.audio_encoder,{audio_values:e})).audio_features}}class Q{}class X extends Q{constructor({last_hidden_state:e,hidden_states:t=null,attentions:r=null}){super(),this.last_hidden_state=e,this.hidden_states=t,this.attentions=r}}class H extends U{}class J extends H{}class Y extends H{async _call(e){return new cT(await super._call(e))}}class K extends H{async _call(e){return new cg(await super._call(e))}}class Z extends H{async _call(e){return new cw(await super._call(e))}}class ee extends H{async _call(e){return new cx(await super._call(e))}}class et extends U{}class er extends et{}class en extends et{async _call(e){return new cT(await super._call(e))}}class eo extends et{async _call(e){return new cg(await super._call(e))}}class es extends et{async _call(e){return new cw(await super._call(e))}}class ei extends et{async _call(e){return new cx(await super._call(e))}}class ea extends U{}class el extends ea{}class ec extends ea{async _call(e){return new cT(await super._call(e))}}class eu extends ea{async _call(e){return new cg(await super._call(e))}}class ed extends ea{async _call(e){return new cw(await super._call(e))}}class em extends U{}class ep extends em{}class e_ extends em{}class eh extends U{}class ef extends eh{}class eg extends U{}class eM extends eg{}class ew extends eg{async _call(e){return new cT(await super._call(e))}}class eT extends eg{async _call(e){return new cg(await super._call(e))}}class ex extends eg{async _call(e){return new cw(await super._call(e))}}class eP extends eg{async _call(e){return new cx(await super._call(e))}}class eb extends U{}class eF extends eb{}class ek extends eb{async _call(e){return new cT(await super._call(e))}}class ey extends eb{async _call(e){return new cg(await super._call(e))}}class ev extends eb{async _call(e){return new cw(await super._call(e))}}class eC extends eb{async _call(e){return new cx(await super._call(e))}}class eS extends U{}class eE extends eS{}class eA extends eS{async _call(e){return new cT(await super._call(e))}}class eL extends eS{async _call(e){return new cg(await super._call(e))}}class eI extends eS{async _call(e){return new cw(await super._call(e))}}class eD extends eS{async _call(e){return new cx(await super._call(e))}}class ez extends U{}class ej extends ez{}class eV extends ez{async _call(e){return new cT(await super._call(e))}}class eO extends ez{async _call(e){return new cg(await super._call(e))}}class eN extends ez{async _call(e){return new cw(await super._call(e))}}class eB extends ez{async _call(e){return new cx(await super._call(e))}}class eG extends U{}class eR extends eG{}class eq extends eG{async _call(e){return new cT(await super._call(e))}}class e$ extends eG{async _call(e){return new cg(await super._call(e))}}class eW extends eG{async _call(e){return new cw(await super._call(e))}}class eU extends eG{async _call(e){return new cx(await super._call(e))}}class eQ extends U{}class eX extends eQ{}class eH extends eQ{async _call(e){return new cT(await super._call(e))}}class eJ extends eQ{async _call(e){return new cg(await super._call(e))}}class eY extends eQ{async _call(e){return new cw(await super._call(e))}}class eK extends eQ{async _call(e){return new cx(await super._call(e))}}class eZ extends U{}class e0 extends eZ{}class e1 extends eZ{async _call(e){return new cg(await super._call(e))}}class e2 extends eZ{async _call(e){return new cw(await super._call(e))}}class e3 extends eZ{async _call(e){return new cx(await super._call(e))}}class e4 extends eZ{async _call(e){return new cT(await super._call(e))}}class e5 extends U{}class e8 extends e5{}class e6 extends e5{async _call(e){return new cT(await super._call(e))}}class e9 extends e5{async _call(e){return new cg(await super._call(e))}}class e7 extends e5{async _call(e){return new cw(await super._call(e))}}class te extends U{}class tt extends te{}class tr extends te{async _call(e){return new cT(await super._call(e))}}class tn extends te{async _call(e){return new cg(await super._call(e))}}class to extends te{async _call(e){return new cx(await super._call(e))}}class ts extends U{}class ti extends ts{}class ta extends ts{async _call(e){return new cT(await super._call(e))}}class tl extends ts{async _call(e){return new cg(await super._call(e))}}class tc extends ts{async _call(e){return new cw(await super._call(e))}}class tu extends ts{async _call(e){return new cx(await super._call(e))}}class td extends U{}class tm extends td{}class tp extends td{async _call(e){return new cT(await super._call(e))}}class t_ extends td{async _call(e){return new cg(await super._call(e))}}class th extends td{async _call(e){return new cx(await super._call(e))}}class tf extends U{}class tg extends tf{}class tM extends tf{async _call(e){return new cg(await super._call(e))}}class tw extends tf{async _call(e){return new cx(await super._call(e))}}class tT extends tf{async _call(e){return new cT(await super._call(e))}}class tx extends U{forward_params=["input_ids","attention_mask","encoder_outputs","decoder_input_ids","decoder_attention_mask","past_key_values"]}class tP extends tx{}class tb extends tx{}class tF extends U{}class tk extends tF{}class ty extends tF{}class tv extends U{}class tC extends tv{}class tS extends tv{}class tE extends U{}class tA extends tE{}class tL extends tE{}class tI extends tE{async _call(e){return new cg(await super._call(e))}}class tD extends U{}class tz extends tD{}class tj extends tD{}class tV extends tD{async _call(e){return new cg(await super._call(e))}}class tO extends tD{}class tN extends U{}class tB extends tN{}class tG extends tN{}class tR extends U{}class tq extends tR{}class t$ extends tR{}class tW extends U{}class tU extends tW{}class tQ extends tW{async _call(e){return new cT(await super._call(e))}}class tX extends tW{async _call(e){return new cg(await super._call(e))}}class tH extends tW{async _call(e){return new cw(await super._call(e))}}class tJ extends tW{async _call(e){return new cx(await super._call(e))}}class tY extends U{}class tK extends tY{}class tZ extends tY{async _call(e){return new cT(await super._call(e))}}class t0 extends tY{async _call(e){return new cg(await super._call(e))}}class t1 extends tY{async _call(e){return new cw(await super._call(e))}}class t2 extends tY{async _call(e){return new cx(await super._call(e))}}class t3 extends U{}class t4 extends t3{}class t5 extends t3{async _call(e){return new cT(await super._call(e))}}class t8 extends t3{async _call(e){return new cg(await super._call(e))}}class t6 extends t3{async _call(e){return new cw(await super._call(e))}}class t9 extends t3{async _call(e){return new cx(await super._call(e))}}class t7 extends U{}class re extends t7{}class rt extends t7{}class rr extends U{requires_attention_mask=!1;main_input_name="input_features";forward_params=["input_features","attention_mask","decoder_input_ids","decoder_attention_mask","past_key_values"]}class rn extends rr{}class ro extends rr{_prepare_generation_config(e,t){return super._prepare_generation_config(e,t,M.WhisperGenerationConfig)}_retrieve_init_tokens(e){let t=[e.decoder_start_token_id],r=e.language,n=e.task;if(e.is_multilingual){r||(console.warn("No language specified - defaulting to English (en)."),r="en");let o=(0,w.whisper_language_to_code)(r),s=`<|${o}|>`;t.push(e.lang_to_id[s]),t.push(e.task_to_id[n??"transcribe"])}else if(r||n)throw Error("Cannot specify `task` or `language` for an English-only model. If the model is intended to be multilingual, pass `is_multilingual=true` to generate, or update the generation config.");return!e.return_timestamps&&e.no_timestamps_token_id&&t.at(-1)!==e.no_timestamps_token_id?t.push(e.no_timestamps_token_id):e.return_timestamps&&t.at(-1)===e.no_timestamps_token_id&&(console.warn("<|notimestamps|> prompt token is removed from generation_config since `return_timestamps` is set to `true`."),t.pop()),t.filter(e=>null!=e)}async generate({inputs:e=null,generation_config:t=null,logits_processor:r=null,stopping_criteria:n=null,...o}){t=this._prepare_generation_config(t,o);let s=o.decoder_input_ids??this._retrieve_init_tokens(t);if(t.return_timestamps&&(r??=new u.LogitsProcessorList).push(new u.WhisperTimeStampLogitsProcessor(t,s)),t.begin_suppress_tokens&&(r??=new u.LogitsProcessorList).push(new u.SuppressTokensAtBeginLogitsProcessor(t.begin_suppress_tokens,s.length)),t.return_token_timestamps){if(!t.alignment_heads)throw Error("Model generation config has no `alignment_heads`, token-level timestamps not available. See https://gist.github.com/hollance/42e32852f24243b748ae6bc1f985b13a on how to add this property to the generation config.");"translate"===t.task&&console.warn("Token-level timestamps may not be reliable for task 'translate'."),t.output_attentions=!0,t.return_dict_in_generate=!0}let i=await super.generate({inputs:e,generation_config:t,logits_processor:r,decoder_input_ids:s,...o});return t.return_token_timestamps&&(i.token_timestamps=this._extract_token_timestamps(i,t.alignment_heads,t.num_frames)),i}_extract_token_timestamps(e,t,r=null,n=.02){if(!e.cross_attentions)throw Error("Model outputs must contain cross attentions to extract timestamps. This is most likely because the model was not exported with `output_attentions=True`.");null==r&&console.warn("`num_frames` has not been set, meaning the entire audio will be analyzed. This may lead to inaccurate token-level timestamps for short audios (< 30 seconds).");let o=this.config.median_filter_width;void 0===o&&(console.warn("Model config has no `median_filter_width`, using default value of 7."),o=7);let s=e.cross_attentions,i=Array.from({length:this.config.decoder_layers},(e,t)=>(0,m.cat)(s.map(e=>e[t]),2)),l=(0,m.stack)(t.map(([e,t])=>{if(e>=i.length)throw Error(`Layer index ${e} is out of bounds for cross attentions (length ${i.length}).`);return r?i[e].slice(null,t,null,[0,r]):i[e].slice(null,t)})).transpose(1,0,2,3),[c,u]=(0,m.std_mean)(l,-2,0,!0),d=l.clone();for(let e=0;e<d.dims[0];++e){let t=d[e];for(let r=0;r<t.dims[0];++r){let n=t[r],s=c[e][r][0].data,i=u[e][r][0].data;for(let e=0;e<n.dims[0];++e){let t=n[e].data;for(let e=0;e<t.length;++e)t[e]=(t[e]-i[e])/s[e];t.set((0,_.medianFilter)(t,o))}}}let p=[(0,m.mean)(d,1)],h=e.sequences.dims,f=new m.Tensor("float32",new Float32Array(h[0]*h[1]),h);for(let e=0;e<h[0];++e){let t=p[e].neg().squeeze_(0),[r,o]=(0,_.dynamic_time_warping)(t.tolist()),s=Array.from({length:r.length-1},(e,t)=>r[t+1]-r[t]),i=(0,a.mergeArrays)([1],s).map(e=>!!e),l=[];for(let e=0;e<i.length;++e)i[e]&&l.push(o[e]*n);f[e].data.set(l,1)}return f}}class rs extends ro{}class ri extends U{requires_attention_mask=!1;main_input_name="input_values";forward_params=["input_values","decoder_input_ids","past_key_values"]}class ra extends ri{}class rl extends ri{}class rc extends U{main_input_name="pixel_values";forward_params=["pixel_values","decoder_input_ids","encoder_hidden_states","past_key_values"]}class ru extends U{forward_params=["input_ids","attention_mask","pixel_values","position_ids","past_key_values"]}class rd extends ru{_merge_input_ids_with_image_features(e){let t=e.image_features.dims.at(-1),r=e.image_features.view(-1,t);return j({image_token_id:this.config.image_token_index,...e,image_features:r})}}class rm extends rd{}class rp extends rd{}class r_ extends U{forward_params=["input_ids","inputs_embeds","attention_mask","pixel_values","encoder_outputs","decoder_input_ids","decoder_inputs_embeds","decoder_attention_mask","past_key_values"];main_input_name="inputs_embeds"}class rh extends r_{_merge_input_ids_with_image_features({inputs_embeds:e,image_features:t,input_ids:r,attention_mask:n}){return{inputs_embeds:(0,m.cat)([t,e],1),attention_mask:(0,m.cat)([(0,m.ones)(t.dims.slice(0,2)),n],1)}}async _prepare_inputs_embeds({input_ids:e,pixel_values:t,inputs_embeds:r,attention_mask:n}){let o,s;if(!e&&!t)throw Error("Either `input_ids` or `pixel_values` should be provided.");return e&&(o=await this.encode_text({input_ids:e})),t&&(s=await this.encode_image({pixel_values:t})),o&&s?{inputs_embeds:r,attention_mask:n}=this._merge_input_ids_with_image_features({inputs_embeds:o,image_features:s,input_ids:e,attention_mask:n}):r=o||s,{inputs_embeds:r,attention_mask:n}}async forward({input_ids:e,pixel_values:t,attention_mask:r,decoder_input_ids:n,decoder_attention_mask:o,encoder_outputs:s,past_key_values:i,inputs_embeds:a,decoder_inputs_embeds:l}){if(a||({inputs_embeds:a,attention_mask:r}=await this._prepare_inputs_embeds({input_ids:e,pixel_values:t,inputs_embeds:a,attention_mask:r})),!s){let{last_hidden_state:e}=await L(this,{inputs_embeds:a,attention_mask:r});s=e}if(!l){if(!n)throw Error("Either `decoder_input_ids` or `decoder_inputs_embeds` should be provided.");l=await this.encode_text({input_ids:n})}let c={inputs_embeds:l,attention_mask:o,encoder_attention_mask:r,encoder_hidden_states:s,past_key_values:i};return await D(this,c,!0)}}class rf extends U{forward_params=["input_ids","attention_mask","pixel_values","position_ids","past_key_values"]}class rg extends rf{_merge_input_ids_with_image_features(e){let t=e.image_features.dims.at(-1),r=e.image_features.view(-1,t);return j({image_token_id:this.config.image_token_index,...e,image_features:r})}}class rM extends ru{_merge_input_ids_with_image_features(e){let t=e.image_features.dims.at(-1),r=e.image_features.view(-1,t);return j({image_token_id:this.config.image_token_index,...e,image_features:r})}}class rw extends U{forward_params=["input_ids","attention_mask","inputs_embeds","per_layer_inputs","position_ids","pixel_values","input_features","input_features_mask","past_key_values"]}class rT extends rw{async forward({input_ids:e=null,attention_mask:t=null,pixel_values:r=null,input_features:n=null,input_features_mask:o=null,position_ids:s=null,inputs_embeds:i=null,per_layer_inputs:a=null,past_key_values:l=null,generation_config:c=null,logits_processor:u=null,...d}){if((!i||!a)&&({inputs_embeds:i,per_layer_inputs:a}=await C(this.sessions.embed_tokens,{input_ids:e}),1!==e.dims[1])){if(r){let{image_features:n}=await C(this.sessions.vision_encoder,{pixel_values:r});({inputs_embeds:i,attention_mask:t}=this._merge_input_ids_with_image_features({image_features:n,inputs_embeds:i,input_ids:e,attention_mask:t}))}if(n){let{audio_features:r}=await C(this.sessions.audio_encoder,{input_features:n,input_features_mask:o});({inputs_embeds:i,attention_mask:t}=this._merge_input_ids_with_audio_features({audio_features:r,inputs_embeds:i,input_ids:e,attention_mask:t}))}}return await D(this,{inputs_embeds:i,per_layer_inputs:a,past_key_values:l,attention_mask:t,position_ids:s,generation_config:c,logits_processor:u},!0)}_merge_input_ids_with_image_features(e){let t=e.image_features.dims.at(-1),r=e.image_features.view(-1,t);return j({image_token_id:this.config.image_token_id,...e,image_features:r})}_merge_input_ids_with_audio_features(e){let t=e.audio_features.dims.at(-1),r=e.audio_features.view(-1,t);return V({audio_token_id:this.config.audio_token_id,...e,audio_features:r})}}class rx extends U{forward_params=["input_ids","attention_mask","pixel_values","pixel_attention_mask","position_ids","past_key_values"]}class rP extends rx{async encode_image({pixel_values:e,pixel_attention_mask:t}){return(await C(this.sessions.vision_encoder,{pixel_values:e,pixel_attention_mask:t})).image_features}_merge_input_ids_with_image_features(e){let t=e.image_features.dims.at(-1),r=e.image_features.view(-1,t);return j({image_token_id:this.config.image_token_id,...e,image_features:r})}}class rb extends rP{}class rF extends U{forward_params=["input_ids","inputs_embeds","attention_mask","position_ids","pixel_values","image_sizes","past_key_values"]}class rk extends rF{async forward({input_ids:e=null,attention_mask:t=null,pixel_values:r=null,image_sizes:n=null,position_ids:o=null,inputs_embeds:s=null,past_key_values:i=null,generation_config:a=null,logits_processor:l=null,...c}){if(!s){let t;if(r&&1!==e.dims[1]){if(!n)throw Error("`image_sizes` must be provided when `pixel_values` is provided.");({image_features:t}=await C(this.sessions.vision_encoder,{pixel_values:r,image_sizes:n}))}else{let e=this.config.normalized_config.hidden_size;t=new m.Tensor("float32",[],[0,e])}({inputs_embeds:s}=await C(this.sessions.prepare_inputs_embeds,{input_ids:e,image_features:t}))}return await D(this,{inputs_embeds:s,past_key_values:i,attention_mask:t,position_ids:o,generation_config:a,logits_processor:l},!1)}}class ry extends U{}class rv extends ry{}class rC extends ry{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"text_model"})}}class rS extends ry{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"text_model"})}}class rE extends ry{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"vision_model"})}}class rA extends ry{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"vision_model"})}}class rL extends U{}class rI extends rL{}class rD extends rL{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"text_model"})}}class rz extends ry{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"vision_model"})}}class rj extends U{}class rV extends rj{}class rO extends U{}class rN extends rO{async forward(e){let t=!e.input_ids,r=!e.pixel_values;if(t&&r)throw Error("Either `input_ids` or `pixel_values` should be provided.");if(t&&(e.input_ids=(0,m.ones)([e.pixel_values.dims[0],1])),r){let{image_size:t}=this.config.vision_config;e.pixel_values=(0,m.full)([0,3,t,t],0)}let{text_embeddings:n,image_embeddings:o,l2norm_text_embeddings:s,l2norm_image_embeddings:i}=await super.forward(e),a={};return t||(a.text_embeddings=n,a.l2norm_text_embeddings=s),r||(a.image_embeddings=o,a.l2norm_image_embeddings=i),a}}class rB extends rO{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"text_model"})}}class rG extends rO{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"vision_model"})}}class rR extends U{}class rq extends rR{}class r$ extends rR{}class rW extends U{}class rU extends rW{}class rQ extends rW{}class rX extends U{}class rH extends rX{}class rJ extends rX{}class rY extends U{}class rK extends rY{}class rZ extends rY{}class r0 extends U{}class r1 extends r0{}class r2 extends r0{}class r3 extends U{}class r4 extends r3{}class r5 extends r3{}class r8 extends U{}class r6 extends r8{}class r9 extends r8{}class r7 extends U{}class ne extends r7{}class nt extends r7{}class nr extends U{}class nn extends nr{}class no extends nr{}class ns extends U{}class ni extends ns{}class na extends ns{}class nl extends U{}class nc extends nl{}class nu extends nl{}class nd extends U{}class nm extends nd{}class np extends nd{}class n_ extends U{}class nh extends n_{}class nf extends n_{}class ng extends U{}class nM extends ng{}class nw extends ng{}class nT extends U{}class nx extends nT{}class nP extends nT{}class nb extends U{}class nF extends nb{}class nk extends nb{}class ny extends U{}class nv extends ny{}class nC extends ny{}class nS extends U{}class nE extends nS{}class nA extends nS{}class nL extends U{}class nI extends nL{}class nD extends nL{}class nz extends U{}class nj extends nz{}class nV extends nz{}class nO extends U{}class nN extends nO{}class nB extends nO{}class nG extends U{}class nR extends nG{}class nq extends nG{}class n$ extends U{}class nW extends n${}class nU extends n${}class nQ extends U{}class nX extends nQ{}class nH extends nQ{}class nJ extends U{}class nY extends nJ{}class nK extends nJ{}class nZ extends U{}class n0 extends nZ{}class n1 extends nZ{}class n2 extends U{forward_params=["input_ids","attention_mask","position_ids","past_key_values","pixel_values","image_grid_thw"]}class n3 extends n2{get_rope_index(e,t,r,n){let{vision_config:o,image_token_id:s,video_token_id:i,vision_start_token_id:a}=this.config,l=o.spatial_merge_size??2,c=[];if(t||r){let o=e.tolist();n||(n=(0,m.ones_like)(e));let u=n.tolist(),d=Array.from({length:3},t=>Array.from({length:e.dims[0]},t=>Array.from({length:e.dims[1]},e=>1))),p=t?t.tolist():[],h=r?r.tolist():[],f=0,g=0;for(let e=0;e<o.length;++e){let t=o[e].filter((t,r)=>1==u[e][r]),r=t.reduce((e,t,r)=>(t==a&&e.push(r),e),[]).map(e=>t[e+1]),n=r.filter(e=>e==s).length,m=r.filter(e=>e==i).length,M=[],w=0,T=n,x=m;for(let e=0;e<r.length;++e){let e,r,n,o;let a=t.findIndex((e,t)=>t>w&&e==s),c=t.findIndex((e,t)=>t>w&&e==i),u=T>0&&-1!==a?a:t.length+1,d=x>0&&-1!==c?c:t.length+1;u<d?([r,n,o]=p[f],++f,--T,e=u):([r,n,o]=h[g],++g,--x,e=d);let[m,P,b]=[Number(r),Math.floor(Number(n)/l),Math.floor(Number(o)/l)],F=e-w,k=M.length>0?(0,_.max)(M.at(-1))[0]+1:0;M.push(Array.from({length:3*F},(e,t)=>k+t%F));let y=F+k,v=m*P*b,C=Array.from({length:v},(e,t)=>y+Math.floor(t/(P*b))),S=Array.from({length:v},(e,t)=>y+Math.floor(t/b)%P),E=Array.from({length:v},(e,t)=>y+t%b);M.push([C,S,E].flat()),w=e+v}if(w<t.length){let e=M.length>0?(0,_.max)(M.at(-1))[0]+1:0,r=t.length-w;M.push(Array.from({length:3*r},(t,n)=>e+n%r))}let P=M.reduce((e,t)=>e+t.length,0),b=Array(P),F=0;for(let e=0;e<3;++e)for(let t=0;t<M.length;++t){let r=M[t],n=r.length/3;for(let t=e*n;t<(e+1)*n;++t)b[F++]=r[t]}let k=0,y=u[e];for(let t=0;t<y.length;++t)if(1==y[t]){for(let r=0;r<3;++r)d[r][e][t]=b[r*P/3+k];++k}let v=(0,_.max)(b)[0];c.push(v+1-o[e].length)}return[new m.Tensor("int64",d.flat(1/0),[3,e.dims[0],e.dims[1]]),new m.Tensor("int64",c,[c.length,1])]}if(n){let{data:e,dims:t}=G(n),r=BigInt64Array.from({length:3*e.length},(t,r)=>e[r%e.length]),o=Array.from({length:t[0]},(r,n)=>(0,_.max)(e.subarray(t[1]*n,t[1]*(n+1)))[0]+1n+BigInt(t[1]));return[new m.Tensor("int64",r,[3,...t]),new m.Tensor("int64",o,[o.length,1])]}{let[t,r]=e.dims,n=BigInt64Array.from({length:3*t*r},(e,n)=>BigInt(Math.floor(n%r/t)));return[new m.Tensor("int64",n,[3,...e.dims]),(0,m.zeros)([t,1])]}}async encode_image({pixel_values:e,image_grid_thw:t}){return(await C(this.sessions.vision_encoder,{pixel_values:e,grid_thw:t})).image_features}_merge_input_ids_with_image_features(e){return j({image_token_id:this.config.image_token_id,...e})}prepare_inputs_for_generation(e,t,r){if(t.attention_mask&&!t.position_ids){if(t.past_key_values){t.pixel_values=null;let e=BigInt(Object.values(t.past_key_values)[0].dims.at(-2)),r=t.rope_deltas.map(t=>e+t);t.position_ids=(0,m.stack)([r,r,r],0)}else[t.position_ids,t.rope_deltas]=this.get_rope_index(t.input_ids,t.image_grid_thw,t.video_grid_thw,t.attention_mask)}return t}}class n4 extends U{}class n5 extends n4{}class n8 extends n4{}class n6 extends U{}class n9 extends n6{}class n7 extends n6{}class oe extends U{}class ot extends oe{}class or extends oe{}class on extends U{}class oo extends on{}class os extends on{}class oi extends U{}class oa extends oi{}class ol extends oi{}class oc extends U{}class ou extends oc{}class od extends oc{async _call(e){return new cg(await super._call(e))}}class om extends U{}class op extends om{}class o_ extends om{async _call(e){return new cg(await super._call(e))}}class oh extends U{}class of extends oh{}class og extends U{}class oM extends og{}class ow extends og{async _call(e){return new cg(await super._call(e))}}class oT extends U{}class ox extends oT{}class oP extends U{}class ob extends oP{}class oF extends oP{async _call(e){return new cg(await super._call(e))}}class ok extends U{}class oy extends ok{}class ov extends U{}class oC extends ov{}class oS extends ov{async _call(e){return new cg(await super._call(e))}}class oE extends U{}class oA extends oE{async _call(e){return new cF(await super._call(e))}}class oL extends U{}class oI extends oL{}class oD extends oL{async _call(e){return new cg(await super._call(e))}}class oz extends U{}class oj extends oz{}class oV extends oz{async _call(e){return new cg(await super._call(e))}}class oO extends U{}class oN extends oO{}class oB extends oO{}class oG extends U{}class oR extends oG{}class oq extends oG{}class o$ extends U{}class oW extends o${}class oU extends o${async _call(e){return new cg(await super._call(e))}}class oQ extends U{}class oX extends oQ{}class oH extends oQ{async _call(e){return new oY(await super._call(e))}}class oJ extends oQ{async _call(e){return new oK(await super._call(e))}}class oY extends Q{constructor({logits:e,pred_boxes:t}){super(),this.logits=e,this.pred_boxes=t}}class oK extends Q{constructor({logits:e,pred_boxes:t,pred_masks:r}){super(),this.logits=e,this.pred_boxes=t,this.pred_masks=r}}class oZ extends U{}class o0 extends oZ{}class o1 extends oZ{async _call(e){return new o2(await super._call(e))}}class o2 extends Q{constructor({logits:e,pred_boxes:t}){super(),this.logits=e,this.pred_boxes=t}}class o3 extends U{}class o4 extends o3{}class o5 extends o3{async _call(e){return new o8(await super._call(e))}}class o8 extends o2{}class o6 extends U{}class o9 extends o6{}class o7 extends o6{async _call(e){return new se(await super._call(e))}}class se extends o2{}class st extends U{}class sr extends st{}class sn extends st{async _call(e){return new o2(await super._call(e))}}class so extends U{}class ss extends so{}class si extends so{async _call(e){return new sa(await super._call(e))}}class sa extends oY{}class sl extends U{}class sc extends sl{}class su extends sl{async _call(e){return new cg(await super._call(e))}}class sd extends U{}class sm extends sd{}class sp extends sd{async _call(e){return new cg(await super._call(e))}}class s_ extends U{}class sh extends s_{}class sf extends s_{async _call(e){return new cg(await super._call(e))}}class sg extends U{}class sM extends sg{}class sw extends sg{async _call(e){return new cg(await super._call(e))}}class sT extends sg{}class sx extends U{}class sP extends sx{}class sb extends sx{}class sF extends U{}class sk extends sF{}class sy extends sF{}class sv extends U{}class sC extends sv{}class sS extends U{}class sE extends sS{}class sA extends sS{}class sL extends sS{}class sI extends U{}class sD extends sI{}class sz extends U{}class sj extends sz{}class sV extends U{}class sO extends sV{}class sN extends U{}class sB extends sN{}class sG extends sN{}class sR extends U{}class sq extends sR{}class s$ extends sR{}class sW extends U{}class sU extends sW{}class sQ extends U{}class sX extends sQ{}class sH extends sQ{async _call(e){return new cg(await super._call(e))}}class sJ extends U{}class sY extends sJ{}class sK extends sJ{async _call(e){return new cg(await super._call(e))}}class sZ extends U{}class s0 extends sZ{}class s1 extends sZ{async _call(e){return new cg(await super._call(e))}}class s2 extends U{}class s3 extends s2{}class s4 extends s2{async _call(e){return new cg(await super._call(e))}}class s5 extends U{}class s8 extends s5{}class s6 extends U{}class s9 extends s6{}class s7 extends U{}class ie extends s7{}class it extends U{}class ir extends it{}class io extends it{async _call(e){return new is(await super._call(e))}}class is extends Q{constructor({logits:e,pred_boxes:t}){super(),this.logits=e,this.pred_boxes=t}}class ii extends U{}class ia extends ii{async get_image_embeddings({pixel_values:e}){return await L(this,{pixel_values:e})}async forward(e){if(e.image_embeddings&&e.image_positional_embeddings||(e={...e,...await this.get_image_embeddings(e)}),!e.input_labels&&e.input_points){let t=e.input_points.dims.slice(0,-1),r=t.reduce((e,t)=>e*t,1);e.input_labels=new m.Tensor("int64",new BigInt64Array(r).fill(1n),t)}let t={image_embeddings:e.image_embeddings,image_positional_embeddings:e.image_positional_embeddings};return e.input_points&&(t.input_points=e.input_points),e.input_labels&&(t.input_labels=e.input_labels),e.input_boxes&&(t.input_boxes=e.input_boxes),await C(this.sessions.prompt_encoder_mask_decoder,t)}async _call(e){return new il(await super._call(e))}}class il extends Q{constructor({iou_scores:e,pred_masks:t}){super(),this.iou_scores=e,this.pred_masks=t}}class ic extends U{}class iu extends ic{}class id extends ic{}class im extends U{}class ip extends im{}class i_ extends im{}class ih extends U{}class ig extends ih{}class iM extends ih{async _call(e){return new cP(await super._call(e))}}class iw extends ih{async _call(e){return new cg(await super._call(e))}}class iT extends ih{async _call(e){return new cw(await super._call(e))}}class ix extends U{}class iP extends ix{}class ib extends ix{async _call(e){return new cw(await super._call(e))}}class iF extends U{}class ik extends iF{}class iy extends U{}class iv extends iy{}class iC extends iy{async _call(e){return new cP(await super._call(e))}}class iS extends iy{async _call(e){return new cg(await super._call(e))}}class iE extends U{}class iA extends iE{}class iL extends iE{async _call(e){return new cP(await super._call(e))}}class iI extends iE{async _call(e){return new cg(await super._call(e))}}class iD extends iE{async _call(e){return new cw(await super._call(e))}}class iz extends U{}class ij extends iz{}class iV extends iz{async _call(e){return new cP(await super._call(e))}}class iO extends iz{async _call(e){return new cg(await super._call(e))}}class iN extends U{}class iB extends ih{}class iG extends ih{async _call(e){return new cP(await super._call(e))}}class iR extends ih{async _call(e){return new cg(await super._call(e))}}class iq extends U{}class i$ extends iq{}class iW extends iq{async _call(e){return new cP(await super._call(e))}}class iU extends iq{async _call(e){return new cg(await super._call(e))}}class iQ extends iq{async _call(e){return new cM(await super._call(e))}}class iX extends iq{async _call(e){return new cw(await super._call(e))}}class iH extends U{}class iJ extends iH{}class iY extends U{}class iK extends iY{}class iZ extends iY{}class i0 extends iY{async generate_speech(e,t,{threshold:r=.5,minlenratio:n=0,maxlenratio:o=20,vocoder:s=null}={}){let{encoder_outputs:i,encoder_attention_mask:a}=await L(this,{input_ids:e}),l=i.dims[1]/this.config.reduction_factor,c=Math.floor(l*o),u=Math.floor(l*n),d=this.config.num_mel_bins,p=[],_=null,h=null,f=0;for(;;){++f;let e={use_cache_branch:E(!!h),output_sequence:h?h.output_sequence_out:new m.Tensor("float32",new Float32Array(d),[1,1,d]),encoder_attention_mask:a,speaker_embeddings:t,encoder_hidden_states:i};this.addPastKeyValues(e,_),h=await C(this.sessions.decoder_model_merged,e),_=this.getPastKeyValues(h,_);let{prob:n,spectrum:o}=h;if(p.push(o),f>=u&&(Array.from(n.data).filter(e=>e>=r).length>0||f>=c))break}let g=(0,m.cat)(p),{waveform:M}=await C(s.sessions.model,{spectrogram:g});return{spectrogram:g,waveform:M}}}class i1 extends U{main_input_name="spectrogram"}class i2 extends U{}class i3 extends i2{}class i4 extends U{}class i5 extends i4{}class i8 extends i4{}class i6 extends U{}class i9 extends i6{}class i7 extends i6{}class ae extends U{}class at extends ae{}class ar extends ae{}class an extends U{}class ao extends an{}class as extends an{}class ai extends U{}class aa extends ai{}class al extends ai{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"text_model"})}}class ac extends ai{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"audio_model"})}}class au extends U{}class ad extends au{async _call(e){return new ck(await super._call(e))}}class am extends U{}class ap extends am{}class a_ extends am{}class ah extends am{}class af extends U{}class ag extends af{}class aM extends af{}class aw extends U{}class aT extends aw{}class ax extends aw{async _call(e){return new cg(await super._call(e))}}class aP extends U{}class ab extends aP{}class aF extends aP{}class ak extends U{forward_params=["input_ids","attention_mask","encoder_outputs","decoder_input_ids","decoder_attention_mask","past_key_values"];_apply_and_filter_by_delay_pattern_mask(e){let[t,r]=e.dims,n=this.config.decoder.num_codebooks,o=r-n,s=0;for(let t=0;t<e.size;++t){if(e.data[t]===this.config.decoder.pad_token_id)continue;let i=t%r-Math.floor(t/r)%n;i>0&&i<=o&&(e.data[s++]=e.data[t])}let i=Math.floor(t/n),a=s/(i*n);return new m.Tensor(e.type,e.data.slice(0,s),[i,n,a])}prepare_inputs_for_generation(e,t,r){let n=structuredClone(e);for(let e=0;e<n.length;++e)for(let t=0;t<n[e].length;++t)e%this.config.decoder.num_codebooks>=t&&(n[e][t]=BigInt(this.config.decoder.pad_token_id));return null!==r.guidance_scale&&r.guidance_scale>1&&(n=n.concat(n)),super.prepare_inputs_for_generation(n,t,r)}async generate(e){let t=await super.generate(e),r=this._apply_and_filter_by_delay_pattern_mask(t).unsqueeze_(0),{audio_values:n}=await C(this.sessions.encodec_decode,{audio_codes:r});return n}}class ay extends U{}class av extends ay{}class aC extends ay{async _call(e){return new cg(await super._call(e))}}class aS extends ay{}class aE extends U{}class aA extends aE{}class aL extends aE{async _call(e){return new cg(await super._call(e))}}class aI extends aE{}class aD extends U{}class az extends aD{}class aj extends aD{async _call(e){return new cg(await super._call(e))}}class aV extends aD{}class aO extends U{}class aN extends aO{}class aB extends aO{async _call(e){return new cg(await super._call(e))}}class aG extends aO{}class aR extends U{}class aq extends aR{}class a$ extends U{}class aW extends a${forward_params=["input_ids","pixel_values","images_seq_mask","images_emb_mask","attention_mask","position_ids","past_key_values"];constructor(...e){super(...e),this._generation_mode="text"}async forward(e){let t;let r=this._generation_mode??"text";if("text"!==r&&e.past_key_values){let r=this.sessions.gen_img_embeds,n=(0,a.pick)({image_ids:e.input_ids},r.inputNames);t=await C(r,n)}else{let r=this.sessions.prepare_inputs_embeds,n=(0,a.pick)(e,r.inputNames);t=await C(r,n)}let n={...e,...t},o=await D(this,n),s=this.sessions["text"===r?"lm_head":"gen_head"];if(!s)throw Error(`Unable to find "${s}" generation head`);let i=await C(s,(0,a.pick)(o,s.inputNames));return{...t,...o,...i}}async generate(e){return this._generation_mode="text",super.generate(e)}async generate_images(e){this._generation_mode="image";let t=(e.inputs??e[this.main_input_name]).dims[1],r=(await super.generate(e)).slice(null,[t,null]),n=this.sessions.image_decode,{decoded_image:o}=await C(n,{generated_tokens:r}),s=o.add_(1).mul_(127.5).clamp_(0,255).to("uint8"),i=[];for(let e of s){let t=p.RawImage.fromTensor(e);i.push(t)}return i}}class aU extends Q{constructor({char_logits:e,bpe_logits:t,wp_logits:r}){super(),this.char_logits=e,this.bpe_logits=t,this.wp_logits=r}get logits(){return[this.char_logits,this.bpe_logits,this.wp_logits]}}class aQ extends U{}class aX extends aQ{async _call(e){return new aU(await super._call(e))}}class aH extends U{}class aJ extends aH{}class aY extends aH{}class aK extends U{}class aZ extends aK{}class a0 extends aK{}class a1 extends U{forward_params=["input_ids","attention_mask","position_ids","audio_values","past_key_values"]}class a2 extends a1{_merge_input_ids_with_audio_features(e){let t=e.audio_features.dims.at(-1),r=e.audio_features.view(-1,t);return V({audio_token_id:this.config.ignore_index??this.config.audio_token_id,...e,audio_features:r})}}class a3 extends a2{}class a4 extends U{main_input_name="input_values";forward_params=["input_values"]}class a5 extends Q{constructor({audio_codes:e}){super(),this.audio_codes=e}}class a8 extends Q{constructor({audio_values:e}){super(),this.audio_values=e}}class a6 extends a4{async encode(e){return new a5(await C(this.sessions.encoder_model,e))}async decode(e){return new a8(await C(this.sessions.decoder_model,e))}}class a9 extends a4{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"encoder_model"})}}class a7 extends a4{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"decoder_model"})}}class le extends U{main_input_name="input_values";forward_params=["input_values"]}class lt extends Q{constructor({audio_codes:e}){super(),this.audio_codes=e}}class lr extends Q{constructor({audio_values:e}){super(),this.audio_values=e}}class ln extends le{async encode(e){return new lt(await C(this.sessions.encoder_model,e))}async decode(e){return new lr(await C(this.sessions.decoder_model,e))}}class lo extends le{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"encoder_model"})}}class ls extends le{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"decoder_model"})}}class li extends U{main_input_name="input_values";forward_params=["input_values"]}class la extends li{async encode(e){return await C(this.sessions.encoder_model,e)}async decode(e){return await C(this.sessions.decoder_model,e)}}class ll extends li{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"encoder_model"})}}class lc extends li{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"decoder_model"})}}class lu{static MODEL_CLASS_MAPPINGS=null;static BASE_IF_FAIL=!1;static async from_pretrained(e,{progress_callback:t=null,config:r=null,cache_dir:o=null,local_files_only:s=!1,revision:i="main",model_file_name:a=null,subfolder:l="onnx",device:c=null,dtype:u=null,use_external_data_format:d=null,session_options:m={}}={}){let p={progress_callback:t,config:r,cache_dir:o,local_files_only:s,revision:i,model_file_name:a,subfolder:l,device:c,dtype:u,use_external_data_format:d,session_options:m};if(p.config=await n.AutoConfig.from_pretrained(e,p),!this.MODEL_CLASS_MAPPINGS)throw Error("`MODEL_CLASS_MAPPINGS` not implemented for this type of `AutoClass`: "+this.name);let _=p.config.model_type;for(let t of this.MODEL_CLASS_MAPPINGS){let r=t.get(_);if(!r){for(let e of t.values())if(e[0]===_){r=e;break}if(!r)continue}return await r[1].from_pretrained(e,p)}if(this.BASE_IF_FAIL)return lX.has(_)||console.warn(`Unknown model class "${_}", attempting to construct from base class.`),await U.from_pretrained(e,p);throw Error(`Unsupported model type: ${_}`)}}let ld=new Map([["bert",["BertModel",J]],["neobert",["NeoBertModel",er]],["modernbert",["ModernBertModel",el]],["nomic_bert",["NomicBertModel",ef]],["roformer",["RoFormerModel",eM]],["electra",["ElectraModel",eE]],["esm",["EsmModel",e8]],["convbert",["ConvBertModel",eF]],["camembert",["CamembertModel",ej]],["deberta",["DebertaModel",eR]],["deberta-v2",["DebertaV2Model",eX]],["mpnet",["MPNetModel",ti]],["albert",["AlbertModel",tg]],["distilbert",["DistilBertModel",e0]],["roberta",["RobertaModel",tU]],["xlm",["XLMModel",tK]],["xlm-roberta",["XLMRobertaModel",t4]],["clap",["ClapModel",aa]],["clip",["CLIPModel",rv]],["clipseg",["CLIPSegModel",rq]],["chinese_clip",["ChineseCLIPModel",rV]],["siglip",["SiglipModel",rI]],["jina_clip",["JinaCLIPModel",rN]],["mobilebert",["MobileBertModel",tt]],["squeezebert",["SqueezeBertModel",tm]],["wav2vec2",["Wav2Vec2Model",ig]],["wav2vec2-bert",["Wav2Vec2BertModel",ij]],["unispeech",["UniSpeechModel",iv]],["unispeech-sat",["UniSpeechSatModel",iA]],["hubert",["HubertModel",iB]],["wavlm",["WavLMModel",i$]],["audio-spectrogram-transformer",["ASTModel",re]],["vits",["VitsModel",ad]],["pyannote",["PyAnnoteModel",iP]],["wespeaker-resnet",["WeSpeakerResNetModel",ik]],["detr",["DetrModel",oX]],["rt_detr",["RTDetrModel",o0]],["rt_detr_v2",["RTDetrV2Model",o4]],["rf_detr",["RFDetrModel",o9]],["d_fine",["DFineModel",sr]],["table-transformer",["TableTransformerModel",ss]],["vit",["ViTModel",ou]],["ijepa",["IJepaModel",op]],["pvt",["PvtModel",oM]],["vit_msn",["ViTMSNModel",ob]],["vit_mae",["ViTMAEModel",ox]],["groupvit",["GroupViTModel",oy]],["fastvit",["FastViTModel",oC]],["mobilevit",["MobileViTModel",oI]],["mobilevitv2",["MobileViTV2Model",oj]],["owlvit",["OwlViTModel",oN]],["owlv2",["Owlv2Model",oR]],["beit",["BeitModel",oW]],["deit",["DeiTModel",sc]],["hiera",["HieraModel",sm]],["convnext",["ConvNextModel",sX]],["convnextv2",["ConvNextV2Model",sY]],["dinov2",["Dinov2Model",s0]],["dinov2_with_registers",["Dinov2WithRegistersModel",s3]],["dinov3_vit",["DINOv3ViTModel",s8]],["dinov3_convnext",["DINOv3ConvNextModel",s9]],["resnet",["ResNetModel",sh]],["swin",["SwinModel",sM]],["swin2sr",["Swin2SRModel",sP]],["donut-swin",["DonutSwinModel",sU]],["yolos",["YolosModel",ir]],["dpt",["DPTModel",sk]],["glpn",["GLPNModel",sq]],["hifigan",["SpeechT5HifiGan",i1]],["efficientnet",["EfficientNetModel",aT]],["decision_transformer",["DecisionTransformerModel",aq]],["patchtst",["PatchTSTForPrediction",aJ]],["patchtsmixer",["PatchTSMixerForPrediction",aZ]],["mobilenet_v1",["MobileNetV1Model",av]],["mobilenet_v2",["MobileNetV2Model",aA]],["mobilenet_v3",["MobileNetV3Model",az]],["mobilenet_v4",["MobileNetV4Model",aN]],["maskformer",["MaskFormerModel",sB]],["mgp-str",["MgpstrForSceneTextRecognition",aX]],["style_text_to_speech_2",["StyleTextToSpeech2Model",iJ]]]),lm=new Map([["t5",["T5Model",tP]],["longt5",["LongT5Model",tk]],["mt5",["MT5Model",tC]],["bart",["BartModel",tA]],["mbart",["MBartModel",tz]],["marian",["MarianModel",iu]],["whisper",["WhisperModel",rn]],["m2m_100",["M2M100Model",ip]],["blenderbot",["BlenderbotModel",tB]],["blenderbot-small",["BlenderbotSmallModel",tq]]]),lp=new Map([["mimi",["MimiModel",a6]],["dac",["DacModel",ln]],["snac",["SnacModel",la]]]),l_=new Map([["bloom",["BloomModel",ot]],["jais",["JAISModel",rH]],["gpt2",["GPT2Model",rU]],["gptj",["GPTJModel",r4]],["gpt_bigcode",["GPTBigCodeModel",r6]],["gpt_neo",["GPTNeoModel",rK]],["gpt_neox",["GPTNeoXModel",r1]],["codegen",["CodeGenModel",ne]],["llama",["LlamaModel",nn]],["arcee",["ArceeModel",ni]],["lfm2",["Lfm2Model",nc]],["smollm3",["SmolLM3Model",nm]],["exaone",["ExaoneModel",nx]],["olmo",["OlmoModel",nv]],["olmo2",["Olmo2Model",nE]],["mobilellm",["MobileLLMModel",nF]],["granite",["GraniteModel",nI]],["cohere",["CohereModel",nj]],["gemma",["GemmaModel",nN]],["gemma2",["Gemma2Model",nR]],["gemma3_text",["Gemma3Model",nW]],["helium",["HeliumModel",nh]],["glm",["GlmModel",nM]],["openelm",["OpenELMModel",nX]],["qwen2",["Qwen2Model",nY]],["qwen3",["Qwen3Model",n0]],["phi",["PhiModel",n5]],["phi3",["Phi3Model",n9]],["mpt",["MptModel",oo]],["opt",["OPTModel",oa]],["mistral",["MistralModel",i5]],["ernie4_5",["Ernie4_5_Model",i9]],["starcoder2",["Starcoder2Model",at]],["falcon",["FalconModel",ao]],["stablelm",["StableLmModel",ag]],["modernbert-decoder",["ModernBertDecoderModel",ep]]]),lh=new Map([["speecht5",["SpeechT5ForSpeechToText",iZ]],["whisper",["WhisperForConditionalGeneration",ro]],["lite-whisper",["LiteWhisperForConditionalGeneration",rs]],["moonshine",["MoonshineForConditionalGeneration",rl]]]),lf=new Map([["speecht5",["SpeechT5ForTextToSpeech",i0]]]),lg=new Map([["vits",["VitsModel",ad]],["musicgen",["MusicgenForConditionalGeneration",ak]]]),lM=new Map([["bert",["BertForSequenceClassification",K]],["neobert",["NeoBertForSequenceClassification",eo]],["modernbert",["ModernBertForSequenceClassification",eu]],["roformer",["RoFormerForSequenceClassification",eT]],["electra",["ElectraForSequenceClassification",eL]],["esm",["EsmForSequenceClassification",e9]],["convbert",["ConvBertForSequenceClassification",ey]],["camembert",["CamembertForSequenceClassification",eO]],["deberta",["DebertaForSequenceClassification",e$]],["deberta-v2",["DebertaV2ForSequenceClassification",eJ]],["mpnet",["MPNetForSequenceClassification",tl]],["albert",["AlbertForSequenceClassification",tM]],["distilbert",["DistilBertForSequenceClassification",e1]],["roberta",["RobertaForSequenceClassification",tX]],["xlm",["XLMForSequenceClassification",t0]],["xlm-roberta",["XLMRobertaForSequenceClassification",t8]],["bart",["BartForSequenceClassification",tI]],["mbart",["MBartForSequenceClassification",tV]],["mobilebert",["MobileBertForSequenceClassification",tn]],["squeezebert",["SqueezeBertForSequenceClassification",t_]]]),lw=new Map([["bert",["BertForTokenClassification",Z]],["neobert",["NeoBertForTokenClassification",es]],["modernbert",["ModernBertForTokenClassification",ed]],["roformer",["RoFormerForTokenClassification",ex]],["electra",["ElectraForTokenClassification",eI]],["esm",["EsmForTokenClassification",e7]],["convbert",["ConvBertForTokenClassification",ev]],["camembert",["CamembertForTokenClassification",eN]],["deberta",["DebertaForTokenClassification",eW]],["deberta-v2",["DebertaV2ForTokenClassification",eY]],["mpnet",["MPNetForTokenClassification",tc]],["distilbert",["DistilBertForTokenClassification",e2]],["roberta",["RobertaForTokenClassification",tH]],["xlm",["XLMForTokenClassification",t1]],["xlm-roberta",["XLMRobertaForTokenClassification",t6]]]),lT=new Map([["t5",["T5ForConditionalGeneration",tb]],["longt5",["LongT5ForConditionalGeneration",ty]],["mt5",["MT5ForConditionalGeneration",tS]],["bart",["BartForConditionalGeneration",tL]],["mbart",["MBartForConditionalGeneration",tj]],["marian",["MarianMTModel",id]],["m2m_100",["M2M100ForConditionalGeneration",i_]],["blenderbot",["BlenderbotForConditionalGeneration",tG]],["blenderbot-small",["BlenderbotSmallForConditionalGeneration",t$]]]),lx=new Map([["bloom",["BloomForCausalLM",or]],["gpt2",["GPT2LMHeadModel",rQ]],["jais",["JAISLMHeadModel",rJ]],["gptj",["GPTJForCausalLM",r5]],["gpt_bigcode",["GPTBigCodeForCausalLM",r9]],["gpt_neo",["GPTNeoForCausalLM",rZ]],["gpt_neox",["GPTNeoXForCausalLM",r2]],["codegen",["CodeGenForCausalLM",nt]],["llama",["LlamaForCausalLM",no]],["arcee",["ArceeForCausalLM",na]],["lfm2",["Lfm2ForCausalLM",nu]],["smollm3",["SmolLM3ForCausalLM",np]],["exaone",["ExaoneForCausalLM",nP]],["olmo",["OlmoForCausalLM",nC]],["olmo2",["Olmo2ForCausalLM",nA]],["mobilellm",["MobileLLMForCausalLM",nk]],["granite",["GraniteForCausalLM",nD]],["cohere",["CohereForCausalLM",nV]],["gemma",["GemmaForCausalLM",nB]],["gemma2",["Gemma2ForCausalLM",nq]],["gemma3_text",["Gemma3ForCausalLM",nU]],["helium",["HeliumForCausalLM",nf]],["glm",["GlmForCausalLM",nw]],["openelm",["OpenELMForCausalLM",nH]],["qwen2",["Qwen2ForCausalLM",nK]],["qwen3",["Qwen3ForCausalLM",n1]],["phi",["PhiForCausalLM",n8]],["phi3",["Phi3ForCausalLM",n7]],["mpt",["MptForCausalLM",os]],["opt",["OPTForCausalLM",ol]],["mbart",["MBartForCausalLM",tO]],["mistral",["MistralForCausalLM",i8]],["ernie4_5",["Ernie4_5_ForCausalLM",i7]],["starcoder2",["Starcoder2ForCausalLM",ar]],["falcon",["FalconForCausalLM",as]],["trocr",["TrOCRForCausalLM",i3]],["stablelm",["StableLmForCausalLM",aM]],["modernbert-decoder",["ModernBertDecoderForCausalLM",e_]],["phi3_v",["Phi3VForCausalLM",rk]]]),lP=new Map([["multi_modality",["MultiModalityCausalLM",aW]]]),lb=new Map([["bert",["BertForMaskedLM",Y]],["neobert",["NeoBertForMaskedLM",en]],["modernbert",["ModernBertForMaskedLM",ec]],["roformer",["RoFormerForMaskedLM",ew]],["electra",["ElectraForMaskedLM",eA]],["esm",["EsmForMaskedLM",e6]],["convbert",["ConvBertForMaskedLM",ek]],["camembert",["CamembertForMaskedLM",eV]],["deberta",["DebertaForMaskedLM",eq]],["deberta-v2",["DebertaV2ForMaskedLM",eH]],["mpnet",["MPNetForMaskedLM",ta]],["albert",["AlbertForMaskedLM",tT]],["distilbert",["DistilBertForMaskedLM",e4]],["roberta",["RobertaForMaskedLM",tQ]],["xlm",["XLMWithLMHeadModel",tZ]],["xlm-roberta",["XLMRobertaForMaskedLM",t5]],["mobilebert",["MobileBertForMaskedLM",tr]],["squeezebert",["SqueezeBertForMaskedLM",tp]]]),lF=new Map([["bert",["BertForQuestionAnswering",ee]],["neobert",["NeoBertForQuestionAnswering",ei]],["roformer",["RoFormerForQuestionAnswering",eP]],["electra",["ElectraForQuestionAnswering",eD]],["convbert",["ConvBertForQuestionAnswering",eC]],["camembert",["CamembertForQuestionAnswering",eB]],["deberta",["DebertaForQuestionAnswering",eU]],["deberta-v2",["DebertaV2ForQuestionAnswering",eK]],["mpnet",["MPNetForQuestionAnswering",tu]],["albert",["AlbertForQuestionAnswering",tw]],["distilbert",["DistilBertForQuestionAnswering",e3]],["roberta",["RobertaForQuestionAnswering",tJ]],["xlm",["XLMForQuestionAnswering",t2]],["xlm-roberta",["XLMRobertaForQuestionAnswering",t9]],["mobilebert",["MobileBertForQuestionAnswering",to]],["squeezebert",["SqueezeBertForQuestionAnswering",th]]]),lk=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",rc]],["idefics3",["Idefics3ForConditionalGeneration",rP]],["smolvlm",["SmolVLMForConditionalGeneration",rb]]]),ly=new Map([["llava",["LlavaForConditionalGeneration",rd]],["llava_onevision",["LlavaOnevisionForConditionalGeneration",rm]],["moondream1",["Moondream1ForConditionalGeneration",rp]],["florence2",["Florence2ForConditionalGeneration",rh]],["qwen2-vl",["Qwen2VLForConditionalGeneration",n3]],["idefics3",["Idefics3ForConditionalGeneration",rP]],["smolvlm",["SmolVLMForConditionalGeneration",rb]],["paligemma",["PaliGemmaForConditionalGeneration",rg]],["llava_qwen2",["LlavaQwen2ForCausalLM",rM]],["gemma3n",["Gemma3nForConditionalGeneration",rT]]]),lv=new Map([["ultravox",["UltravoxModel",a2]],["voxtral",["VoxtralForConditionalGeneration",a3]]]),lC=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",rc]]]),lS=new Map([["vit",["ViTForImageClassification",od]],["ijepa",["IJepaForImageClassification",o_]],["pvt",["PvtForImageClassification",ow]],["vit_msn",["ViTMSNForImageClassification",oF]],["fastvit",["FastViTForImageClassification",oS]],["mobilevit",["MobileViTForImageClassification",oD]],["mobilevitv2",["MobileViTV2ForImageClassification",oV]],["beit",["BeitForImageClassification",oU]],["deit",["DeiTForImageClassification",su]],["hiera",["HieraForImageClassification",sp]],["convnext",["ConvNextForImageClassification",sH]],["convnextv2",["ConvNextV2ForImageClassification",sK]],["dinov2",["Dinov2ForImageClassification",s1]],["dinov2_with_registers",["Dinov2WithRegistersForImageClassification",s4]],["resnet",["ResNetForImageClassification",sf]],["swin",["SwinForImageClassification",sw]],["segformer",["SegformerForImageClassification",a_]],["efficientnet",["EfficientNetForImageClassification",ax]],["mobilenet_v1",["MobileNetV1ForImageClassification",aC]],["mobilenet_v2",["MobileNetV2ForImageClassification",aL]],["mobilenet_v3",["MobileNetV3ForImageClassification",aj]],["mobilenet_v4",["MobileNetV4ForImageClassification",aB]]]),lE=new Map([["detr",["DetrForObjectDetection",oH]],["rt_detr",["RTDetrForObjectDetection",o1]],["rt_detr_v2",["RTDetrV2ForObjectDetection",o5]],["rf_detr",["RFDetrForObjectDetection",o7]],["d_fine",["DFineForObjectDetection",sn]],["table-transformer",["TableTransformerForObjectDetection",si]],["yolos",["YolosForObjectDetection",io]]]),lA=new Map([["owlvit",["OwlViTForObjectDetection",oB]],["owlv2",["Owlv2ForObjectDetection",oq]],["grounding-dino",["GroundingDinoForObjectDetection",ie]]]),lL=new Map([["detr",["DetrForSegmentation",oJ]],["clipseg",["CLIPSegForImageSegmentation",r$]]]),lI=new Map([["segformer",["SegformerForSemanticSegmentation",ah]],["sapiens",["SapiensForSemanticSegmentation",sE]],["swin",["SwinForSemanticSegmentation",sT]],["mobilenet_v1",["MobileNetV1ForSemanticSegmentation",aS]],["mobilenet_v2",["MobileNetV2ForSemanticSegmentation",aI]],["mobilenet_v3",["MobileNetV3ForSemanticSegmentation",aV]],["mobilenet_v4",["MobileNetV4ForSemanticSegmentation",aG]]]),lD=new Map([["detr",["DetrForSegmentation",oJ]],["maskformer",["MaskFormerForInstanceSegmentation",sG]]]),lz=new Map([["sam",["SamModel",ia]]]),lj=new Map([["wav2vec2",["Wav2Vec2ForCTC",iM]],["wav2vec2-bert",["Wav2Vec2BertForCTC",iV]],["unispeech",["UniSpeechForCTC",iC]],["unispeech-sat",["UniSpeechSatForCTC",iL]],["wavlm",["WavLMForCTC",iW]],["hubert",["HubertForCTC",iG]]]),lV=new Map([["wav2vec2",["Wav2Vec2ForSequenceClassification",iw]],["wav2vec2-bert",["Wav2Vec2BertForSequenceClassification",iO]],["unispeech",["UniSpeechForSequenceClassification",iS]],["unispeech-sat",["UniSpeechSatForSequenceClassification",iI]],["wavlm",["WavLMForSequenceClassification",iU]],["hubert",["HubertForSequenceClassification",iR]],["audio-spectrogram-transformer",["ASTForAudioClassification",rt]]]),lO=new Map([["wavlm",["WavLMForXVector",iQ]]]),lN=new Map([["unispeech-sat",["UniSpeechSatForAudioFrameClassification",iD]],["wavlm",["WavLMForAudioFrameClassification",iX]],["wav2vec2",["Wav2Vec2ForAudioFrameClassification",iT]],["pyannote",["PyAnnoteForAudioFrameClassification",ib]]]),lB=new Map([["vitmatte",["VitMatteForImageMatting",oA]]]),lG=new Map([["patchtst",["PatchTSTForPrediction",aY]],["patchtsmixer",["PatchTSMixerForPrediction",a0]]]),lR=new Map([["swin2sr",["Swin2SRForImageSuperResolution",sb]]]),lq=new Map([["dpt",["DPTForDepthEstimation",sy]],["depth_anything",["DepthAnythingForDepthEstimation",sC]],["glpn",["GLPNForDepthEstimation",s$]],["sapiens",["SapiensForDepthEstimation",sA]],["depth_pro",["DepthProForDepthEstimation",sD]],["metric3d",["Metric3DForDepthEstimation",sj]],["metric3dv2",["Metric3Dv2ForDepthEstimation",sO]]]),l$=new Map([["sapiens",["SapiensForNormalEstimation",sL]]]),lW=new Map([["vitpose",["VitPoseForPoseEstimation",of]]]),lU=new Map([["clip",["CLIPVisionModelWithProjection",rA]],["siglip",["SiglipVisionModel",rz]],["jina_clip",["JinaCLIPVisionModel",rG]]]),lQ=[[ld,T.EncoderOnly],[lm,T.EncoderDecoder],[l_,T.DecoderOnly],[lp,T.AutoEncoder],[lM,T.EncoderOnly],[lw,T.EncoderOnly],[lT,T.Seq2Seq],[lh,T.Seq2Seq],[lx,T.DecoderOnly],[lP,T.MultiModality],[lb,T.EncoderOnly],[lF,T.EncoderOnly],[lk,T.Vision2Seq],[ly,T.ImageTextToText],[lv,T.AudioTextToText],[lS,T.EncoderOnly],[lL,T.EncoderOnly],[lD,T.EncoderOnly],[lI,T.EncoderOnly],[lB,T.EncoderOnly],[lG,T.EncoderOnly],[lR,T.EncoderOnly],[lq,T.EncoderOnly],[l$,T.EncoderOnly],[lW,T.EncoderOnly],[lE,T.EncoderOnly],[lA,T.EncoderOnly],[lz,T.MaskGeneration],[lj,T.EncoderOnly],[lV,T.EncoderOnly],[lf,T.Seq2Seq],[lg,T.EncoderOnly],[lO,T.EncoderOnly],[lN,T.EncoderOnly],[lU,T.EncoderOnly]];for(let[e,t]of lQ)for(let[r,n]of e.values())x.set(r,t),b.set(n,r),P.set(r,n);for(let[e,t,r]of[["MusicgenForConditionalGeneration",ak,T.Musicgen],["Phi3VForCausalLM",rk,T.Phi3V],["CLIPTextModelWithProjection",rS,T.EncoderOnly],["SiglipTextModel",rD,T.EncoderOnly],["JinaCLIPTextModel",rB,T.EncoderOnly],["ClapTextModelWithProjection",al,T.EncoderOnly],["ClapAudioModelWithProjection",ac,T.EncoderOnly],["DacEncoderModel",lo,T.EncoderOnly],["DacDecoderModel",ls,T.EncoderOnly],["MimiEncoderModel",a9,T.EncoderOnly],["MimiDecoderModel",a7,T.EncoderOnly],["SnacEncoderModel",ll,T.EncoderOnly],["SnacDecoderModel",lc,T.EncoderOnly],["Gemma3nForConditionalGeneration",rT,T.ImageAudioTextToText]])x.set(e,r),b.set(t,e),P.set(e,t);let lX=new Map([["modnet",lL],["birefnet",lL],["isnet",lL],["ben",lL]]);for(let[e,t]of lX.entries())t.set(e,["PreTrainedModel",U]),x.set(e,T.EncoderOnly),b.set(U,e),P.set(e,U);class lH extends lu{static MODEL_CLASS_MAPPINGS=lQ.map(e=>e[0]);static BASE_IF_FAIL=!0}class lJ extends lu{static MODEL_CLASS_MAPPINGS=[lM]}class lY extends lu{static MODEL_CLASS_MAPPINGS=[lw]}class lK extends lu{static MODEL_CLASS_MAPPINGS=[lT]}class lZ extends lu{static MODEL_CLASS_MAPPINGS=[lh]}class l0 extends lu{static MODEL_CLASS_MAPPINGS=[lf]}class l1 extends lu{static MODEL_CLASS_MAPPINGS=[lg]}class l2 extends lu{static MODEL_CLASS_MAPPINGS=[lx]}class l3 extends lu{static MODEL_CLASS_MAPPINGS=[lb]}class l4 extends lu{static MODEL_CLASS_MAPPINGS=[lF]}class l5 extends lu{static MODEL_CLASS_MAPPINGS=[lk]}class l8 extends lu{static MODEL_CLASS_MAPPINGS=[lS]}class l6 extends lu{static MODEL_CLASS_MAPPINGS=[lL]}class l9 extends lu{static MODEL_CLASS_MAPPINGS=[lI]}class l7 extends lu{static MODEL_CLASS_MAPPINGS=[lD]}class ce extends lu{static MODEL_CLASS_MAPPINGS=[lE]}class ct extends lu{static MODEL_CLASS_MAPPINGS=[lA]}class cr extends lu{static MODEL_CLASS_MAPPINGS=[lz]}class cn extends lu{static MODEL_CLASS_MAPPINGS=[lj]}class co extends lu{static MODEL_CLASS_MAPPINGS=[lV]}class cs extends lu{static MODEL_CLASS_MAPPINGS=[lO]}class ci extends lu{static MODEL_CLASS_MAPPINGS=[lN]}class ca extends lu{static MODEL_CLASS_MAPPINGS=[lC]}class cl extends lu{static MODEL_CLASS_MAPPINGS=[lB]}class cc extends lu{static MODEL_CLASS_MAPPINGS=[lR]}class cu extends lu{static MODEL_CLASS_MAPPINGS=[lq]}class cd extends lu{static MODEL_CLASS_MAPPINGS=[l$]}class cm extends lu{static MODEL_CLASS_MAPPINGS=[lW]}class cp extends lu{static MODEL_CLASS_MAPPINGS=[lU]}class c_ extends lu{static MODEL_CLASS_MAPPINGS=[ly]}class ch extends lu{static MODEL_CLASS_MAPPINGS=[lv]}class cf extends Q{constructor({logits:e,past_key_values:t,encoder_outputs:r,decoder_attentions:n=null,cross_attentions:o=null}){super(),this.logits=e,this.past_key_values=t,this.encoder_outputs=r,this.decoder_attentions=n,this.cross_attentions=o}}class cg extends Q{constructor({logits:e,...t}){super(),this.logits=e;let r=Object.values(t);r.length>0&&(this.attentions=r)}}class cM extends Q{constructor({logits:e,embeddings:t}){super(),this.logits=e,this.embeddings=t}}class cw extends Q{constructor({logits:e}){super(),this.logits=e}}class cT extends Q{constructor({logits:e}){super(),this.logits=e}}class cx extends Q{constructor({start_logits:e,end_logits:t}){super(),this.start_logits=e,this.end_logits=t}}class cP extends Q{constructor({logits:e}){super(),this.logits=e}}class cb extends Q{constructor({logits:e,past_key_values:t}){super(),this.logits=e,this.past_key_values=t}}class cF extends Q{constructor({alphas:e}){super(),this.alphas=e}}class ck extends Q{constructor({waveform:e,spectrogram:t}){super(),this.waveform=e,this.spectrogram=t}}},"./src/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.js":/*!******************************************************************************************************!*\
  !*** ./src/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.js ***!
  \******************************************************************************************************/(e,t,r)=>{r.r(t),r.d(t,{ASTFeatureExtractor:()=>s});var n=r(/*! ../../base/feature_extraction_utils.js */"./src/base/feature_extraction_utils.js");r(/*! ../../utils/tensor.js */"./src/utils/tensor.js");var o=r(/*! ../../utils/audio.js */"./src/utils/audio.js");class s extends n.FeatureExtractor{constructor(e){super(e);let t=this.config.sampling_rate,r=(0,o.mel_filter_bank)(257,this.config.num_mel_bins,20,Math.floor(t/2),t,null,"kaldi",!0);this.mel_filters=r,this.window=(0,o.window_function)(400,"hann",{periodic:!1}),this.mean=this.config.mean,this.std=this.config.std}async _extract_fbank_features(e,t){return(0,o.spectrogram)(e,this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1192092955078125e-22,remove_dc_offset:!0,max_num_frames:t,transpose:!0})}async _call(e){(0,n.validate_audio_inputs)(e,"ASTFeatureExtractor");let t=await this._extract_fbank_features(e,this.config.max_length);if(this.config.do_normalize){let e=2*this.std,r=t.data;for(let t=0;t<r.length;++t)r[t]=(r[t]-this.mean)/e}return{input_values:t.unsqueeze_(0)}}}},"./src/models/auto/feature_extraction_auto.js":/*!****************************************************!*\
  !*** ./src/models/auto/feature_extraction_auto.js ***!
  \****************************************************/(e,t,r)=>{r.r(t),r.d(t,{AutoFeatureExtractor:()=>i});var n=r(/*! ../../utils/constants.js */"./src/utils/constants.js"),o=r(/*! ../../utils/hub.js */"./src/utils/hub.js");r(/*! ../../base/feature_extraction_utils.js */"./src/base/feature_extraction_utils.js");var s=r(/*! ../feature_extractors.js */"./src/models/feature_extractors.js");class i{static async from_pretrained(e,t={}){let r=await (0,o.getModelJSON)(e,n.FEATURE_EXTRACTOR_NAME,!0,t),i=r.feature_extractor_type,a=s[i];if(!a)throw Error(`Unknown feature_extractor_type: '${i}'. Please report this at ${n.GITHUB_ISSUE_URL}.`);return new a(r)}}},"./src/models/auto/image_processing_auto.js":/*!**************************************************!*\
  !*** ./src/models/auto/image_processing_auto.js ***!
  \**************************************************/(e,t,r)=>{r.r(t),r.d(t,{AutoImageProcessor:()=>a});var n=r(/*! ../../utils/constants.js */"./src/utils/constants.js"),o=r(/*! ../../utils/hub.js */"./src/utils/hub.js"),s=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js"),i=r(/*! ../image_processors.js */"./src/models/image_processors.js");class a{static async from_pretrained(e,t={}){let r=await (0,o.getModelJSON)(e,n.IMAGE_PROCESSOR_NAME,!0,t),a=r.image_processor_type??r.feature_extractor_type,l=i[a?.replace(/Fast$/,"")];return l||(void 0!==a&&console.warn(`Image processor type '${a}' not found, assuming base ImageProcessor. Please report this at ${n.GITHUB_ISSUE_URL}.`),l=s.ImageProcessor),new l(r)}}},"./src/models/auto/processing_auto.js":/*!********************************************!*\
  !*** ./src/models/auto/processing_auto.js ***!
  \********************************************/(e,t,r)=>{r.r(t),r.d(t,{AutoProcessor:()=>c});var n=r(/*! ../../utils/constants.js */"./src/utils/constants.js"),o=r(/*! ../../utils/hub.js */"./src/utils/hub.js"),s=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),i=r(/*! ../processors.js */"./src/models/processors.js"),a=r(/*! ../image_processors.js */"./src/models/image_processors.js"),l=r(/*! ../feature_extractors.js */"./src/models/feature_extractors.js");class c{static async from_pretrained(e,t={}){let r=await (0,o.getModelJSON)(e,n.IMAGE_PROCESSOR_NAME,!0,t),{image_processor_type:c,feature_extractor_type:u,processor_class:d}=r;if(d&&i[d])return i[d].from_pretrained(e,t);if(!c&&!u)throw Error("No `image_processor_type` or `feature_extractor_type` found in the config.");let m={};if(c){let e=a[c.replace(/Fast$/,"")];if(!e)throw Error(`Unknown image_processor_type: '${c}'.`);m.image_processor=new e(r)}if(u){let e=a[u];if(e)m.image_processor=new e(r);else{let e=l[u];if(!e)throw Error(`Unknown feature_extractor_type: '${u}'.`);m.feature_extractor=new e(r)}}return new s.Processor({},m,null)}}},"./src/models/beit/image_processing_beit.js":/*!**************************************************!*\
  !*** ./src/models/beit/image_processing_beit.js ***!
  \**************************************************/(e,t,r)=>{r.r(t),r.d(t,{BeitFeatureExtractor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}},"./src/models/bit/image_processing_bit.js":/*!************************************************!*\
  !*** ./src/models/bit/image_processing_bit.js ***!
  \************************************************/(e,t,r)=>{r.r(t),r.d(t,{BitImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}},"./src/models/chinese_clip/image_processing_chinese_clip.js":/*!******************************************************************!*\
  !*** ./src/models/chinese_clip/image_processing_chinese_clip.js ***!
  \******************************************************************/(e,t,r)=>{r.r(t),r.d(t,{ChineseCLIPFeatureExtractor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}},"./src/models/clap/feature_extraction_clap.js":/*!****************************************************!*\
  !*** ./src/models/clap/feature_extraction_clap.js ***!
  \****************************************************/(e,t,r)=>{r.r(t),r.d(t,{ClapFeatureExtractor:()=>s});var n=r(/*! ../../base/feature_extraction_utils.js */"./src/base/feature_extraction_utils.js");r(/*! ../../utils/tensor.js */"./src/utils/tensor.js");var o=r(/*! ../../utils/audio.js */"./src/utils/audio.js");class s extends n.FeatureExtractor{constructor(e){super(e),this.mel_filters=(0,o.mel_filter_bank)(this.config.nb_frequency_bins,this.config.feature_size,this.config.frequency_min,this.config.frequency_max,this.config.sampling_rate,null,"htk"),this.mel_filters_slaney=(0,o.mel_filter_bank)(this.config.nb_frequency_bins,this.config.feature_size,this.config.frequency_min,this.config.frequency_max,this.config.sampling_rate,"slaney","slaney"),this.window=(0,o.window_function)(this.config.fft_window_size,"hann")}async _get_input_mel(e,t,r,n){let o;let s=e.length-t;if(s>0){if("rand_trunc"===r){let r=Math.floor(Math.random()*(s+1));e=e.subarray(r,r+t),o=await this._extract_fbank_features(e,this.mel_filters_slaney,this.config.nb_max_samples)}else throw Error(`Truncation strategy "${r}" not implemented`)}else{if(s<0){let r=new Float64Array(t);if(r.set(e),"repeat"===n)for(let n=e.length;n<t;n+=e.length)r.set(e.subarray(0,Math.min(e.length,t-n)),n);else if("repeatpad"===n)for(let t=e.length;t<-s;t+=e.length)r.set(e,t);e=r}if("fusion"===r)throw Error(`Truncation strategy "${r}" not implemented`);o=await this._extract_fbank_features(e,this.mel_filters_slaney,this.config.nb_max_samples)}return o.unsqueeze_(0)}async _extract_fbank_features(e,t,r=null){return(0,o.spectrogram)(e,this.window,this.config.fft_window_size,this.config.hop_length,{power:2,mel_filters:t,log_mel:"dB",max_num_frames:r,do_pad:!1,transpose:!0})}async _call(e,{max_length:t=null}={}){return(0,n.validate_audio_inputs)(e,"ClapFeatureExtractor"),{input_features:(await this._get_input_mel(e,t??this.config.nb_max_samples,this.config.truncation,this.config.padding)).unsqueeze_(0)}}}},"./src/models/clip/image_processing_clip.js":/*!**************************************************!*\
  !*** ./src/models/clip/image_processing_clip.js ***!
  \**************************************************/(e,t,r)=>{r.r(t),r.d(t,{CLIPFeatureExtractor:()=>s,CLIPImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}class s extends o{}},"./src/models/convnext/image_processing_convnext.js":/*!**********************************************************!*\
  !*** ./src/models/convnext/image_processing_convnext.js ***!
  \**********************************************************/(e,t,r)=>{r.r(t),r.d(t,{ConvNextFeatureExtractor:()=>s,ConvNextImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{constructor(e){super(e),this.crop_pct=this.config.crop_pct??.875}async resize(e){let t=this.size?.shortest_edge;if(void 0===t)throw Error("Size dictionary must contain 'shortest_edge' key.");if(t<384){let r=Math.floor(t/this.crop_pct),[n,o]=this.get_resize_output_image_size(e,{shortest_edge:r});e=await e.resize(n,o,{resample:this.resample}),e=await e.center_crop(t,t)}else e=await e.resize(t,t,{resample:this.resample});return e}}class s extends o{}},"./src/models/dac/feature_extraction_dac.js":/*!**************************************************!*\
  !*** ./src/models/dac/feature_extraction_dac.js ***!
  \**************************************************/(e,t,r)=>{r.r(t),r.d(t,{DacFeatureExtractor:()=>o});var n=r(/*! ../encodec/feature_extraction_encodec.js */"./src/models/encodec/feature_extraction_encodec.js");class o extends n.EncodecFeatureExtractor{}},"./src/models/deit/image_processing_deit.js":/*!**************************************************!*\
  !*** ./src/models/deit/image_processing_deit.js ***!
  \**************************************************/(e,t,r)=>{r.r(t),r.d(t,{DeiTFeatureExtractor:()=>s,DeiTImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}class s extends o{}},"./src/models/detr/image_processing_detr.js":/*!**************************************************!*\
  !*** ./src/models/detr/image_processing_detr.js ***!
  \**************************************************/(e,t,r)=>{r.r(t),r.d(t,{DetrFeatureExtractor:()=>i,DetrImageProcessor:()=>s});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js"),o=r(/*! ../../utils/tensor.js */"./src/utils/tensor.js");class s extends n.ImageProcessor{async _call(e){let t=await super._call(e),r=[t.pixel_values.dims[0],64,64],n=(0,o.full)(r,1n);return{...t,pixel_mask:n}}post_process_object_detection(...e){return(0,n.post_process_object_detection)(...e)}post_process_panoptic_segmentation(...e){return(0,n.post_process_panoptic_segmentation)(...e)}post_process_instance_segmentation(...e){return(0,n.post_process_instance_segmentation)(...e)}}class i extends s{}},"./src/models/dinov3_vit/image_processing_dinov3_vit.js":/*!**************************************************************!*\
  !*** ./src/models/dinov3_vit/image_processing_dinov3_vit.js ***!
  \**************************************************************/(e,t,r)=>{r.r(t),r.d(t,{DINOv3ViTImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}},"./src/models/donut/image_processing_donut.js":/*!****************************************************!*\
  !*** ./src/models/donut/image_processing_donut.js ***!
  \****************************************************/(e,t,r)=>{r.r(t),r.d(t,{DonutFeatureExtractor:()=>s,DonutImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{pad_image(e,t,r,n={}){let[o,s,i]=t,a=this.image_mean;Array.isArray(this.image_mean)||(a=Array(i).fill(a));let l=this.image_std;Array.isArray(l)||(l=Array(i).fill(a));let c=a.map((e,t)=>-e/l[t]);return super.pad_image(e,t,r,{center:!0,constant_values:c,...n})}}class s extends o{}},"./src/models/dpt/image_processing_dpt.js":/*!************************************************!*\
  !*** ./src/models/dpt/image_processing_dpt.js ***!
  \************************************************/(e,t,r)=>{r.r(t),r.d(t,{DPTFeatureExtractor:()=>s,DPTImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}class s extends o{}},"./src/models/efficientnet/image_processing_efficientnet.js":/*!******************************************************************!*\
  !*** ./src/models/efficientnet/image_processing_efficientnet.js ***!
  \******************************************************************/(e,t,r)=>{r.r(t),r.d(t,{EfficientNetImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{constructor(e){super(e),this.include_top=this.config.include_top??!0,this.include_top&&(this.image_std=this.image_std.map(e=>e*e))}}},"./src/models/encodec/feature_extraction_encodec.js":/*!**********************************************************!*\
  !*** ./src/models/encodec/feature_extraction_encodec.js ***!
  \**********************************************************/(e,t,r)=>{r.r(t),r.d(t,{EncodecFeatureExtractor:()=>s});var n=r(/*! ../../base/feature_extraction_utils.js */"./src/base/feature_extraction_utils.js"),o=r(/*! ../../utils/tensor.js */"./src/utils/tensor.js");class s extends n.FeatureExtractor{async _call(e){(0,n.validate_audio_inputs)(e,"EncodecFeatureExtractor"),e instanceof Float64Array&&(e=new Float32Array(e));let t=this.config.feature_size;if(e.length%t!=0)throw Error(`The length of the audio data must be a multiple of the number of channels (${t}).`);let r=[1,t,e.length/t];return{input_values:new o.Tensor("float32",e,r)}}}},"./src/models/feature_extractors.js":/*!******************************************!*\
  !*** ./src/models/feature_extractors.js ***!
  \******************************************/(e,t,r)=>{r.r(t),r.d(t,{ASTFeatureExtractor:()=>n.ASTFeatureExtractor,ClapFeatureExtractor:()=>s.ClapFeatureExtractor,DacFeatureExtractor:()=>i.DacFeatureExtractor,EncodecFeatureExtractor:()=>o.EncodecFeatureExtractor,Gemma3nAudioFeatureExtractor:()=>a.Gemma3nAudioFeatureExtractor,ImageFeatureExtractor:()=>f.ImageProcessor,MoonshineFeatureExtractor:()=>l.MoonshineFeatureExtractor,PyAnnoteFeatureExtractor:()=>c.PyAnnoteFeatureExtractor,SeamlessM4TFeatureExtractor:()=>u.SeamlessM4TFeatureExtractor,SnacFeatureExtractor:()=>d.SnacFeatureExtractor,SpeechT5FeatureExtractor:()=>m.SpeechT5FeatureExtractor,Wav2Vec2FeatureExtractor:()=>p.Wav2Vec2FeatureExtractor,WeSpeakerFeatureExtractor:()=>_.WeSpeakerFeatureExtractor,WhisperFeatureExtractor:()=>h.WhisperFeatureExtractor});var n=r(/*! ./audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.js */"./src/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.js"),o=r(/*! ./encodec/feature_extraction_encodec.js */"./src/models/encodec/feature_extraction_encodec.js"),s=r(/*! ./clap/feature_extraction_clap.js */"./src/models/clap/feature_extraction_clap.js"),i=r(/*! ./dac/feature_extraction_dac.js */"./src/models/dac/feature_extraction_dac.js"),a=r(/*! ./gemma3n/feature_extraction_gemma3n.js */"./src/models/gemma3n/feature_extraction_gemma3n.js"),l=r(/*! ./moonshine/feature_extraction_moonshine.js */"./src/models/moonshine/feature_extraction_moonshine.js"),c=r(/*! ./pyannote/feature_extraction_pyannote.js */"./src/models/pyannote/feature_extraction_pyannote.js"),u=r(/*! ./seamless_m4t/feature_extraction_seamless_m4t.js */"./src/models/seamless_m4t/feature_extraction_seamless_m4t.js"),d=r(/*! ./snac/feature_extraction_snac.js */"./src/models/snac/feature_extraction_snac.js"),m=r(/*! ./speecht5/feature_extraction_speecht5.js */"./src/models/speecht5/feature_extraction_speecht5.js"),p=r(/*! ./wav2vec2/feature_extraction_wav2vec2.js */"./src/models/wav2vec2/feature_extraction_wav2vec2.js"),_=r(/*! ./wespeaker/feature_extraction_wespeaker.js */"./src/models/wespeaker/feature_extraction_wespeaker.js"),h=r(/*! ./whisper/feature_extraction_whisper.js */"./src/models/whisper/feature_extraction_whisper.js"),f=r(/*! ../base/image_processors_utils.js */"./src/base/image_processors_utils.js")},"./src/models/florence2/processing_florence2.js":/*!******************************************************!*\
  !*** ./src/models/florence2/processing_florence2.js ***!
  \******************************************************/(e,t,r)=>{r.r(t),r.d(t,{Florence2Processor:()=>i});var n=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),o=r(/*! ../auto/image_processing_auto.js */"./src/models/auto/image_processing_auto.js"),s=r(/*! ../../tokenizers.js */"./src/tokenizers.js");class i extends n.Processor{static tokenizer_class=s.AutoTokenizer;static image_processor_class=o.AutoImageProcessor;constructor(e,t,r){super(e,t,r);let{tasks_answer_post_processing_type:n,task_prompts_without_inputs:o,task_prompts_with_input:s}=this.image_processor.config;this.tasks_answer_post_processing_type=new Map(Object.entries(n??{})),this.task_prompts_without_inputs=new Map(Object.entries(o??{})),this.task_prompts_with_input=new Map(Object.entries(s??{})),this.regexes={quad_boxes:/(.+?)<loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)>/gm,bboxes:/([^<]+)?<loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)>/gm},this.size_per_bin=1e3}construct_prompts(e){"string"==typeof e&&(e=[e]);let t=[];for(let r of e)if(this.task_prompts_without_inputs.has(r))t.push(this.task_prompts_without_inputs.get(r));else{for(let[e,n]of this.task_prompts_with_input)if(r.includes(e)){t.push(n.replaceAll("{input}",r).replaceAll(e,""));break}t.length!==e.length&&t.push(r)}return t}post_process_generation(e,t,r){let n;let o=this.tasks_answer_post_processing_type.get(t)??"pure_text";switch(e=e.replaceAll("<s>","").replaceAll("</s>",""),o){case"pure_text":n=e;break;case"description_with_bboxes":case"bboxes":case"phrase_grounding":case"ocr":let s="ocr"===o?"quad_boxes":"bboxes",i=e.matchAll(this.regexes[s]),a=[],l=[];for(let[e,t,...n]of i)a.push(t?t.trim():a.at(-1)??""),l.push(n.map((e,t)=>(Number(e)+.5)/this.size_per_bin*r[t%2]));n={labels:a,[s]:l};break;default:throw Error(`Task "${t}" (of type "${o}") not yet implemented.`)}return{[t]:n}}async _call(e,t=null,r={}){if(!e&&!t)throw Error("Either text or images must be provided");let n=await this.image_processor(e,r),o=t?this.tokenizer(this.construct_prompts(t),r):{};return{...n,...o}}}},"./src/models/gemma3n/feature_extraction_gemma3n.js":/*!**********************************************************!*\
  !*** ./src/models/gemma3n/feature_extraction_gemma3n.js ***!
  \**********************************************************/(e,t,r)=>{r.r(t),r.d(t,{Gemma3nAudioFeatureExtractor:()=>i});var n=r(/*! ../../base/feature_extraction_utils.js */"./src/base/feature_extraction_utils.js"),o=r(/*! ../../utils/tensor.js */"./src/utils/tensor.js"),s=r(/*! ../../utils/audio.js */"./src/utils/audio.js");class i extends n.FeatureExtractor{constructor(e){super(e);let{fft_length:t,feature_size:r,min_frequency:n,max_frequency:o,sampling_rate:i,frame_length:a}=this.config,l=(0,s.mel_filter_bank)(Math.floor(1+t/2),r,n,o,i,null,"htk",!1);this.mel_filters=l,this.window=(0,s.window_function)(a,"hann")}async _extract_fbank_features(e,t){return(0,s.spectrogram)(e,this.window,this.config.frame_length,this.config.hop_length,{fft_length:this.config.fft_length,center:!1,onesided:!0,preemphasis:this.config.preemphasis,preemphasis_htk_flavor:this.config.preemphasis_htk_flavor,mel_filters:this.mel_filters,log_mel:"log",mel_floor:this.config.mel_floor,remove_dc_offset:!1,transpose:!0})}async _call(e,{max_length:t=48e4,truncation:r=!0,padding:s=!0,pad_to_multiple_of:i=128}={}){if((0,n.validate_audio_inputs)(e,"Gemma3nAudioFeatureExtractor"),r&&e.length>t&&(e=e.slice(0,t)),s&&e.length%i!=0){let t=i-e.length%i,r=new Float64Array(e.length+t);r.set(e),0!==this.config.padding_value&&r.fill(this.config.padding_value,e.length),e=r}let a=await this._extract_fbank_features(e,this.config.max_length),l=(0,o.full)([1,a.dims[0]],!0);return{input_features:a.unsqueeze_(0),input_features_mask:l}}}},"./src/models/gemma3n/processing_gemma3n.js":/*!**************************************************!*\
  !*** ./src/models/gemma3n/processing_gemma3n.js ***!
  \**************************************************/(e,t,r)=>{r.r(t),r.d(t,{Gemma3nProcessor:()=>a});var n=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),o=r(/*! ../auto/image_processing_auto.js */"./src/models/auto/image_processing_auto.js"),s=r(/*! ../auto/feature_extraction_auto.js */"./src/models/auto/feature_extraction_auto.js"),i=r(/*! ../../tokenizers.js */"./src/tokenizers.js");r(/*! ../../utils/image.js */"./src/utils/image.js"),r(/*! ../../utils/audio.js */"./src/utils/audio.js");class a extends n.Processor{static image_processor_class=o.AutoImageProcessor;static feature_extractor_class=s.AutoFeatureExtractor;static tokenizer_class=i.AutoTokenizer;static uses_processor_config=!0;static uses_chat_template_file=!0;constructor(e,t,r){super(e,t,r),this.audio_seq_length=this.config.audio_seq_length,this.image_seq_length=this.config.image_seq_length;let{audio_token_id:n,boa_token:o,audio_token:s,eoa_token:i,image_token_id:a,boi_token:l,image_token:c,eoi_token:u}=this.tokenizer.config;this.audio_token_id=n,this.boa_token=o,this.audio_token=s;let d=s.repeat(this.audio_seq_length);this.full_audio_sequence=`

${o}${d}${i}

`,this.image_token_id=a,this.boi_token=l,this.image_token=c;let m=c.repeat(this.image_seq_length);this.full_image_sequence=`

${l}${m}${u}

`}async _call(e,t=null,r=null,n={}){let o,s;return"string"==typeof e&&(e=[e]),r&&(o=await this.feature_extractor(r,n),e=e.map(e=>e.replaceAll(this.audio_token,this.full_audio_sequence))),t&&(s=await this.image_processor(t,n),e=e.map(e=>e.replaceAll(this.image_token,this.full_image_sequence))),{...this.tokenizer(e,n),...s,...o}}}},"./src/models/glpn/image_processing_glpn.js":/*!**************************************************!*\
  !*** ./src/models/glpn/image_processing_glpn.js ***!
  \**************************************************/(e,t,r)=>{r.r(t),r.d(t,{GLPNFeatureExtractor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}},"./src/models/grounding_dino/image_processing_grounding_dino.js":/*!**********************************************************************!*\
  !*** ./src/models/grounding_dino/image_processing_grounding_dino.js ***!
  \**********************************************************************/(e,t,r)=>{r.r(t),r.d(t,{GroundingDinoImageProcessor:()=>s});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js"),o=r(/*! ../../utils/tensor.js */"./src/utils/tensor.js");class s extends n.ImageProcessor{async _call(e){let t=await super._call(e),r=t.pixel_values.dims,n=(0,o.ones)([r[0],r[2],r[3]]);return{...t,pixel_mask:n}}}},"./src/models/grounding_dino/processing_grounding_dino.js":/*!****************************************************************!*\
  !*** ./src/models/grounding_dino/processing_grounding_dino.js ***!
  \****************************************************************/(e,t,r)=>{r.r(t),r.d(t,{GroundingDinoProcessor:()=>a});var n=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),o=r(/*! ../auto/image_processing_auto.js */"./src/models/auto/image_processing_auto.js"),s=r(/*! ../../tokenizers.js */"./src/tokenizers.js"),i=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class a extends n.Processor{static tokenizer_class=s.AutoTokenizer;static image_processor_class=o.AutoImageProcessor;async _call(e,t,r={}){let n=e?await this.image_processor(e,r):{};return{...t?this.tokenizer(t,r):{},...n}}post_process_grounded_object_detection(e,t,{box_threshold:r=.25,text_threshold:n=.25,target_sizes:o=null}={}){let{logits:s,pred_boxes:a}=e,l=s.dims[0];if(null!==o&&o.length!==l)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let c=s.dims.at(1),u=s.sigmoid(),d=u.max(-1).tolist(),m=a.tolist().map(e=>e.map(e=>(0,i.center_to_corners_format)(e))),p=[];for(let e=0;e<l;++e){let s=null!==o?o[e]:null;null!==s&&(m[e]=m[e].map(e=>e.map((e,t)=>e*s[(t+1)%2])));let i=d[e],a=[],l=[],_=[];for(let o=0;o<c;++o){let s=i[o];if(s<=r)continue;let c=m[e][o],d=u[e][o];a.push(s),_.push(c);let p=function(e,t){let r=e.dims.at(-1)-1,n=e.tolist();n.fill(!1,0,1),n.fill(!1,r);let o=t.tolist();return n.map((e,t)=>e?t:null).filter(e=>null!==e).map(e=>o[e])}(d.gt(n),t[e]);l.push(p)}p.push({scores:a,boxes:_,labels:this.batch_decode(l)})}return p}}},"./src/models/idefics3/image_processing_idefics3.js":/*!**********************************************************!*\
  !*** ./src/models/idefics3/image_processing_idefics3.js ***!
  \**********************************************************/(e,t,r)=>{r.r(t),r.d(t,{Idefics3ImageProcessor:()=>s});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js"),o=r(/*! ../../utils/tensor.js */"./src/utils/tensor.js");class s extends n.ImageProcessor{constructor(e){super(e),this.do_image_splitting=e.do_image_splitting??!0,this.max_image_size=e.max_image_size}get_resize_for_vision_encoder(e,t){let[r,n]=e.dims.slice(-2),o=n/r;return n>=r?r=Math.ceil((r=Math.floor((n=Math.ceil(n/t)*t)/o))/t)*t:n=Math.ceil((n=Math.floor((r=Math.ceil(r/t)*t)*o))/t)*t,{height:r,width:n}}async _call(e,{do_image_splitting:t=null,return_row_col_info:r=!1}={}){let n,s,i;if(Array.isArray(e)){if(0===e.length||!e[0])throw Error("No images provided.");n=Array.isArray(e[0])?e:[e]}else n=[[e]];let a=[],l=[],c=[],u=[],d=[];for(let e of n){let r,n=await Promise.all(e.map(e=>this.preprocess(e)));u.push(...n.map(e=>e.original_size)),d.push(...n.map(e=>e.reshaped_input_size)),n.forEach(e=>e.pixel_values.unsqueeze_(0));let{longest_edge:s}=this.max_image_size;if(t??this.do_image_splitting){let e=Array(n.length),t=Array(n.length);r=await Promise.all(n.map(async(r,n)=>{let i=this.get_resize_for_vision_encoder(r.pixel_values,s),a=await (0,o.interpolate_4d)(r.pixel_values,{size:[i.height,i.width]}),{frames:l,num_splits_h:c,num_splits_w:u}=await this.split_image(a,this.max_image_size);return e[n]=c,t[n]=u,(0,o.cat)(l,0)})),l.push(e),c.push(t)}else{let e=[s,s];r=await Promise.all(n.map(t=>(0,o.interpolate_4d)(t.pixel_values,{size:e}))),l.push(Array(n.length).fill(0)),c.push(Array(n.length).fill(0))}a.push((0,o.cat)(r,0))}let m=a.length,[p,_,h,f]=a[0].dims;if(1===m)s=a[0].unsqueeze_(0),i=(0,o.full)([m,p,h,f],!0);else{let e=Math.max(...a.map(e=>e.dims.at(0))),t=(i=(0,o.full)([m,e,h,f],!0)).data,r=e*h*f;for(let n=0;n<m;++n){let s=a[n].dims[0];if(s<e){a[n]=(0,o.cat)([a[n],(0,o.full)([e-s,_,h,f],0)],0);let i=n*r+s*h*f,l=(n+1)*r;t.fill(!1,i,l)}}s=(0,o.stack)(a,0)}return{pixel_values:s,pixel_attention_mask:i,original_sizes:u,reshaped_input_sizes:d,...r?{rows:l,cols:c}:{}}}async split_image(e,{longest_edge:t}){let r=[],[n,s]=e.dims.slice(-2),i=0,a=0;if(n>t||s>t){i=Math.ceil(n/t),a=Math.ceil(s/t);let l=Math.ceil(n/i),c=Math.ceil(s/a);for(let t=0;t<i;++t)for(let u=0;u<a;++u){let d,m,p,_;t===i-1?(m=n-l,_=n):(m=t*l,_=(t+1)*l),u===a-1?(d=s-c,p=s):(d=u*c,p=(u+1)*c);let h=[m,d],f=[_,p],g=await (0,o.slice)(e,h,f,[2,3]);r.push(g)}(n!==t||s!==t)&&(e=await (0,o.interpolate_4d)(e,{size:[t,t]}))}return r.push(e),{frames:r,num_splits_h:i,num_splits_w:a}}}},"./src/models/idefics3/processing_idefics3.js":/*!****************************************************!*\
  !*** ./src/models/idefics3/processing_idefics3.js ***!
  \****************************************************/(e,t,r)=>{r.r(t),r.d(t,{Idefics3Processor:()=>a});var n=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),o=r(/*! ../auto/image_processing_auto.js */"./src/models/auto/image_processing_auto.js"),s=r(/*! ../../tokenizers.js */"./src/tokenizers.js");r(/*! ../../utils/image.js */"./src/utils/image.js");var i=r(/*! ../../utils/core.js */"./src/utils/core.js");class a extends n.Processor{static image_processor_class=o.AutoImageProcessor;static tokenizer_class=s.AutoTokenizer;static uses_processor_config=!0;fake_image_token="<fake_token_around_image>";image_token="<image>";global_img_token="<global-img>";async _call(e,t=null,r={}){let n;r.return_row_col_info??=!0,t&&(n=await this.image_processor(t,r)),Array.isArray(e)||(e=[e]);let o=n.rows??[Array(e.length).fill(0)],s=n.cols??[Array(e.length).fill(0)],a=this.config.image_seq_len,l=[],c=[];for(let t=0;t<e.length;++t){let r=e[t],n=o[t],u=s[t];l.push((0,i.count)(r,this.image_token));let d=n.map((e,t)=>{var r,n,o,s,i,l;return r=e,n=u[t],o=a,s=this.fake_image_token,i=this.image_token,l=this.global_img_token,0===r&&0===n?`${s}${l}`+i.repeat(o)+`${s}`:function(e,t,r,n,o,s){let i="";for(let s=0;s<t;++s){for(let t=0;t<r;++t)i+=n+`<row_${s+1}_col_${t+1}>`+o.repeat(e);i+="\n"}return i+(`
${n}${s}`+o.repeat(e))+`${n}`}(o,r,n,s,i,l)}),m=r.split(this.image_token);if(0===m.length)throw Error("The image token should be present in the text.");let p=m[0];for(let e=0;e<d.length;++e)p+=d[e]+m[e+1];c.push(p)}return{...this.tokenizer(c),...n}}}},"./src/models/image_processors.js":/*!****************************************!*\
  !*** ./src/models/image_processors.js ***!
  \****************************************/(e,t,r)=>{r.r(t),r.d(t,{BeitFeatureExtractor:()=>n.BeitFeatureExtractor,BitImageProcessor:()=>o.BitImageProcessor,CLIPFeatureExtractor:()=>i.CLIPFeatureExtractor,CLIPImageProcessor:()=>i.CLIPImageProcessor,ChineseCLIPFeatureExtractor:()=>s.ChineseCLIPFeatureExtractor,ConvNextFeatureExtractor:()=>a.ConvNextFeatureExtractor,ConvNextImageProcessor:()=>a.ConvNextImageProcessor,DINOv3ViTImageProcessor:()=>u.DINOv3ViTImageProcessor,DPTFeatureExtractor:()=>m.DPTFeatureExtractor,DPTImageProcessor:()=>m.DPTImageProcessor,DeiTFeatureExtractor:()=>l.DeiTFeatureExtractor,DeiTImageProcessor:()=>l.DeiTImageProcessor,DetrFeatureExtractor:()=>c.DetrFeatureExtractor,DetrImageProcessor:()=>c.DetrImageProcessor,DonutFeatureExtractor:()=>d.DonutFeatureExtractor,DonutImageProcessor:()=>d.DonutImageProcessor,EfficientNetImageProcessor:()=>p.EfficientNetImageProcessor,GLPNFeatureExtractor:()=>_.GLPNFeatureExtractor,GroundingDinoImageProcessor:()=>h.GroundingDinoImageProcessor,Idefics3ImageProcessor:()=>f.Idefics3ImageProcessor,JinaCLIPImageProcessor:()=>M.JinaCLIPImageProcessor,LlavaOnevisionImageProcessor:()=>w.LlavaOnevisionImageProcessor,Mask2FormerImageProcessor:()=>T.Mask2FormerImageProcessor,MaskFormerFeatureExtractor:()=>x.MaskFormerFeatureExtractor,MaskFormerImageProcessor:()=>x.MaskFormerImageProcessor,MobileNetV1FeatureExtractor:()=>P.MobileNetV1FeatureExtractor,MobileNetV1ImageProcessor:()=>P.MobileNetV1ImageProcessor,MobileNetV2FeatureExtractor:()=>b.MobileNetV2FeatureExtractor,MobileNetV2ImageProcessor:()=>b.MobileNetV2ImageProcessor,MobileNetV3FeatureExtractor:()=>F.MobileNetV3FeatureExtractor,MobileNetV3ImageProcessor:()=>F.MobileNetV3ImageProcessor,MobileNetV4FeatureExtractor:()=>k.MobileNetV4FeatureExtractor,MobileNetV4ImageProcessor:()=>k.MobileNetV4ImageProcessor,MobileViTFeatureExtractor:()=>y.MobileViTFeatureExtractor,MobileViTImageProcessor:()=>y.MobileViTImageProcessor,NougatImageProcessor:()=>v.NougatImageProcessor,OwlViTFeatureExtractor:()=>S.OwlViTFeatureExtractor,OwlViTImageProcessor:()=>S.OwlViTImageProcessor,Owlv2ImageProcessor:()=>C.Owlv2ImageProcessor,Phi3VImageProcessor:()=>E.Phi3VImageProcessor,PvtImageProcessor:()=>A.PvtImageProcessor,Qwen2VLImageProcessor:()=>L.Qwen2VLImageProcessor,RTDetrImageProcessor:()=>I.RTDetrImageProcessor,SamImageProcessor:()=>D.SamImageProcessor,SegformerFeatureExtractor:()=>z.SegformerFeatureExtractor,SegformerImageProcessor:()=>z.SegformerImageProcessor,SiglipImageProcessor:()=>j.SiglipImageProcessor,SmolVLMImageProcessor:()=>V.SmolVLMImageProcessor,Swin2SRImageProcessor:()=>O.Swin2SRImageProcessor,VLMImageProcessor:()=>g.VLMImageProcessor,ViTFeatureExtractor:()=>N.ViTFeatureExtractor,ViTImageProcessor:()=>N.ViTImageProcessor,VitMatteImageProcessor:()=>B.VitMatteImageProcessor,VitPoseImageProcessor:()=>G.VitPoseImageProcessor,YolosFeatureExtractor:()=>R.YolosFeatureExtractor,YolosImageProcessor:()=>R.YolosImageProcessor});var n=r(/*! ./beit/image_processing_beit.js */"./src/models/beit/image_processing_beit.js"),o=r(/*! ./bit/image_processing_bit.js */"./src/models/bit/image_processing_bit.js"),s=r(/*! ./chinese_clip/image_processing_chinese_clip.js */"./src/models/chinese_clip/image_processing_chinese_clip.js"),i=r(/*! ./clip/image_processing_clip.js */"./src/models/clip/image_processing_clip.js"),a=r(/*! ./convnext/image_processing_convnext.js */"./src/models/convnext/image_processing_convnext.js"),l=r(/*! ./deit/image_processing_deit.js */"./src/models/deit/image_processing_deit.js"),c=r(/*! ./detr/image_processing_detr.js */"./src/models/detr/image_processing_detr.js"),u=r(/*! ./dinov3_vit/image_processing_dinov3_vit.js */"./src/models/dinov3_vit/image_processing_dinov3_vit.js"),d=r(/*! ./donut/image_processing_donut.js */"./src/models/donut/image_processing_donut.js"),m=r(/*! ./dpt/image_processing_dpt.js */"./src/models/dpt/image_processing_dpt.js"),p=r(/*! ./efficientnet/image_processing_efficientnet.js */"./src/models/efficientnet/image_processing_efficientnet.js"),_=r(/*! ./glpn/image_processing_glpn.js */"./src/models/glpn/image_processing_glpn.js"),h=r(/*! ./grounding_dino/image_processing_grounding_dino.js */"./src/models/grounding_dino/image_processing_grounding_dino.js"),f=r(/*! ./idefics3/image_processing_idefics3.js */"./src/models/idefics3/image_processing_idefics3.js"),g=r(/*! ./janus/image_processing_janus.js */"./src/models/janus/image_processing_janus.js"),M=r(/*! ./jina_clip/image_processing_jina_clip.js */"./src/models/jina_clip/image_processing_jina_clip.js"),w=r(/*! ./llava_onevision/image_processing_llava_onevision.js */"./src/models/llava_onevision/image_processing_llava_onevision.js"),T=r(/*! ./mask2former/image_processing_mask2former.js */"./src/models/mask2former/image_processing_mask2former.js"),x=r(/*! ./maskformer/image_processing_maskformer.js */"./src/models/maskformer/image_processing_maskformer.js"),P=r(/*! ./mobilenet_v1/image_processing_mobilenet_v1.js */"./src/models/mobilenet_v1/image_processing_mobilenet_v1.js"),b=r(/*! ./mobilenet_v2/image_processing_mobilenet_v2.js */"./src/models/mobilenet_v2/image_processing_mobilenet_v2.js"),F=r(/*! ./mobilenet_v3/image_processing_mobilenet_v3.js */"./src/models/mobilenet_v3/image_processing_mobilenet_v3.js"),k=r(/*! ./mobilenet_v4/image_processing_mobilenet_v4.js */"./src/models/mobilenet_v4/image_processing_mobilenet_v4.js"),y=r(/*! ./mobilevit/image_processing_mobilevit.js */"./src/models/mobilevit/image_processing_mobilevit.js"),v=r(/*! ./nougat/image_processing_nougat.js */"./src/models/nougat/image_processing_nougat.js"),C=r(/*! ./owlv2/image_processing_owlv2.js */"./src/models/owlv2/image_processing_owlv2.js"),S=r(/*! ./owlvit/image_processing_owlvit.js */"./src/models/owlvit/image_processing_owlvit.js"),E=r(/*! ./phi3_v/image_processing_phi3_v.js */"./src/models/phi3_v/image_processing_phi3_v.js"),A=r(/*! ./pvt/image_processing_pvt.js */"./src/models/pvt/image_processing_pvt.js"),L=r(/*! ./qwen2_vl/image_processing_qwen2_vl.js */"./src/models/qwen2_vl/image_processing_qwen2_vl.js"),I=r(/*! ./rt_detr/image_processing_rt_detr.js */"./src/models/rt_detr/image_processing_rt_detr.js"),D=r(/*! ./sam/image_processing_sam.js */"./src/models/sam/image_processing_sam.js"),z=r(/*! ./segformer/image_processing_segformer.js */"./src/models/segformer/image_processing_segformer.js"),j=r(/*! ./siglip/image_processing_siglip.js */"./src/models/siglip/image_processing_siglip.js"),V=r(/*! ./smolvlm/image_processing_smolvlm.js */"./src/models/smolvlm/image_processing_smolvlm.js"),O=r(/*! ./swin2sr/image_processing_swin2sr.js */"./src/models/swin2sr/image_processing_swin2sr.js"),N=r(/*! ./vit/image_processing_vit.js */"./src/models/vit/image_processing_vit.js"),B=r(/*! ./vitmatte/image_processing_vitmatte.js */"./src/models/vitmatte/image_processing_vitmatte.js"),G=r(/*! ./vitpose/image_processing_vitpose.js */"./src/models/vitpose/image_processing_vitpose.js"),R=r(/*! ./yolos/image_processing_yolos.js */"./src/models/yolos/image_processing_yolos.js")},"./src/models/janus/image_processing_janus.js":/*!****************************************************!*\
  !*** ./src/models/janus/image_processing_janus.js ***!
  \****************************************************/(e,t,r)=>{r.r(t),r.d(t,{VLMImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{constructor(e){super({do_pad:!0,pad_size:{width:e.image_size,height:e.image_size},...e}),this.constant_values=this.config.background_color.map(e=>e*this.rescale_factor)}pad_image(e,t,r,n){return super.pad_image(e,t,r,{constant_values:this.constant_values,center:!0,...n})}}},"./src/models/janus/processing_janus.js":/*!**********************************************!*\
  !*** ./src/models/janus/processing_janus.js ***!
  \**********************************************/(e,t,r)=>{r.r(t),r.d(t,{VLChatProcessor:()=>c});var n=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),o=r(/*! ../auto/image_processing_auto.js */"./src/models/auto/image_processing_auto.js"),s=r(/*! ../../tokenizers.js */"./src/tokenizers.js"),i=r(/*! ../../utils/core.js */"./src/utils/core.js"),a=r(/*! ../../utils/tensor.js */"./src/utils/tensor.js"),l=r(/*! ../../utils/image.js */"./src/utils/image.js");class c extends n.Processor{static image_processor_class=o.AutoImageProcessor;static tokenizer_class=s.AutoTokenizer;static uses_processor_config=!0;constructor(e,t,r){super(e,t,r),this.image_tag=this.config.image_tag,this.image_start_tag=this.config.image_start_tag,this.image_end_tag=this.config.image_end_tag,this.num_image_tokens=this.config.num_image_tokens}async _call(e,{images:t=null,chat_template:r="default"}={}){t?Array.isArray(t)||(t=[t]):t=await Promise.all(e.filter(e=>e.images).flatMap(e=>e.images).map(e=>l.RawImage.read(e)));let n=this.tokenizer,o=n.apply_chat_template(e,{tokenize:!1,add_generation_prompt:!0,chat_template:r}),s=e=>n.encode(e,{add_special_tokens:!1}),c=o.split(this.image_tag),u=c.length-1;if(t.length!==u)throw Error(`Number of images provided (${t.length}) does not match number of "${this.image_tag}" image tags (${u})`);let[d,m,p]=n.model.convert_tokens_to_ids([this.image_tag,this.image_start_tag,this.image_end_tag]),_=s(c[0]),h=Array(_.length).fill(!1);for(let e=1;e<c.length;++e){let t=Array(this.num_image_tokens).fill(d),r=s(c[e]);_=(0,i.mergeArrays)(_,[m],t,[p],r);let n=Array(this.num_image_tokens).fill(!0);h=(0,i.mergeArrays)(h,[!1],n,[!1],Array(r.length).fill(!1))}let f=[1,_.length],g={input_ids:new a.Tensor("int64",_,f),attention_mask:new a.Tensor("int64",Array(_.length).fill(1),f),images_seq_mask:new a.Tensor("bool",h,f),images_emb_mask:new a.Tensor("bool",Array(u*this.num_image_tokens).fill(!0),[1,u,this.num_image_tokens])};if(t&&t.length>0){let e=await this.image_processor(t);return e.pixel_values.unsqueeze_(0),{...g,...e}}return g}}},"./src/models/jina_clip/image_processing_jina_clip.js":/*!************************************************************!*\
  !*** ./src/models/jina_clip/image_processing_jina_clip.js ***!
  \************************************************************/(e,t,r)=>{r.r(t),r.d(t,{JinaCLIPImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{constructor(e){let{resize_mode:t,fill_color:r,interpolation:n,size:o,...s}=e;super({...s,size:"squash"===t?{width:o,height:o}:"shortest"===t?{shortest_edge:o}:{longest_edge:o},resample:"bicubic"===n?3:2,do_center_crop:!0,crop_size:o,do_normalize:!0})}}},"./src/models/jina_clip/processing_jina_clip.js":/*!******************************************************!*\
  !*** ./src/models/jina_clip/processing_jina_clip.js ***!
  \******************************************************/(e,t,r)=>{r.r(t),r.d(t,{JinaCLIPProcessor:()=>i});var n=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),o=r(/*! ../auto/image_processing_auto.js */"./src/models/auto/image_processing_auto.js"),s=r(/*! ../../tokenizers.js */"./src/tokenizers.js");class i extends n.Processor{static tokenizer_class=s.AutoTokenizer;static image_processor_class=o.AutoImageProcessor;async _call(e=null,t=null,r={}){if(!e&&!t)throw Error("Either text or images must be provided");let n=e?this.tokenizer(e,r):{},o=t?await this.image_processor(t,r):{};return{...n,...o}}}},"./src/models/llava/processing_llava.js":/*!**********************************************!*\
  !*** ./src/models/llava/processing_llava.js ***!
  \**********************************************/(e,t,r)=>{r.r(t),r.d(t,{LlavaProcessor:()=>i});var n=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),o=r(/*! ../auto/image_processing_auto.js */"./src/models/auto/image_processing_auto.js"),s=r(/*! ../../tokenizers.js */"./src/tokenizers.js");class i extends n.Processor{static tokenizer_class=s.AutoTokenizer;static image_processor_class=o.AutoImageProcessor;static uses_processor_config=!0;async _call(e,t=null,r={}){let n=await this.image_processor(e,r);if(t){let[e,r]=n.pixel_values.dims.slice(-2),{image_token:o,patch_size:s,num_additional_image_tokens:i}=this.config,a=Math.floor(e/s)*Math.floor(r/s)+i;Array.isArray(t=structuredClone(t))||(t=[t]);for(let e=0;e<t.length;++e)t[e]=t[e].replace(o,o.repeat(a))}let o=t?this.tokenizer(t,r):{};return{...n,...o}}}},"./src/models/llava_onevision/image_processing_llava_onevision.js":/*!************************************************************************!*\
  !*** ./src/models/llava_onevision/image_processing_llava_onevision.js ***!
  \************************************************************************/(e,t,r)=>{r.r(t),r.d(t,{LlavaOnevisionImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}},"./src/models/mask2former/image_processing_mask2former.js":/*!****************************************************************!*\
  !*** ./src/models/mask2former/image_processing_mask2former.js ***!
  \****************************************************************/(e,t,r)=>{r.r(t),r.d(t,{Mask2FormerImageProcessor:()=>o});var n=r(/*! ../maskformer/image_processing_maskformer.js */"./src/models/maskformer/image_processing_maskformer.js");class o extends n.MaskFormerImageProcessor{}},"./src/models/maskformer/image_processing_maskformer.js":/*!**************************************************************!*\
  !*** ./src/models/maskformer/image_processing_maskformer.js ***!
  \**************************************************************/(e,t,r)=>{r.r(t),r.d(t,{MaskFormerFeatureExtractor:()=>s,MaskFormerImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{post_process_panoptic_segmentation(...e){return(0,n.post_process_panoptic_segmentation)(...e)}post_process_instance_segmentation(...e){return(0,n.post_process_instance_segmentation)(...e)}}class s extends o{}},"./src/models/mgp_str/processing_mgp_str.js":/*!**************************************************!*\
  !*** ./src/models/mgp_str/processing_mgp_str.js ***!
  \**************************************************/(e,t,r)=>{r.r(t),r.d(t,{MgpstrProcessor:()=>l});var n=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),o=r(/*! ../auto/image_processing_auto.js */"./src/models/auto/image_processing_auto.js"),s=r(/*! ../../tokenizers.js */"./src/tokenizers.js"),i=r(/*! ../../utils/maths.js */"./src/utils/maths.js");let a={char:["char_decode",1],bpe:["bpe_decode",2],wp:["wp_decode",102]};class l extends n.Processor{static tokenizer_class=s.AutoTokenizer;static image_processor_class=o.AutoImageProcessor;get char_tokenizer(){return this.components.char_tokenizer}get bpe_tokenizer(){return this.components.bpe_tokenizer}get wp_tokenizer(){return this.components.wp_tokenizer}_decode_helper(e,t){if(!a.hasOwnProperty(t))throw Error(`Format ${t} is not supported.`);let[r,n]=a[t],o=this[r].bind(this),[s,l]=e.dims,c=[],u=[],d=e.tolist();for(let e=0;e<s;++e){let t=d[e],r=[],o=[];for(let e=1;e<l;++e){let[s,a]=(0,i.max)((0,i.softmax)(t[e]));if(o.push(s),a==n)break;r.push(a)}let s=o.length>0?o.reduce((e,t)=>e*t,1):0;u.push(r),c.push(s)}return[o(u),c]}char_decode(e){return this.char_tokenizer.batch_decode(e).map(e=>e.replaceAll(" ",""))}bpe_decode(e){return this.bpe_tokenizer.batch_decode(e)}wp_decode(e){return this.wp_tokenizer.batch_decode(e).map(e=>e.replaceAll(" ",""))}batch_decode([e,t,r]){let[n,o]=this._decode_helper(e,"char"),[s,a]=this._decode_helper(t,"bpe"),[l,c]=this._decode_helper(r,"wp"),u=[],d=[];for(let e=0;e<n.length;++e){let[t,r]=(0,i.max)([o[e],a[e],c[e]]);u.push([n[e],s[e],l[e]][r]),d.push(t)}return{generated_text:u,scores:d,char_preds:n,bpe_preds:s,wp_preds:l}}static async from_pretrained(...e){let t=await super.from_pretrained(...e),r=await s.AutoTokenizer.from_pretrained("Xenova/gpt2"),n=await s.AutoTokenizer.from_pretrained("Xenova/bert-base-uncased");return t.components={image_processor:t.image_processor,char_tokenizer:t.tokenizer,bpe_tokenizer:r,wp_tokenizer:n},t}async _call(e,t=null){let r=await this.image_processor(e);return t&&(r.labels=this.tokenizer(t).input_ids),r}}},"./src/models/mobilenet_v1/image_processing_mobilenet_v1.js":/*!******************************************************************!*\
  !*** ./src/models/mobilenet_v1/image_processing_mobilenet_v1.js ***!
  \******************************************************************/(e,t,r)=>{r.r(t),r.d(t,{MobileNetV1FeatureExtractor:()=>s,MobileNetV1ImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}class s extends o{}},"./src/models/mobilenet_v2/image_processing_mobilenet_v2.js":/*!******************************************************************!*\
  !*** ./src/models/mobilenet_v2/image_processing_mobilenet_v2.js ***!
  \******************************************************************/(e,t,r)=>{r.r(t),r.d(t,{MobileNetV2FeatureExtractor:()=>s,MobileNetV2ImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}class s extends o{}},"./src/models/mobilenet_v3/image_processing_mobilenet_v3.js":/*!******************************************************************!*\
  !*** ./src/models/mobilenet_v3/image_processing_mobilenet_v3.js ***!
  \******************************************************************/(e,t,r)=>{r.r(t),r.d(t,{MobileNetV3FeatureExtractor:()=>s,MobileNetV3ImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}class s extends o{}},"./src/models/mobilenet_v4/image_processing_mobilenet_v4.js":/*!******************************************************************!*\
  !*** ./src/models/mobilenet_v4/image_processing_mobilenet_v4.js ***!
  \******************************************************************/(e,t,r)=>{r.r(t),r.d(t,{MobileNetV4FeatureExtractor:()=>s,MobileNetV4ImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}class s extends o{}},"./src/models/mobilevit/image_processing_mobilevit.js":/*!************************************************************!*\
  !*** ./src/models/mobilevit/image_processing_mobilevit.js ***!
  \************************************************************/(e,t,r)=>{r.r(t),r.d(t,{MobileViTFeatureExtractor:()=>s,MobileViTImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}class s extends o{}},"./src/models/moonshine/feature_extraction_moonshine.js":/*!**************************************************************!*\
  !*** ./src/models/moonshine/feature_extraction_moonshine.js ***!
  \**************************************************************/(e,t,r)=>{r.r(t),r.d(t,{MoonshineFeatureExtractor:()=>s});var n=r(/*! ../../base/feature_extraction_utils.js */"./src/base/feature_extraction_utils.js"),o=r(/*! ../../utils/tensor.js */"./src/utils/tensor.js");class s extends n.FeatureExtractor{async _call(e){(0,n.validate_audio_inputs)(e,"MoonshineFeatureExtractor"),e instanceof Float64Array&&(e=new Float32Array(e));let t=[1,e.length];return{input_values:new o.Tensor("float32",e,t)}}}},"./src/models/moonshine/processing_moonshine.js":/*!******************************************************!*\
  !*** ./src/models/moonshine/processing_moonshine.js ***!
  \******************************************************/(e,t,r)=>{r.r(t),r.d(t,{MoonshineProcessor:()=>i});var n=r(/*! ../auto/feature_extraction_auto.js */"./src/models/auto/feature_extraction_auto.js"),o=r(/*! ../../tokenizers.js */"./src/tokenizers.js"),s=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js");class i extends s.Processor{static tokenizer_class=o.AutoTokenizer;static feature_extractor_class=n.AutoFeatureExtractor;async _call(e){return await this.feature_extractor(e)}}},"./src/models/nougat/image_processing_nougat.js":/*!******************************************************!*\
  !*** ./src/models/nougat/image_processing_nougat.js ***!
  \******************************************************/(e,t,r)=>{r.r(t),r.d(t,{NougatImageProcessor:()=>o});var n=r(/*! ../donut/image_processing_donut.js */"./src/models/donut/image_processing_donut.js");class o extends n.DonutImageProcessor{}},"./src/models/owlv2/image_processing_owlv2.js":/*!****************************************************!*\
  !*** ./src/models/owlv2/image_processing_owlv2.js ***!
  \****************************************************/(e,t,r)=>{r.r(t),r.d(t,{Owlv2ImageProcessor:()=>o});var n=r(/*! ../owlvit/image_processing_owlvit.js */"./src/models/owlvit/image_processing_owlvit.js");class o extends n.OwlViTImageProcessor{}},"./src/models/owlvit/image_processing_owlvit.js":/*!******************************************************!*\
  !*** ./src/models/owlvit/image_processing_owlvit.js ***!
  \******************************************************/(e,t,r)=>{r.r(t),r.d(t,{OwlViTFeatureExtractor:()=>s,OwlViTImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{post_process_object_detection(...e){return(0,n.post_process_object_detection)(...e)}}class s extends o{}},"./src/models/owlvit/processing_owlvit.js":/*!************************************************!*\
  !*** ./src/models/owlvit/processing_owlvit.js ***!
  \************************************************/(e,t,r)=>{r.r(t),r.d(t,{OwlViTProcessor:()=>i});var n=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),o=r(/*! ../auto/image_processing_auto.js */"./src/models/auto/image_processing_auto.js"),s=r(/*! ../../tokenizers.js */"./src/tokenizers.js");class i extends n.Processor{static tokenizer_class=s.AutoTokenizer;static image_processor_class=o.AutoImageProcessor}},"./src/models/paligemma/processing_paligemma.js":/*!******************************************************!*\
  !*** ./src/models/paligemma/processing_paligemma.js ***!
  \******************************************************/(e,t,r)=>{r.r(t),r.d(t,{PaliGemmaProcessor:()=>a});var n=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),o=r(/*! ../auto/image_processing_auto.js */"./src/models/auto/image_processing_auto.js"),s=r(/*! ../../tokenizers.js */"./src/tokenizers.js");let i="<image>";class a extends n.Processor{static tokenizer_class=s.AutoTokenizer;static image_processor_class=o.AutoImageProcessor;static uses_processor_config=!1;async _call(e,t=null,r={}){let n;t||(console.warn("You are using PaliGemma without a text prefix. It will perform as a picture-captioning model."),t=""),Array.isArray(e)||(e=[e]),Array.isArray(t)||(t=[t]);let o=this.tokenizer.bos_token,s=this.image_processor.config.image_seq_length;t.some(e=>e.includes(i))?n=t.map(e=>{let t=e.replaceAll(i,i.repeat(s)),r=t.lastIndexOf(i),n=-1===r?0:r+i.length;return t.slice(0,n)+o+t.slice(n)+"\n"}):(console.warn("You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens."),n=t.map(t=>{var r;return r=e.length,`${i.repeat(s*r)}${o}${t}
`}));let a=this.tokenizer(n,r);return{...await this.image_processor(e,r),...a}}}},"./src/models/phi3_v/image_processing_phi3_v.js":/*!******************************************************!*\
  !*** ./src/models/phi3_v/image_processing_phi3_v.js ***!
  \******************************************************/(e,t,r)=>{r.r(t),r.d(t,{Phi3VImageProcessor:()=>c});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js"),o=r(/*! ../../utils/tensor.js */"./src/utils/tensor.js");let s=[2,3],{ceil:i,floor:a,sqrt:l}=Math;class c extends n.ImageProcessor{constructor(e){super({...e,do_normalize:!0,do_pad:!0,pad_size:"custom",do_convert_rgb:!0,do_resize:!0}),this._num_crops=e.num_crops}calc_num_image_tokens_from_image_size(e,t){let{num_img_tokens:r}=this.config;return a((a(t/336)*a(e/336)+1)*r+1+(a(t/336)+1)*l(r))}get_resize_output_image_size(e,t){let r=this._num_crops,[n,o]=e.size,s=n/o,i=1;for(;i*Math.ceil(i/s)<=r;)i+=1;let a=Math.floor(336*(i-=1));return[a,Math.floor(a/s)]}pad_image(e,t,r,n={}){let[o,s]=t,a=336*i(o/336),l=336*i(s/336),c=[1,1,1].map((e,t)=>(e-this.image_mean[t])/this.image_std[t]);return super.pad_image(e,t,{width:l,height:a},{center:!0,constant_values:c,...n})}async _call(e,{num_crops:t=null}={}){if(this._num_crops=t??=this.config.num_crops,t<4||l(t)%1!=0)throw Error("num_crops must be a square number >= 4");Array.isArray(e)||(e=[e]);let r=e.length,n=await Promise.all(e.map(e=>this.preprocess(e))),c=n.map(e=>e.original_size),u=n.map(e=>e.reshaped_input_size),d=[];for(let{pixel_values:e}of n){e.unsqueeze_(0);let[r,n]=e.dims.slice(-2),i=await (0,o.interpolate_4d)(e,{size:[336,336],mode:"bicubic"});if(t>0){let c=[],u=l(t),m=a(n/u),p=a(r/u);for(let t=0;t<u;++t)for(let i=0;i<u;++i){let a,l,d,_;t===u-1?(l=r-p,_=r):(l=t*p,_=(t+1)*p),i===u-1?(a=n-m,d=n):(a=i*m,d=(i+1)*m);let h=[l,a],f=[_,d],g=await (0,o.slice)(e,h,f,s);c.push(g)}let _=await (0,o.interpolate_4d)((0,o.cat)(c,0),{size:[336,336],mode:"bicubic"});d.push((0,o.cat)([i,_],0))}else d.push(i)}let m=(0,o.stack)(d,0),p=u.map(e=>e.map(e=>336*i(e/336)));return{pixel_values:m,original_sizes:c,reshaped_input_sizes:u,image_sizes:new o.Tensor("int64",p.flat(),[r,2]),num_img_tokens:p.map(([e,t])=>this.calc_num_image_tokens_from_image_size(t,e))}}}},"./src/models/phi3_v/processing_phi3_v.js":/*!************************************************!*\
  !*** ./src/models/phi3_v/processing_phi3_v.js ***!
  \************************************************/(e,t,r)=>{r.r(t),r.d(t,{Phi3VProcessor:()=>l});var n=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),o=r(/*! ../auto/image_processing_auto.js */"./src/models/auto/image_processing_auto.js"),s=r(/*! ../../tokenizers.js */"./src/tokenizers.js");r(/*! ../../utils/image.js */"./src/utils/image.js");let i="<|image|>",a=/<\|image_\d+\|>/g;class l extends n.Processor{static image_processor_class=o.AutoImageProcessor;static tokenizer_class=s.AutoTokenizer;async _call(e,t=null,{padding:r=!0,truncation:n=!0,num_crops:o=null}={}){let s,l;if(Array.isArray(e)||(e=[e]),t){let{num_img_tokens:c}=l=await this.image_processor(t,{num_crops:o}),u=e.map((e,t)=>e.split(a).join(i.repeat(c[t])));s=this.tokenizer(u,{padding:r,truncation:n});let d=this.tokenizer.model.convert_tokens_to_ids([i])[0];s.input_ids.map_(e=>e==d?-e:e)}else s=this.tokenizer(e);return{...s,...l}}}},"./src/models/processors.js":/*!**********************************!*\
  !*** ./src/models/processors.js ***!
  \**********************************/(e,t,r)=>{r.r(t),r.d(t,{Florence2Processor:()=>n.Florence2Processor,Gemma3nProcessor:()=>o.Gemma3nProcessor,GroundingDinoProcessor:()=>s.GroundingDinoProcessor,Idefics3Processor:()=>i.Idefics3Processor,JinaCLIPProcessor:()=>l.JinaCLIPProcessor,LlavaProcessor:()=>c.LlavaProcessor,MgpstrProcessor:()=>u.MgpstrProcessor,MoonshineProcessor:()=>d.MoonshineProcessor,OwlViTProcessor:()=>m.OwlViTProcessor,PaliGemmaProcessor:()=>_.PaliGemmaProcessor,Phi3VProcessor:()=>p.Phi3VProcessor,PyAnnoteProcessor:()=>h.PyAnnoteProcessor,Qwen2VLProcessor:()=>f.Qwen2VLProcessor,SamProcessor:()=>g.SamProcessor,SmolVLMProcessor:()=>M.SmolVLMProcessor,SpeechT5Processor:()=>w.SpeechT5Processor,UltravoxProcessor:()=>T.UltravoxProcessor,VLChatProcessor:()=>a.VLChatProcessor,VoxtralProcessor:()=>x.VoxtralProcessor,Wav2Vec2Processor:()=>P.Wav2Vec2Processor,Wav2Vec2ProcessorWithLM:()=>b.Wav2Vec2ProcessorWithLM,WhisperProcessor:()=>F.WhisperProcessor});var n=r(/*! ./florence2/processing_florence2.js */"./src/models/florence2/processing_florence2.js"),o=r(/*! ./gemma3n/processing_gemma3n.js */"./src/models/gemma3n/processing_gemma3n.js"),s=r(/*! ./grounding_dino/processing_grounding_dino.js */"./src/models/grounding_dino/processing_grounding_dino.js"),i=r(/*! ./idefics3/processing_idefics3.js */"./src/models/idefics3/processing_idefics3.js"),a=r(/*! ./janus/processing_janus.js */"./src/models/janus/processing_janus.js"),l=r(/*! ./jina_clip/processing_jina_clip.js */"./src/models/jina_clip/processing_jina_clip.js"),c=r(/*! ./llava/processing_llava.js */"./src/models/llava/processing_llava.js"),u=r(/*! ./mgp_str/processing_mgp_str.js */"./src/models/mgp_str/processing_mgp_str.js"),d=r(/*! ./moonshine/processing_moonshine.js */"./src/models/moonshine/processing_moonshine.js"),m=r(/*! ./owlvit/processing_owlvit.js */"./src/models/owlvit/processing_owlvit.js"),p=r(/*! ./phi3_v/processing_phi3_v.js */"./src/models/phi3_v/processing_phi3_v.js"),_=r(/*! ./paligemma/processing_paligemma.js */"./src/models/paligemma/processing_paligemma.js"),h=r(/*! ./pyannote/processing_pyannote.js */"./src/models/pyannote/processing_pyannote.js"),f=r(/*! ./qwen2_vl/processing_qwen2_vl.js */"./src/models/qwen2_vl/processing_qwen2_vl.js"),g=r(/*! ./sam/processing_sam.js */"./src/models/sam/processing_sam.js"),M=r(/*! ./smolvlm/processing_smolvlm.js */"./src/models/smolvlm/processing_smolvlm.js"),w=r(/*! ./speecht5/processing_speecht5.js */"./src/models/speecht5/processing_speecht5.js"),T=r(/*! ./ultravox/processing_ultravox.js */"./src/models/ultravox/processing_ultravox.js"),x=r(/*! ./voxtral/processing_voxtral.js */"./src/models/voxtral/processing_voxtral.js"),P=r(/*! ./wav2vec2/processing_wav2vec2.js */"./src/models/wav2vec2/processing_wav2vec2.js"),b=r(/*! ./wav2vec2_with_lm/processing_wav2vec2_with_lm.js */"./src/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.js"),F=r(/*! ./whisper/processing_whisper.js */"./src/models/whisper/processing_whisper.js")},"./src/models/pvt/image_processing_pvt.js":/*!************************************************!*\
  !*** ./src/models/pvt/image_processing_pvt.js ***!
  \************************************************/(e,t,r)=>{r.r(t),r.d(t,{PvtImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}},"./src/models/pyannote/feature_extraction_pyannote.js":/*!************************************************************!*\
  !*** ./src/models/pyannote/feature_extraction_pyannote.js ***!
  \************************************************************/(e,t,r)=>{r.r(t),r.d(t,{PyAnnoteFeatureExtractor:()=>i});var n=r(/*! ../../base/feature_extraction_utils.js */"./src/base/feature_extraction_utils.js"),o=r(/*! ../../utils/tensor.js */"./src/utils/tensor.js"),s=r(/*! ../../utils/maths.js */"./src/utils/maths.js");class i extends n.FeatureExtractor{async _call(e){(0,n.validate_audio_inputs)(e,"PyAnnoteFeatureExtractor"),e instanceof Float64Array&&(e=new Float32Array(e));let t=[1,1,e.length];return{input_values:new o.Tensor("float32",e,t)}}samples_to_frames(e){return(e-this.config.offset)/this.config.step}post_process_speaker_diarization(e,t){let r=t/this.samples_to_frames(t)/this.config.sampling_rate,n=[];for(let t of e.tolist()){let e=[],o=-1;for(let r=0;r<t.length;++r){let n=(0,s.softmax)(t[r]),[i,a]=(0,s.max)(n),[l,c]=[r,r+1];a!==o?(o=a,e.push({id:a,start:l,end:c,score:i})):(e.at(-1).end=c,e.at(-1).score+=i)}n.push(e.map(({id:e,start:t,end:n,score:o})=>({id:e,start:t*r,end:n*r,confidence:o/(n-t)})))}return n}}},"./src/models/pyannote/processing_pyannote.js":/*!****************************************************!*\
  !*** ./src/models/pyannote/processing_pyannote.js ***!
  \****************************************************/(e,t,r)=>{r.r(t),r.d(t,{PyAnnoteProcessor:()=>s});var n=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),o=r(/*! ./feature_extraction_pyannote.js */"./src/models/pyannote/feature_extraction_pyannote.js");class s extends n.Processor{static feature_extractor_class=o.PyAnnoteFeatureExtractor;async _call(e){return await this.feature_extractor(e)}post_process_speaker_diarization(...e){return this.feature_extractor.post_process_speaker_diarization(...e)}get sampling_rate(){return this.feature_extractor.config.sampling_rate}}},"./src/models/qwen2_vl/image_processing_qwen2_vl.js":/*!**********************************************************!*\
  !*** ./src/models/qwen2_vl/image_processing_qwen2_vl.js ***!
  \**********************************************************/(e,t,r)=>{r.r(t),r.d(t,{Qwen2VLImageProcessor:()=>s});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js"),o=r(/*! ../../utils/tensor.js */"./src/utils/tensor.js");class s extends n.ImageProcessor{async _call(e,...t){let{pixel_values:r,original_sizes:n,reshaped_input_sizes:s}=await super._call(e,...t),i=r,{temporal_patch_size:a,merge_size:l,patch_size:c}=this.config;1===i.dims[0]&&(i=(0,o.cat)(Array.from({length:a},()=>i),0));let u=i.dims[0]/a,d=i.dims[1],m=Math.floor(i.dims[2]/c),p=Math.floor(i.dims[3]/c);return{pixel_values:i.view(u,a,d,Math.floor(m/l),l,c,Math.floor(p/l),l,c).permute(0,3,6,4,7,2,1,5,8).view(u*m*p,d*a*c*c),image_grid_thw:new o.Tensor("int64",[u,m,p],[1,3]),original_sizes:n,reshaped_input_sizes:s}}}},"./src/models/qwen2_vl/processing_qwen2_vl.js":/*!****************************************************!*\
  !*** ./src/models/qwen2_vl/processing_qwen2_vl.js ***!
  \****************************************************/(e,t,r)=>{r.r(t),r.d(t,{Qwen2VLProcessor:()=>i});var n=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),o=r(/*! ../auto/image_processing_auto.js */"./src/models/auto/image_processing_auto.js"),s=r(/*! ../../tokenizers.js */"./src/tokenizers.js");r(/*! ../../utils/image.js */"./src/utils/image.js");class i extends n.Processor{static image_processor_class=o.AutoImageProcessor;static tokenizer_class=s.AutoTokenizer;async _call(e,t=null,...r){let n,o;if(Array.isArray(e)||(e=[e]),t&&(o=(n=await this.image_processor(t)).image_grid_thw),o){let t=this.image_processor.config.merge_size**2,r=0,n=o.tolist();e=e.map(e=>{for(;e.includes("<|image_pad|>");){let o=Number(n[r++].reduce((e,t)=>e*t,1n));e=e.replace("<|image_pad|>","<|placeholder|>".repeat(Math.floor(o/t)))}return e.replaceAll("<|placeholder|>","<|image_pad|>")})}return{...this.tokenizer(e),...n}}}},"./src/models/rt_detr/image_processing_rt_detr.js":/*!********************************************************!*\
  !*** ./src/models/rt_detr/image_processing_rt_detr.js ***!
  \********************************************************/(e,t,r)=>{r.r(t),r.d(t,{RTDetrImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{post_process_object_detection(...e){return(0,n.post_process_object_detection)(...e)}}},"./src/models/sam/image_processing_sam.js":/*!************************************************!*\
  !*** ./src/models/sam/image_processing_sam.js ***!
  \************************************************/(e,t,r)=>{r.r(t),r.d(t,{SamImageProcessor:()=>i});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js"),o=r(/*! ../../utils/core.js */"./src/utils/core.js"),s=r(/*! ../../utils/tensor.js */"./src/utils/tensor.js");class i extends n.ImageProcessor{reshape_input_points(e,t,r,n=!1){e=structuredClone(e);let i=(0,o.calculateDimensions)(e);if(3===i.length)n||(i=[1,...i]),e=[e];else if(4!==i.length)throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");for(let n=0;n<e.length;++n){let o=t[n],s=r[n],i=[s[0]/o[0],s[1]/o[1]];for(let t=0;t<e[n].length;++t)for(let r=0;r<e[n][t].length;++r)for(let o=0;o<e[n][t][r].length;++o)e[n][t][r][o]*=i[o%2]}return new s.Tensor("float32",Float32Array.from(e.flat(1/0)),i)}add_input_labels(e,t){let r=(0,o.calculateDimensions)(e);if(2===r.length)r=[1,...r],e=[e];else if(3!==r.length)throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");if(r.some((e,r)=>e!==t.dims[r]))throw Error(`The first ${r.length} dimensions of 'input_points' and 'input_labels' must be the same.`);return new s.Tensor("int64",e.flat(1/0).map(BigInt),r)}async _call(e,{input_points:t=null,input_labels:r=null,input_boxes:n=null}={}){let o=await super._call(e);if(t&&(o.input_points=this.reshape_input_points(t,o.original_sizes,o.reshaped_input_sizes)),r){if(!o.input_points)throw Error("`input_points` must be provided if `input_labels` are provided.");o.input_labels=this.add_input_labels(r,o.input_points)}return n&&(o.input_boxes=this.reshape_input_points(n,o.original_sizes,o.reshaped_input_sizes,!0)),o}async post_process_masks(e,t,r,{mask_threshold:n=0,binarize:o=!0,pad_size:i=null}={}){let a=[],l=[(i=i??this.pad_size).height,i.width];for(let i=0;i<t.length;++i){let c=t[i],u=r[i],d=await (0,s.interpolate_4d)(e[i],{mode:"bilinear",size:l});if(d=d.slice(null,null,[0,u[0]],[0,u[1]]),d=await (0,s.interpolate_4d)(d,{mode:"bilinear",size:c}),o){let e=d.data,t=new Uint8Array(e.length);for(let r=0;r<e.length;++r)e[r]>n&&(t[r]=1);d=new s.Tensor("bool",t,d.dims)}a.push(d)}return a}generate_crop_boxes(e,t,{crop_n_layers:r=0,overlap_ratio:n=512/1500,points_per_crop:o=32,crop_n_points_downscale_factor:s=1}={}){}}},"./src/models/sam/processing_sam.js":/*!******************************************!*\
  !*** ./src/models/sam/processing_sam.js ***!
  \******************************************/(e,t,r)=>{r.r(t),r.d(t,{SamProcessor:()=>s});var n=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),o=r(/*! ../auto/image_processing_auto.js */"./src/models/auto/image_processing_auto.js");class s extends n.Processor{static image_processor_class=o.AutoImageProcessor;async _call(...e){return await this.image_processor(...e)}post_process_masks(...e){return this.image_processor.post_process_masks(...e)}reshape_input_points(...e){return this.image_processor.reshape_input_points(...e)}}},"./src/models/seamless_m4t/feature_extraction_seamless_m4t.js":/*!********************************************************************!*\
  !*** ./src/models/seamless_m4t/feature_extraction_seamless_m4t.js ***!
  \********************************************************************/(e,t,r)=>{r.r(t),r.d(t,{SeamlessM4TFeatureExtractor:()=>i});var n=r(/*! ../../base/feature_extraction_utils.js */"./src/base/feature_extraction_utils.js"),o=r(/*! ../../utils/tensor.js */"./src/utils/tensor.js"),s=r(/*! ../../utils/audio.js */"./src/utils/audio.js");class i extends n.FeatureExtractor{constructor(e){super(e);let t=this.config.sampling_rate,r=(0,s.mel_filter_bank)(257,this.config.num_mel_bins,20,Math.floor(t/2),t,null,"kaldi",!0);this.mel_filters=r,this.window=(0,s.window_function)(400,"povey",{periodic:!1})}async _extract_fbank_features(e,t){return e=e.map(e=>32768*e),(0,s.spectrogram)(e,this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1192092955078125e-22,remove_dc_offset:!0,max_num_frames:t,transpose:!0})}async _call(e,{padding:t=!0,pad_to_multiple_of:r=2,do_normalize_per_mel_bins:s=!0,return_attention_mask:i=!0}={}){let a;(0,n.validate_audio_inputs)(e,"SeamlessM4TFeatureExtractor");let l=await this._extract_fbank_features(e,this.config.max_length);if(s){let[e,t]=l.dims,r=l.data;for(let n=0;n<t;++n){let o=0;for(let s=0;s<e;++s)o+=r[s*t+n];let s=o/e,i=0;for(let o=0;o<e;++o)i+=(r[o*t+n]-s)**2;let a=Math.sqrt((i/=e-1)+1e-7);for(let o=0;o<e;++o){let e=o*t+n;r[e]=(r[e]-s)/a}}}if(t){let[e,t]=l.dims,n=l.data,s=e%r;if(s>0){let r=new Float32Array(t*(e+s));r.set(n),r.fill(this.config.padding_value,n.length);let c=e+s;l=new o.Tensor(l.type,r,[c,t]),i&&(a=new o.Tensor("int64",new BigInt64Array(c),[1,c])).data.fill(1n,0,e)}}let[c,u]=l.dims,d=this.config.stride;if(0!=c%d)throw Error(`The number of frames (${c}) must be a multiple of the stride (${d}).`);let m=l.view(1,Math.floor(c/d),u*d),p={input_features:m};if(i){let e=m.dims[1],t=new BigInt64Array(e);if(a){let e=a.data;for(let r=1,n=0;r<c;r+=d,++n)t[n]=e[r]}else t.fill(1n);p.attention_mask=new o.Tensor("int64",t,[1,e])}return p}}},"./src/models/segformer/image_processing_segformer.js":/*!************************************************************!*\
  !*** ./src/models/segformer/image_processing_segformer.js ***!
  \************************************************************/(e,t,r)=>{r.r(t),r.d(t,{SegformerFeatureExtractor:()=>s,SegformerImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{post_process_semantic_segmentation(...e){return(0,n.post_process_semantic_segmentation)(...e)}}class s extends o{}},"./src/models/siglip/image_processing_siglip.js":/*!******************************************************!*\
  !*** ./src/models/siglip/image_processing_siglip.js ***!
  \******************************************************/(e,t,r)=>{r.r(t),r.d(t,{SiglipImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}},"./src/models/smolvlm/image_processing_smolvlm.js":/*!********************************************************!*\
  !*** ./src/models/smolvlm/image_processing_smolvlm.js ***!
  \********************************************************/(e,t,r)=>{r.r(t),r.d(t,{SmolVLMImageProcessor:()=>n.Idefics3ImageProcessor});var n=r(/*! ../idefics3/image_processing_idefics3.js */"./src/models/idefics3/image_processing_idefics3.js")},"./src/models/smolvlm/processing_smolvlm.js":/*!**************************************************!*\
  !*** ./src/models/smolvlm/processing_smolvlm.js ***!
  \**************************************************/(e,t,r)=>{r.r(t),r.d(t,{SmolVLMProcessor:()=>n.Idefics3Processor});var n=r(/*! ../idefics3/processing_idefics3.js */"./src/models/idefics3/processing_idefics3.js")},"./src/models/snac/feature_extraction_snac.js":/*!****************************************************!*\
  !*** ./src/models/snac/feature_extraction_snac.js ***!
  \****************************************************/(e,t,r)=>{r.r(t),r.d(t,{SnacFeatureExtractor:()=>o});var n=r(/*! ../dac/feature_extraction_dac.js */"./src/models/dac/feature_extraction_dac.js");class o extends n.DacFeatureExtractor{}},"./src/models/speecht5/feature_extraction_speecht5.js":/*!************************************************************!*\
  !*** ./src/models/speecht5/feature_extraction_speecht5.js ***!
  \************************************************************/(e,t,r)=>{r.r(t),r.d(t,{SpeechT5FeatureExtractor:()=>o});var n=r(/*! ../../base/feature_extraction_utils.js */"./src/base/feature_extraction_utils.js");class o extends n.FeatureExtractor{}},"./src/models/speecht5/processing_speecht5.js":/*!****************************************************!*\
  !*** ./src/models/speecht5/processing_speecht5.js ***!
  \****************************************************/(e,t,r)=>{r.r(t),r.d(t,{SpeechT5Processor:()=>i});var n=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),o=r(/*! ../../tokenizers.js */"./src/tokenizers.js"),s=r(/*! ../auto/feature_extraction_auto.js */"./src/models/auto/feature_extraction_auto.js");class i extends n.Processor{static tokenizer_class=o.AutoTokenizer;static feature_extractor_class=s.AutoFeatureExtractor;async _call(e){return await this.feature_extractor(e)}}},"./src/models/swin2sr/image_processing_swin2sr.js":/*!********************************************************!*\
  !*** ./src/models/swin2sr/image_processing_swin2sr.js ***!
  \********************************************************/(e,t,r)=>{r.r(t),r.d(t,{Swin2SRImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{pad_image(e,t,r,n={}){let[o,s,i]=t;return super.pad_image(e,t,{width:s+(r-s%r)%r,height:o+(r-o%r)%r},{mode:"symmetric",center:!1,constant_values:-1,...n})}}},"./src/models/ultravox/processing_ultravox.js":/*!****************************************************!*\
  !*** ./src/models/ultravox/processing_ultravox.js ***!
  \****************************************************/(e,t,r)=>{r.r(t),r.d(t,{UltravoxProcessor:()=>i});var n=r(/*! ../auto/feature_extraction_auto.js */"./src/models/auto/feature_extraction_auto.js"),o=r(/*! ../../tokenizers.js */"./src/tokenizers.js"),s=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js");class i extends s.Processor{static tokenizer_class=o.AutoTokenizer;static feature_extractor_class=n.AutoFeatureExtractor;static uses_processor_config=!0;async _call(e,t=null,r={}){if(Array.isArray(e))throw Error("Batched inputs are not supported yet.");let n={};if(t){let o=t.length,{input_features:s}=await this.feature_extractor(t,{...r,max_length:o}),i=1+Math.ceil(Math.round(o/this.config.encoder_ds_factor+1e-4)/this.config.stack_factor);n.audio_token_len=[i],n.audio_values=s;let a=this.config.audio_placeholder;if(!e.includes(a))throw Error(`The input text does not contain the image token ${a}.`);e=e.replaceAll(a,a.repeat(i))}return{...this.tokenizer(e,{add_special_tokens:!1,...r}),...n}}}},"./src/models/vit/image_processing_vit.js":/*!************************************************!*\
  !*** ./src/models/vit/image_processing_vit.js ***!
  \************************************************/(e,t,r)=>{r.r(t),r.d(t,{ViTFeatureExtractor:()=>s,ViTImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{}class s extends o{}},"./src/models/vitmatte/image_processing_vitmatte.js":/*!**********************************************************!*\
  !*** ./src/models/vitmatte/image_processing_vitmatte.js ***!
  \**********************************************************/(e,t,r)=>{r.r(t),r.d(t,{VitMatteImageProcessor:()=>s});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js"),o=r(/*! ../../utils/tensor.js */"./src/utils/tensor.js");class s extends n.ImageProcessor{async _call(e,t){Array.isArray(e)||(e=[e]),Array.isArray(t)||(t=[t]);let r=await Promise.all(e.map(e=>this.preprocess(e))),n=await Promise.all(t.map(e=>this.preprocess(e,{do_normalize:!1,do_convert_rgb:!1,do_convert_grayscale:!0})));return{pixel_values:(0,o.stack)(r.map((e,t)=>(0,o.cat)([e.pixel_values,n[t].pixel_values],0)),0),original_sizes:r.map(e=>e.original_size),reshaped_input_sizes:r.map(e=>e.reshaped_input_size)}}}},"./src/models/vitpose/image_processing_vitpose.js":/*!********************************************************!*\
  !*** ./src/models/vitpose/image_processing_vitpose.js ***!
  \********************************************************/(e,t,r)=>{r.r(t),r.d(t,{VitPoseImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{post_process_pose_estimation(e,t,{threshold:r=null}={}){let n=e.tolist(),[o,s,i,a]=e.dims,l=[];for(let e=0;e<o;++e){let o=n[e],s=t[e],c=[];for(let e=0;e<s.length;++e){let t=s[e],n=[],l=[],u=[],d=t.at(-2)/a,m=t.at(-1)/i;for(let e=0;e<o.length;++e){let[t,s]=[0,0],i=0,a=-1/0,c=o[e];for(let e=0;e<c.length;++e){let r=c[e];for(let n=0;n<r.length;++n){let o=r[n];i+=o,a=Math.max(a,o),t+=(n+.5)*o,s+=e*o}}if(null!=r&&a<r)continue;let p=[d*t/i,m*s/i];n.push(p),u.push(e),l.push(a)}c.push({bbox:t,scores:l,labels:u,keypoints:n})}l.push(c)}return l}}},"./src/models/voxtral/processing_voxtral.js":/*!**************************************************!*\
  !*** ./src/models/voxtral/processing_voxtral.js ***!
  \**************************************************/(e,t,r)=>{r.r(t),r.d(t,{VoxtralProcessor:()=>l});var n=r(/*! ../auto/feature_extraction_auto.js */"./src/models/auto/feature_extraction_auto.js"),o=r(/*! ../../tokenizers.js */"./src/tokenizers.js"),s=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js"),i=r(/*! ../../utils/tensor.js */"./src/utils/tensor.js");let a="[AUDIO]";class l extends s.Processor{static tokenizer_class=o.AutoTokenizer;static feature_extractor_class=n.AutoFeatureExtractor;static uses_processor_config=!1;async _call(e,t=null,r={}){if(Array.isArray(e))throw Error("Batched inputs are not supported yet.");let n={};if(t){if(!e.includes(a))throw Error(`The input text does not contain the audio token ${a}.`);Array.isArray(t)||(t=[t]);let o=e.split(a),s=o.length-1;if(s!==t.length)throw Error(`The number of audio inputs (${t.length}) does not match the number of audio tokens in the text (${s}).`);let l=this.feature_extractor.config.n_samples,c=t.map(e=>(function(e,t){let r=[];for(let n=0;n<e.length;n+=t)r.push(e.subarray(n,Math.min(n+t,e.length)));return r})(e,l)),u=c.map(e=>e.length),d=c.flat(),m=(await Promise.all(d.map(e=>this.feature_extractor(e,r)))).map(e=>e.input_features);n.audio_values=m.length>1?(0,i.cat)(m,0):m[0];let p=o[0];for(let e=0;e<u.length;++e){p+="[BEGIN_AUDIO]";for(let t=0;t<u[e];++t)p+=a.repeat(375);p+=o[e+1]}e=p}return{...this.tokenizer(e,{add_special_tokens:!1,...r}),...n}}}},"./src/models/wav2vec2/feature_extraction_wav2vec2.js":/*!************************************************************!*\
  !*** ./src/models/wav2vec2/feature_extraction_wav2vec2.js ***!
  \************************************************************/(e,t,r)=>{r.r(t),r.d(t,{Wav2Vec2FeatureExtractor:()=>s});var n=r(/*! ../../base/feature_extraction_utils.js */"./src/base/feature_extraction_utils.js"),o=r(/*! ../../utils/tensor.js */"./src/utils/tensor.js");class s extends n.FeatureExtractor{_zero_mean_unit_var_norm(e){let t=e.reduce((e,t)=>e+t,0)/e.length,r=e.reduce((e,r)=>e+(r-t)**2,0)/e.length;return e.map(e=>(e-t)/Math.sqrt(r+1e-7))}async _call(e){(0,n.validate_audio_inputs)(e,"Wav2Vec2FeatureExtractor"),e instanceof Float64Array&&(e=new Float32Array(e));let t=e;this.config.do_normalize&&(t=this._zero_mean_unit_var_norm(t));let r=[1,t.length];return{input_values:new o.Tensor("float32",t,r),attention_mask:new o.Tensor("int64",new BigInt64Array(t.length).fill(1n),r)}}}},"./src/models/wav2vec2/processing_wav2vec2.js":/*!****************************************************!*\
  !*** ./src/models/wav2vec2/processing_wav2vec2.js ***!
  \****************************************************/(e,t,r)=>{r.r(t),r.d(t,{Wav2Vec2Processor:()=>i});var n=r(/*! ../../tokenizers.js */"./src/tokenizers.js"),o=r(/*! ../auto/feature_extraction_auto.js */"./src/models/auto/feature_extraction_auto.js"),s=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js");class i extends s.Processor{static tokenizer_class=n.AutoTokenizer;static feature_extractor_class=o.AutoFeatureExtractor;async _call(e){return await this.feature_extractor(e)}}},"./src/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.js":/*!********************************************************************!*\
  !*** ./src/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.js ***!
  \********************************************************************/(e,t,r)=>{r.r(t),r.d(t,{Wav2Vec2ProcessorWithLM:()=>i});var n=r(/*! ../../tokenizers.js */"./src/tokenizers.js"),o=r(/*! ../auto/feature_extraction_auto.js */"./src/models/auto/feature_extraction_auto.js"),s=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js");class i extends s.Processor{static tokenizer_class=n.AutoTokenizer;static feature_extractor_class=o.AutoFeatureExtractor;async _call(e){return await this.feature_extractor(e)}}},"./src/models/wespeaker/feature_extraction_wespeaker.js":/*!**************************************************************!*\
  !*** ./src/models/wespeaker/feature_extraction_wespeaker.js ***!
  \**************************************************************/(e,t,r)=>{r.r(t),r.d(t,{WeSpeakerFeatureExtractor:()=>s});var n=r(/*! ../../base/feature_extraction_utils.js */"./src/base/feature_extraction_utils.js");r(/*! ../../utils/tensor.js */"./src/utils/tensor.js");var o=r(/*! ../../utils/audio.js */"./src/utils/audio.js");class s extends n.FeatureExtractor{constructor(e){super(e);let t=this.config.sampling_rate,r=(0,o.mel_filter_bank)(257,this.config.num_mel_bins,20,Math.floor(t/2),t,null,"kaldi",!0);this.mel_filters=r,this.window=(0,o.window_function)(400,"hamming",{periodic:!1}),this.min_num_frames=this.config.min_num_frames}async _extract_fbank_features(e){return e=e.map(e=>32768*e),(0,o.spectrogram)(e,this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1192092955078125e-22,remove_dc_offset:!0,transpose:!0,min_num_frames:this.min_num_frames})}async _call(e){(0,n.validate_audio_inputs)(e,"WeSpeakerFeatureExtractor");let t=(await this._extract_fbank_features(e)).unsqueeze_(0);if(null===this.config.fbank_centering_span){let e=t.mean(1).data,r=t.data,[n,o,s]=t.dims;for(let t=0;t<n;++t){let n=t*o*s,i=t*s;for(let t=0;t<o;++t){let o=n+t*s;for(let t=0;t<s;++t)r[o+t]-=e[i+t]}}}return{input_features:t}}}},"./src/models/whisper/common_whisper.js":/*!**********************************************!*\
  !*** ./src/models/whisper/common_whisper.js ***!
  \**********************************************/(e,t,r)=>{r.r(t),r.d(t,{WHISPER_LANGUAGE_MAPPING:()=>o,WHISPER_TO_LANGUAGE_CODE_MAPPING:()=>s,whisper_language_to_code:()=>i});let n=[["en","english"],["zh","chinese"],["de","german"],["es","spanish"],["ru","russian"],["ko","korean"],["fr","french"],["ja","japanese"],["pt","portuguese"],["tr","turkish"],["pl","polish"],["ca","catalan"],["nl","dutch"],["ar","arabic"],["sv","swedish"],["it","italian"],["id","indonesian"],["hi","hindi"],["fi","finnish"],["vi","vietnamese"],["he","hebrew"],["uk","ukrainian"],["el","greek"],["ms","malay"],["cs","czech"],["ro","romanian"],["da","danish"],["hu","hungarian"],["ta","tamil"],["no","norwegian"],["th","thai"],["ur","urdu"],["hr","croatian"],["bg","bulgarian"],["lt","lithuanian"],["la","latin"],["mi","maori"],["ml","malayalam"],["cy","welsh"],["sk","slovak"],["te","telugu"],["fa","persian"],["lv","latvian"],["bn","bengali"],["sr","serbian"],["az","azerbaijani"],["sl","slovenian"],["kn","kannada"],["et","estonian"],["mk","macedonian"],["br","breton"],["eu","basque"],["is","icelandic"],["hy","armenian"],["ne","nepali"],["mn","mongolian"],["bs","bosnian"],["kk","kazakh"],["sq","albanian"],["sw","swahili"],["gl","galician"],["mr","marathi"],["pa","punjabi"],["si","sinhala"],["km","khmer"],["sn","shona"],["yo","yoruba"],["so","somali"],["af","afrikaans"],["oc","occitan"],["ka","georgian"],["be","belarusian"],["tg","tajik"],["sd","sindhi"],["gu","gujarati"],["am","amharic"],["yi","yiddish"],["lo","lao"],["uz","uzbek"],["fo","faroese"],["ht","haitian creole"],["ps","pashto"],["tk","turkmen"],["nn","nynorsk"],["mt","maltese"],["sa","sanskrit"],["lb","luxembourgish"],["my","myanmar"],["bo","tibetan"],["tl","tagalog"],["mg","malagasy"],["as","assamese"],["tt","tatar"],["haw","hawaiian"],["ln","lingala"],["ha","hausa"],["ba","bashkir"],["jw","javanese"],["su","sundanese"]],o=new Map(n),s=new Map([...n.map(([e,t])=>[t,e]),["burmese","my"],["valencian","ca"],["flemish","nl"],["haitian","ht"],["letzeburgesch","lb"],["pushto","ps"],["panjabi","pa"],["moldavian","ro"],["moldovan","ro"],["sinhalese","si"],["castilian","es"]]);function i(e){e=e.toLowerCase();let t=s.get(e);if(void 0===t){let r=e.match(/^<\|([a-z]{2})\|>$/);if(r&&(e=r[1]),o.has(e))t=e;else{let t=2===e.length?o.keys():o.values();throw Error(`Language "${e}" is not supported. Must be one of: ${JSON.stringify(Array.from(t))}`)}}return t}},"./src/models/whisper/feature_extraction_whisper.js":/*!**********************************************************!*\
  !*** ./src/models/whisper/feature_extraction_whisper.js ***!
  \**********************************************************/(e,t,r)=>{r.r(t),r.d(t,{WhisperFeatureExtractor:()=>i});var n=r(/*! ../../base/feature_extraction_utils.js */"./src/base/feature_extraction_utils.js");r(/*! ../../utils/tensor.js */"./src/utils/tensor.js");var o=r(/*! ../../utils/audio.js */"./src/utils/audio.js"),s=r(/*! ../../utils/maths.js */"./src/utils/maths.js");class i extends n.FeatureExtractor{constructor(e){super(e),this.config.mel_filters??=(0,o.mel_filter_bank)(Math.floor(1+this.config.n_fft/2),this.config.feature_size,0,8e3,this.config.sampling_rate,"slaney","slaney"),this.window=(0,o.window_function)(this.config.n_fft,"hann")}async _extract_fbank_features(e){let t=await (0,o.spectrogram)(e,this.window,this.config.n_fft,this.config.hop_length,{power:2,mel_filters:this.config.mel_filters,log_mel:"log10",max_num_frames:Math.min(Math.floor(e.length/this.config.hop_length),this.config.nb_max_frames)}),r=t.data,n=(0,s.max)(r)[0];for(let e=0;e<r.length;++e)r[e]=(Math.max(r[e],n-8)+4)/4;return t}async _call(e,{max_length:t=null}={}){let r;(0,n.validate_audio_inputs)(e,"WhisperFeatureExtractor");let o=t??this.config.n_samples;return e.length>o?(e.length>this.config.n_samples&&console.warn("Attempting to extract features for audio longer than 30 seconds. If using a pipeline to extract transcript from a long audio clip, remember to specify `chunk_length_s` and/or `stride_length_s`."),r=e.slice(0,o)):(r=new Float32Array(o)).set(e),{input_features:(await this._extract_fbank_features(r)).unsqueeze_(0)}}}},"./src/models/whisper/generation_whisper.js":/*!**************************************************!*\
  !*** ./src/models/whisper/generation_whisper.js ***!
  \**************************************************/(e,t,r)=>{r.r(t),r.d(t,{WhisperGenerationConfig:()=>o});var n=r(/*! ../../generation/configuration_utils.js */"./src/generation/configuration_utils.js");class o extends n.GenerationConfig{return_timestamps=null;return_token_timestamps=null;num_frames=null;alignment_heads=null;task=null;language=null;no_timestamps_token_id=null;prompt_ids=null;is_multilingual=null;lang_to_id=null;task_to_id=null;max_initial_timestamp_index=1}},"./src/models/whisper/processing_whisper.js":/*!**************************************************!*\
  !*** ./src/models/whisper/processing_whisper.js ***!
  \**************************************************/(e,t,r)=>{r.r(t),r.d(t,{WhisperProcessor:()=>i});var n=r(/*! ../auto/feature_extraction_auto.js */"./src/models/auto/feature_extraction_auto.js"),o=r(/*! ../../tokenizers.js */"./src/tokenizers.js"),s=r(/*! ../../base/processing_utils.js */"./src/base/processing_utils.js");class i extends s.Processor{static tokenizer_class=o.AutoTokenizer;static feature_extractor_class=n.AutoFeatureExtractor;async _call(e){return await this.feature_extractor(e)}}},"./src/models/yolos/image_processing_yolos.js":/*!****************************************************!*\
  !*** ./src/models/yolos/image_processing_yolos.js ***!
  \****************************************************/(e,t,r)=>{r.r(t),r.d(t,{YolosFeatureExtractor:()=>s,YolosImageProcessor:()=>o});var n=r(/*! ../../base/image_processors_utils.js */"./src/base/image_processors_utils.js");class o extends n.ImageProcessor{post_process_object_detection(...e){return(0,n.post_process_object_detection)(...e)}}class s extends o{}},"./src/ops/registry.js":/*!*****************************!*\
  !*** ./src/ops/registry.js ***!
  \*****************************/(e,t,r)=>{r.r(t),r.d(t,{TensorOpRegistry:()=>l});var n=r(/*! ../backends/onnx.js */"./src/backends/onnx.js"),o=r(/*! ../utils/tensor.js */"./src/utils/tensor.js"),s=r(/*! ../env.js */"./src/env.js");let i=s.apis.IS_BROWSER_ENV||s.apis.IS_WEBWORKER_ENV,a=async(e,t,r)=>{let s=await (0,n.createInferenceSession)(new Uint8Array(e),t),a=Promise.resolve();return async e=>{let t=(0,n.isONNXProxy)(),l=Object.fromEntries(Object.entries(e).map(([e,r])=>[e,(t?r.clone():r).ort_tensor])),c=await (a=i?a.then(()=>s.run(l)):s.run(l));return Array.isArray(r)?r.map(e=>new o.Tensor(c[e])):new o.Tensor(c[r])}};class l{static session_options={};static get nearest_interpolate_4d(){return this._nearest_interpolate_4d||(this._nearest_interpolate_4d=a([8,10,18,0,58,129,1,10,41,10,1,120,10,0,10,0,10,1,115,18,1,121,34,6,82,101,115,105,122,101,42,18,10,4,109,111,100,101,34,7,110,101,97,114,101,115,116,160,1,3,18,1,114,90,31,10,1,120,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,90,15,10,1,115,18,10,10,8,8,7,18,4,10,2,8,4,98,31,10,1,121,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,66,2,16,21],this.session_options,"y")),this._nearest_interpolate_4d}static get bilinear_interpolate_4d(){return this._bilinear_interpolate_4d||(this._bilinear_interpolate_4d=a([8,9,18,0,58,128,1,10,40,10,1,120,10,0,10,0,10,1,115,18,1,121,34,6,82,101,115,105,122,101,42,17,10,4,109,111,100,101,34,6,108,105,110,101,97,114,160,1,3,18,1,114,90,31,10,1,120,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,90,15,10,1,115,18,10,10,8,8,7,18,4,10,2,8,4,98,31,10,1,121,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,66,2,16,20],this.session_options,"y")),this._bilinear_interpolate_4d}static get bicubic_interpolate_4d(){return this._bicubic_interpolate_4d||(this._bicubic_interpolate_4d=a([8,9,18,0,58,127,10,39,10,1,120,10,0,10,0,10,1,115,18,1,121,34,6,82,101,115,105,122,101,42,16,10,4,109,111,100,101,34,5,99,117,98,105,99,160,1,3,18,1,114,90,31,10,1,120,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,90,15,10,1,115,18,10,10,8,8,7,18,4,10,2,8,4,98,31,10,1,121,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,66,2,16,20],this.session_options,"y")),this._bicubic_interpolate_4d}static get matmul(){return this._matmul||(this._matmul=a([8,9,18,0,58,55,10,17,10,1,97,10,1,98,18,1,99,34,6,77,97,116,77,117,108,18,1,114,90,9,10,1,97,18,4,10,2,8,1,90,9,10,1,98,18,4,10,2,8,1,98,9,10,1,99,18,4,10,2,8,1,66,2,16,20],this.session_options,"c")),this._matmul}static get stft(){return this._stft||(this._stft=a([8,7,18,0,58,148,1,10,38,10,1,115,10,1,106,10,1,119,10,1,108,18,1,111,34,4,83,84,70,84,42,15,10,8,111,110,101,115,105,100,101,100,24,1,160,1,2,18,1,115,90,26,10,1,115,18,21,10,19,8,1,18,15,10,3,18,1,98,10,3,18,1,115,10,3,18,1,99,90,11,10,1,106,18,6,10,4,8,7,18,0,90,16,10,1,119,18,11,10,9,8,1,18,5,10,3,18,1,119,90,11,10,1,108,18,6,10,4,8,7,18,0,98,31,10,1,111,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,102,10,3,18,1,100,10,3,18,1,99,66,2,16,17],this.session_options,"o")),this._stft}static get rfft(){return this._rfft||(this._rfft=a([8,9,18,0,58,97,10,33,10,1,120,10,0,10,1,97,18,1,121,34,3,68,70,84,42,15,10,8,111,110,101,115,105,100,101,100,24,1,160,1,2,18,1,100,90,21,10,1,120,18,16,10,14,8,1,18,10,10,3,18,1,115,10,3,18,1,99,90,11,10,1,97,18,6,10,4,8,7,18,0,98,21,10,1,121,18,16,10,14,8,1,18,10,10,3,18,1,115,10,3,18,1,99,66,2,16,20],this.session_options,"y")),this._rfft}static get top_k(){return this._top_k||(this._top_k=a([8,10,18,0,58,73,10,18,10,1,120,10,1,107,18,1,118,18,1,105,34,4,84,111,112,75,18,1,116,90,9,10,1,120,18,4,10,2,8,1,90,15,10,1,107,18,10,10,8,8,7,18,4,10,2,8,1,98,9,10,1,118,18,4,10,2,8,1,98,9,10,1,105,18,4,10,2,8,7,66,2,16,21],this.session_options,["v","i"])),this._top_k}static get slice(){return this._slice||(this._slice=a([8,7,18,0,58,96,10,25,10,1,120,10,1,115,10,1,101,10,1,97,10,1,116,18,1,121,34,5,83,108,105,99,101,18,1,114,90,9,10,1,120,18,4,10,2,8,1,90,9,10,1,115,18,4,10,2,8,7,90,9,10,1,101,18,4,10,2,8,7,90,9,10,1,97,18,4,10,2,8,7,90,9,10,1,116,18,4,10,2,8,7,98,9,10,1,121,18,4,10,2,8,1,66,2,16,13],this.session_options,"y")),this._slice}}},"./src/pipelines.js":/*!**************************!*\
  !*** ./src/pipelines.js ***!
  \**************************/(e,t,r)=>{r.r(t),r.d(t,{AudioClassificationPipeline:()=>C,AutomaticSpeechRecognitionPipeline:()=>E,BackgroundRemovalPipeline:()=>D,DepthEstimationPipeline:()=>G,DocumentQuestionAnsweringPipeline:()=>O,FeatureExtractionPipeline:()=>y,FillMaskPipeline:()=>w,ImageClassificationPipeline:()=>L,ImageFeatureExtractionPipeline:()=>v,ImageSegmentationPipeline:()=>I,ImageToImagePipeline:()=>B,ImageToTextPipeline:()=>A,ObjectDetectionPipeline:()=>j,Pipeline:()=>h,QuestionAnsweringPipeline:()=>M,SummarizationPipeline:()=>x,Text2TextGenerationPipeline:()=>T,TextClassificationPipeline:()=>f,TextGenerationPipeline:()=>F,TextToAudioPipeline:()=>N,TokenClassificationPipeline:()=>g,TranslationPipeline:()=>P,ZeroShotAudioClassificationPipeline:()=>S,ZeroShotClassificationPipeline:()=>k,ZeroShotImageClassificationPipeline:()=>z,ZeroShotObjectDetectionPipeline:()=>V,pipeline:()=>$});var n=r(/*! ./tokenizers.js */"./src/tokenizers.js"),o=r(/*! ./models.js */"./src/models.js"),s=r(/*! ./models/auto/processing_auto.js */"./src/models/auto/processing_auto.js");r(/*! ./base/processing_utils.js */"./src/base/processing_utils.js");var i=r(/*! ./utils/generic.js */"./src/utils/generic.js"),a=r(/*! ./utils/core.js */"./src/utils/core.js"),l=r(/*! ./utils/maths.js */"./src/utils/maths.js"),c=r(/*! ./utils/audio.js */"./src/utils/audio.js"),u=r(/*! ./utils/tensor.js */"./src/utils/tensor.js"),d=r(/*! ./utils/image.js */"./src/utils/image.js");async function m(e){return Array.isArray(e)||(e=[e]),await Promise.all(e.map(e=>d.RawImage.read(e)))}async function p(e,t){return Array.isArray(e)||(e=[e]),await Promise.all(e.map(e=>"string"==typeof e||e instanceof URL?(0,c.read_audio)(e,t):e instanceof Float64Array?new Float32Array(e):e))}function _(e,t){t&&(e=e.map(e=>0|e));let[r,n,o,s]=e;return{xmin:r,ymin:n,xmax:o,ymax:s}}class h extends i.Callable{constructor({task:e,model:t,tokenizer:r=null,processor:n=null}){super(),this.task=e,this.model=t,this.tokenizer=r,this.processor=n}async dispose(){await this.model.dispose()}}class f extends h{constructor(e){super(e)}async _call(e,{top_k:t=1}={}){let r=this.tokenizer(e,{padding:!0,truncation:!0}),n=await this.model(r),o="multi_label_classification"===this.model.config.problem_type?e=>e.sigmoid():e=>new u.Tensor("float32",(0,l.softmax)(e.data),e.dims),s=this.model.config.id2label,i=[];for(let e of n.logits){let r=o(e),n=await (0,u.topk)(r,t),a=n[0].tolist(),l=n[1].tolist().map((e,t)=>({label:s?s[e]:`LABEL_${e}`,score:a[t]}));1===t?i.push(...l):i.push(l)}return Array.isArray(e)||1===t?i:i[0]}}class g extends h{constructor(e){super(e)}async _call(e,{ignore_labels:t=["O"]}={}){let r=Array.isArray(e),n=this.tokenizer(r?e:[e],{padding:!0,truncation:!0}),o=(await this.model(n)).logits,s=this.model.config.id2label,i=[];for(let e=0;e<o.dims[0];++e){let r=n.input_ids[e],a=o[e],c=[];for(let e=0;e<a.dims[0];++e){let n=a[e],o=(0,l.max)(n.data)[1],i=s?s[o]:`LABEL_${o}`;if(t.includes(i))continue;let u=this.tokenizer.decode([r[e].item()],{skip_special_tokens:!0});if(""===u)continue;let d=(0,l.softmax)(n.data);c.push({entity:i,score:d[o],index:e,word:u})}i.push(c)}return r?i:i[0]}}class M extends h{constructor(e){super(e)}async _call(e,t,{top_k:r=1}={}){let n=this.tokenizer(e,{text_pair:t,padding:!0,truncation:!0}),{start_logits:o,end_logits:s}=await this.model(n),i=n.input_ids.tolist(),c=n.attention_mask.tolist(),u=this.tokenizer.all_special_ids,d=[];for(let e=0;e<o.dims[0];++e){let t=i[e],n=t.findIndex(e=>e==this.tokenizer.sep_token_id);c[e].map((e,r)=>1==e&&(0===r||r>n&&-1===u.findIndex(e=>e==t[r])));let m=o[e].tolist(),p=s[e].tolist();for(let r=1;r<m.length;++r)(0==c[e]||r<=n||-1!==u.findIndex(e=>e==t[r]))&&(m[r]=-1/0,p[r]=-1/0);let _=(0,l.softmax)(m).map((e,t)=>[e,t]),h=(0,l.softmax)(p).map((e,t)=>[e,t]);_[0][0]=0,h[0][0]=0;let f=(0,a.product)(_,h).filter(e=>e[0][1]<=e[1][1]).map(e=>[e[0][1],e[1][1],e[0][0]*e[1][0]]).sort((e,t)=>t[2]-e[2]);for(let e=0;e<Math.min(f.length,r);++e){let[r,n,o]=f[e],s=t.slice(r,n+1),i=this.tokenizer.decode(s,{skip_special_tokens:!0});d.push({answer:i,score:o})}}return 1===r?d[0]:d}}class w extends h{constructor(e){super(e)}async _call(e,{top_k:t=5}={}){let r=this.tokenizer(e,{padding:!0,truncation:!0}),{logits:n}=await this.model(r),o=[],s=r.input_ids.tolist();for(let e=0;e<s.length;++e){let r=s[e],i=r.findIndex(e=>e==this.tokenizer.mask_token_id);if(-1===i)throw Error(`Mask token (${this.tokenizer.mask_token}) not found in text.`);let a=n[e][i],c=await (0,u.topk)(new u.Tensor("float32",(0,l.softmax)(a.data),a.dims),t),d=c[0].tolist(),m=c[1].tolist();o.push(m.map((e,t)=>{let n=r.slice();return n[i]=e,{score:d[t],token:Number(e),token_str:this.tokenizer.decode([e]),sequence:this.tokenizer.decode(n,{skip_special_tokens:!0})}}))}return Array.isArray(e)?o:o[0]}}class T extends h{_key="generated_text";constructor(e){super(e)}async _call(e,t={}){let r;Array.isArray(e)||(e=[e]),this.model.config.prefix&&(e=e.map(e=>this.model.config.prefix+e));let n=this.model.config.task_specific_params;n&&n[this.task]&&n[this.task].prefix&&(e=e.map(e=>n[this.task].prefix+e));let o=this.tokenizer,s={padding:!0,truncation:!0};r=this instanceof P&&"_build_translation_inputs"in o?o._build_translation_inputs(e,s,t):o(e,s);let i=await this.model.generate({...r,...t});return o.batch_decode(i,{skip_special_tokens:!0}).map(e=>({[this._key]:e}))}}class x extends T{_key="summary_text";constructor(e){super(e)}}class P extends T{_key="translation_text";constructor(e){super(e)}}function b(e){return Array.isArray(e)&&e.every(e=>"role"in e&&"content"in e)}class F extends h{constructor(e){super(e)}async _call(e,t={}){let r,n,o=!1,s=!1,i=t.add_special_tokens??(this.tokenizer.add_bos_token||this.tokenizer.add_eos_token)??!1;if("string"==typeof e)r=e=[e];else if(Array.isArray(e)&&e.every(e=>"string"==typeof e))o=!0,r=e;else{if(b(e))e=[e];else if(Array.isArray(e)&&e.every(b))o=!0;else throw Error("Input must be a string, an array of strings, a Chat, or an array of Chats");s=!0,r=e.map(e=>this.tokenizer.apply_chat_template(e,{tokenize:!1,add_generation_prompt:!0})),i=!1}let a=!s&&(t.return_full_text??!0);this.tokenizer.padding_side="left";let l=this.tokenizer(r,{add_special_tokens:i,padding:!0,truncation:!0}),c=await this.model.generate({...l,...t}),u=this.tokenizer.batch_decode(c,{skip_special_tokens:!0});!a&&l.input_ids.dims.at(-1)>0&&(n=this.tokenizer.batch_decode(l.input_ids,{skip_special_tokens:!0}).map(e=>e.length));let d=Array.from({length:e.length},e=>[]);for(let t=0;t<u.length;++t){let r=Math.floor(t/c.dims[0]*e.length);n&&(u[t]=u[t].slice(n[r])),d[r].push({generated_text:s?[...e[r],{role:"assistant",content:u[t]}]:u[t]})}return o||1!==d.length?d:d[0]}}class k extends h{constructor(e){super(e),this.label2id=Object.fromEntries(Object.entries(this.model.config.label2id).map(([e,t])=>[e.toLowerCase(),t])),this.entailment_id=this.label2id.entailment,void 0===this.entailment_id&&(console.warn("Could not find 'entailment' in label2id mapping. Using 2 as entailment_id."),this.entailment_id=2),this.contradiction_id=this.label2id.contradiction??this.label2id.not_entailment,void 0===this.contradiction_id&&(console.warn("Could not find 'contradiction' in label2id mapping. Using 0 as contradiction_id."),this.contradiction_id=0)}async _call(e,t,{hypothesis_template:r="This example is {}.",multi_label:n=!1}={}){let o=Array.isArray(e);o||(e=[e]),Array.isArray(t)||(t=[t]);let s=t.map(e=>r.replace("{}",e)),i=n||1===t.length,a=[];for(let r of e){let e=[];for(let t of s){let n=this.tokenizer(r,{text_pair:t,padding:!0,truncation:!0}),o=await this.model(n);i?e.push([o.logits.data[this.contradiction_id],o.logits.data[this.entailment_id]]):e.push(o.logits.data[this.entailment_id])}let n=(i?e.map(e=>(0,l.softmax)(e)[1]):(0,l.softmax)(e)).map((e,t)=>[e,t]).sort((e,t)=>t[0]-e[0]);a.push({sequence:r,labels:n.map(e=>t[e[1]]),scores:n.map(e=>e[0])})}return o?a:a[0]}}class y extends h{constructor(e){super(e)}async _call(e,{pooling:t="none",normalize:r=!1,quantize:n=!1,precision:o="binary"}={}){let s=this.tokenizer(e,{padding:!0,truncation:!0}),i=await this.model(s),a=i.last_hidden_state??i.logits??i.token_embeddings;switch(t){case"none":break;case"mean":a=(0,u.mean_pooling)(a,s.attention_mask);break;case"first_token":case"cls":a=a.slice(null,0);break;case"last_token":case"eos":a=a.slice(null,-1);break;default:throw Error(`Pooling method '${t}' not supported.`)}return r&&(a=a.normalize(2,-1)),n&&(a=(0,u.quantize_embeddings)(a,o)),a}}class v extends h{constructor(e){super(e)}async _call(e,{pool:t=null}={}){let r;let n=await m(e),{pixel_values:o}=await this.processor(n),s=await this.model({pixel_values:o});if(t){if(!("pooler_output"in s))throw Error("No pooled output was returned. Make sure the model has a 'pooler' layer when using the 'pool' option.");r=s.pooler_output}else r=s.last_hidden_state??s.logits??s.image_embeds;return r}}class C extends h{constructor(e){super(e)}async _call(e,{top_k:t=5}={}){let r=this.processor.feature_extractor.config.sampling_rate,n=await p(e,r),o=this.model.config.id2label,s=[];for(let e of n){let r=await this.processor(e),n=(await this.model(r)).logits[0],i=await (0,u.topk)(new u.Tensor("float32",(0,l.softmax)(n.data),n.dims),t),a=i[0].tolist(),c=i[1].tolist().map((e,t)=>({label:o?o[e]:`LABEL_${e}`,score:a[t]}));s.push(c)}return Array.isArray(e)?s:s[0]}}class S extends h{constructor(e){super(e)}async _call(e,t,{hypothesis_template:r="This is a sound of {}."}={}){let n=!Array.isArray(e);n&&(e=[e]);let o=t.map(e=>r.replace("{}",e)),s=this.tokenizer(o,{padding:!0,truncation:!0}),i=this.processor.feature_extractor.config.sampling_rate,a=await p(e,i),c=[];for(let e of a){let r=await this.processor(e),n=await this.model({...s,...r}),o=(0,l.softmax)(n.logits_per_audio.data);c.push([...o].map((e,r)=>({score:e,label:t[r]})))}return n?c[0]:c}}class E extends h{constructor(e){super(e)}async _call(e,t={}){switch(this.model.config.model_type){case"whisper":case"lite-whisper":return this._call_whisper(e,t);case"wav2vec2":case"wav2vec2-bert":case"unispeech":case"unispeech-sat":case"hubert":return this._call_wav2vec2(e,t);case"moonshine":return this._call_moonshine(e,t);default:throw Error(`AutomaticSpeechRecognitionPipeline does not support model type '${this.model.config.model_type}'.`)}}async _call_wav2vec2(e,t){t.language&&console.warn('`language` parameter is not yet supported for `wav2vec2` models, defaulting to "English".'),t.task&&console.warn('`task` parameter is not yet supported for `wav2vec2` models, defaulting to "transcribe".');let r=!Array.isArray(e);r&&(e=[e]);let n=this.processor.feature_extractor.config.sampling_rate,o=await p(e,n),s=[];for(let e of o){let t=await this.processor(e),r=(await this.model(t)).logits[0],n=[];for(let e of r)n.push((0,l.max)(e.data)[1]);let o=this.tokenizer.decode(n);s.push({text:o})}return r?s[0]:s}async _call_whisper(e,t){let r=t.return_timestamps??!1,n=t.chunk_length_s??0,o=t.force_full_sequences??!1,s=t.stride_length_s??null,i={...t};"word"===r&&(i.return_token_timestamps=!0,i.return_timestamps=!1);let a=!Array.isArray(e);a&&(e=[e]);let c=this.processor.feature_extractor.config.chunk_length/this.model.config.max_source_positions,u=this.processor.feature_extractor.config.hop_length,d=this.processor.feature_extractor.config.sampling_rate,m=await p(e,d),_=[];for(let e of m){let t=[];if(n>0){if(null===s)s=n/6;else if(n<=s)throw Error("`chunk_length_s` must be larger than `stride_length_s`.");let r=d*n,o=d*s,i=r-2*o,a=0;for(;;){let n=a+r,s=e.subarray(a,n),l=await this.processor(s),c=0===a,u=n>=e.length;if(t.push({stride:[s.length,c?0:o,u?0:o],input_features:l.input_features,is_last:u}),u)break;a+=i}}else t=[{stride:[e.length,0,0],input_features:(await this.processor(e)).input_features,is_last:!0}];for(let e of t){i.num_frames=Math.floor(e.stride[0]/u);let t=await this.model.generate({inputs:e.input_features,...i});"word"===r?(e.tokens=t.sequences.tolist()[0],e.token_timestamps=t.token_timestamps.tolist()[0].map(e=>(0,l.round)(e,2))):e.tokens=t[0].tolist(),e.stride=e.stride.map(e=>e/d)}let[a,m]=this.tokenizer._decode_asr(t,{time_precision:c,return_timestamps:r,force_full_sequences:o});_.push({text:a,...m})}return a?_[0]:_}async _call_moonshine(e,t){let r=!Array.isArray(e);r&&(e=[e]);let n=this.processor.feature_extractor.config.sampling_rate,o=await p(e,n),s=[];for(let e of o){let r=await this.processor(e),o=6*Math.floor(e.length/n),i=await this.model.generate({max_new_tokens:o,...t,...r}),a=this.processor.batch_decode(i,{skip_special_tokens:!0})[0];s.push({text:a})}return r?s[0]:s}}class A extends h{constructor(e){super(e)}async _call(e,t={}){let r=Array.isArray(e),n=await m(e),{pixel_values:o}=await this.processor(n),s=[];for(let e of o){e.dims=[1,...e.dims];let r=await this.model.generate({inputs:e,...t}),n=this.tokenizer.batch_decode(r,{skip_special_tokens:!0}).map(e=>({generated_text:e.trim()}));s.push(n)}return r?s:s[0]}}class L extends h{constructor(e){super(e)}async _call(e,{top_k:t=5}={}){let r=await m(e),{pixel_values:n}=await this.processor(r),o=await this.model({pixel_values:n}),s=this.model.config.id2label,i=[];for(let e of o.logits){let r=await (0,u.topk)(new u.Tensor("float32",(0,l.softmax)(e.data),e.dims),t),n=r[0].tolist(),o=r[1].tolist().map((e,t)=>({label:s?s[e]:`LABEL_${e}`,score:n[t]}));i.push(o)}return Array.isArray(e)?i:i[0]}}class I extends h{constructor(e){super(e),this.subtasks_mapping={panoptic:"post_process_panoptic_segmentation",instance:"post_process_instance_segmentation",semantic:"post_process_semantic_segmentation"}}async _call(e,{threshold:t=.5,mask_threshold:r=.5,overlap_mask_area_threshold:n=.8,label_ids_to_fuse:o=null,target_sizes:s=null,subtask:i=null}={}){if(Array.isArray(e)&&1!==e.length)throw Error("Image segmentation pipeline currently only supports a batch size of 1.");let a=await m(e),l=a.map(e=>[e.height,e.width]),c=await this.processor(a),{inputNames:u,outputNames:p}=this.model.sessions.model;if(!u.includes("pixel_values")){if(1!==u.length)throw Error(`Expected a single input name, but got ${u.length} inputs: ${u}.`);let e=u[0];if(e in c)throw Error(`Input name ${e} already exists in the inputs.`);c[e]=c.pixel_values}let _=await this.model(c),h=null;if(null!==i)h=this.subtasks_mapping[i];else if(this.processor.image_processor){for(let[e,t]of Object.entries(this.subtasks_mapping))if(t in this.processor.image_processor){h=this.processor.image_processor[t].bind(this.processor.image_processor),i=e;break}}let f=this.model.config.id2label,g=[];if(i){if("panoptic"===i||"instance"===i){let e=h(_,t,r,n,o,s??l)[0],i=e.segmentation;for(let t of e.segments_info){let e=new Uint8ClampedArray(i.data.length);for(let r=0;r<i.data.length;++r)i.data[r]===t.id&&(e[r]=255);let r=new d.RawImage(e,i.dims[1],i.dims[0],1);g.push({score:t.score,label:f[t.label_id],mask:r})}}else if("semantic"===i){let{segmentation:e,labels:t}=h(_,s??l)[0];for(let r of t){let t=new Uint8ClampedArray(e.data.length);for(let n=0;n<e.data.length;++n)e.data[n]===r&&(t[n]=255);let n=new d.RawImage(t,e.dims[1],e.dims[0],1);g.push({score:null,label:f[r],mask:n})}}else throw Error(`Subtask ${i} not supported.`)}else{let e=_[p[0]];for(let t=0;t<l.length;++t){let r=l[t],n=e[t];n.data.some(e=>e<-.00001||e>1.00001)&&n.sigmoid_();let o=await d.RawImage.fromTensor(n.mul_(255).to("uint8")).resize(r[1],r[0]);g.push({label:null,score:null,mask:o})}}return g}}class D extends I{constructor(e){super(e)}async _call(e,t={}){if(Array.isArray(e)&&1!==e.length)throw Error("Background removal pipeline currently only supports a batch size of 1.");let r=await m(e),n=await super._call(e,t);return r.map((e,t)=>{let r=e.clone();return r.putAlpha(n[t].mask),r})}}class z extends h{constructor(e){super(e)}async _call(e,t,{hypothesis_template:r="This is a photo of {}"}={}){let n=Array.isArray(e),o=await m(e),s=t.map(e=>r.replace("{}",e)),i=this.tokenizer(s,{padding:"siglip"!==this.model.config.model_type||"max_length",truncation:!0}),{pixel_values:a}=await this.processor(o),c=await this.model({...i,pixel_values:a}),u="siglip"===this.model.config.model_type?e=>e.sigmoid().data:e=>(0,l.softmax)(e.data),d=[];for(let e of c.logits_per_image){let r=[...u(e)].map((e,r)=>({score:e,label:t[r]}));r.sort((e,t)=>t.score-e.score),d.push(r)}return n?d:d[0]}}class j extends h{constructor(e){super(e)}async _call(e,{threshold:t=.9,percentage:r=!1}={}){let n=Array.isArray(e);if(n&&1!==e.length)throw Error("Object detection pipeline currently only supports a batch size of 1.");let o=await m(e),s=r?null:o.map(e=>[e.height,e.width]),{pixel_values:i,pixel_mask:a}=await this.processor(o),l=await this.model({pixel_values:i,pixel_mask:a}),c=this.processor.image_processor.post_process_object_detection(l,t,s),u=this.model.config.id2label,d=c.map(e=>e.boxes.map((t,n)=>({score:e.scores[n],label:u[e.classes[n]],box:_(t,!r)})));return n?d:d[0]}}class V extends h{constructor(e){super(e)}async _call(e,t,{threshold:r=.1,top_k:n=null,percentage:o=!1}={}){let s=Array.isArray(e),i=await m(e),a=this.tokenizer(t,{padding:!0,truncation:!0}),l=await this.processor(i),c=[];for(let e=0;e<i.length;++e){let s;let u=i[e],d=o?null:[[u.height,u.width]],m=l.pixel_values[e].unsqueeze_(0),p=await this.model({...a,pixel_values:m});if("post_process_grounded_object_detection"in this.processor){let e=this.processor.post_process_grounded_object_detection(p,a.input_ids,{box_threshold:r,text_threshold:r,target_sizes:d})[0];s=e.boxes.map((t,r)=>({score:e.scores[r],label:e.labels[r],box:_(t,!o)}))}else{let e=this.processor.image_processor.post_process_object_detection(p,r,d,!0)[0];s=e.boxes.map((r,n)=>({score:e.scores[n],label:t[e.classes[n]],box:_(r,!o)}))}s.sort((e,t)=>t.score-e.score),null!==n&&(s=s.slice(0,n)),c.push(s)}return s?c:c[0]}}class O extends h{constructor(e){super(e)}async _call(e,t,r={}){let n=(await m(e))[0],{pixel_values:o}=await this.processor(n),s=`<s_docvqa><s_question>${t}</s_question><s_answer>`,i=this.tokenizer(s,{add_special_tokens:!1,padding:!0,truncation:!0}).input_ids,a=await this.model.generate({inputs:o,max_length:this.model.config.decoder.max_position_embeddings,decoder_input_ids:i,...r}),l=this.tokenizer.batch_decode(a)[0].match(/<s_answer>(.*?)<\/s_answer>/),c=null;return l&&l.length>=2&&(c=l[1].trim()),[{answer:c}]}}class N extends h{DEFAULT_VOCODER_ID="Xenova/speecht5_hifigan";constructor(e){super(e),this.vocoder=e.vocoder??null}async _call(e,{speaker_embeddings:t=null}={}){return this.processor?this._call_text_to_spectrogram(e,{speaker_embeddings:t}):this._call_text_to_waveform(e)}async _call_text_to_waveform(e){let t=this.tokenizer(e,{padding:!0,truncation:!0}),{waveform:r}=await this.model(t),n=this.model.config.sampling_rate;return new c.RawAudio(r.data,n)}async _call_text_to_spectrogram(e,{speaker_embeddings:t}){if(this.vocoder||(console.log("No vocoder specified, using default HifiGan vocoder."),this.vocoder=await o.AutoModel.from_pretrained(this.DEFAULT_VOCODER_ID,{dtype:"fp32"})),("string"==typeof t||t instanceof URL)&&(t=new Float32Array(await (await fetch(t)).arrayBuffer())),t instanceof Float32Array)t=new u.Tensor("float32",t,[1,t.length]);else if(!(t instanceof u.Tensor))throw Error("Speaker embeddings must be a `Tensor`, `Float32Array`, `string`, or `URL`.");let{input_ids:r}=this.tokenizer(e,{padding:!0,truncation:!0}),{waveform:n}=await this.model.generate_speech(r,t,{vocoder:this.vocoder}),s=this.processor.feature_extractor.config.sampling_rate;return new c.RawAudio(n.data,s)}}class B extends h{constructor(e){super(e)}async _call(e){let t=await m(e),r=await this.processor(t),n=await this.model(r),o=[];for(let e of n.reconstruction){let t=e.squeeze().clamp_(0,1).mul_(255).round_().to("uint8");o.push(d.RawImage.fromTensor(t))}return o.length>1?o:o[0]}}class G extends h{constructor(e){super(e)}async _call(e){let t=await m(e),r=await this.processor(t),{predicted_depth:n}=await this.model(r),o=[];for(let e=0;e<t.length;++e){let r=n[e],[s,i]=r.dims.slice(-2),[a,l]=t[e].size,c=(await (0,u.interpolate_4d)(r.view(1,1,s,i),{size:[l,a],mode:"bilinear"})).view(l,a),m=c.min().item(),p=c.max().item(),_=c.sub(m).div_(p-m).mul_(255).to("uint8").unsqueeze(0),h=d.RawImage.fromTensor(_);o.push({predicted_depth:c,depth:h})}return o.length>1?o:o[0]}}let R=Object.freeze({"text-classification":{tokenizer:n.AutoTokenizer,pipeline:f,model:o.AutoModelForSequenceClassification,default:{model:"Xenova/distilbert-base-uncased-finetuned-sst-2-english"},type:"text"},"token-classification":{tokenizer:n.AutoTokenizer,pipeline:g,model:o.AutoModelForTokenClassification,default:{model:"Xenova/bert-base-multilingual-cased-ner-hrl"},type:"text"},"question-answering":{tokenizer:n.AutoTokenizer,pipeline:M,model:o.AutoModelForQuestionAnswering,default:{model:"Xenova/distilbert-base-cased-distilled-squad"},type:"text"},"fill-mask":{tokenizer:n.AutoTokenizer,pipeline:w,model:o.AutoModelForMaskedLM,default:{model:"Xenova/bert-base-uncased"},type:"text"},summarization:{tokenizer:n.AutoTokenizer,pipeline:x,model:o.AutoModelForSeq2SeqLM,default:{model:"Xenova/distilbart-cnn-6-6"},type:"text"},translation:{tokenizer:n.AutoTokenizer,pipeline:P,model:o.AutoModelForSeq2SeqLM,default:{model:"Xenova/t5-small"},type:"text"},"text2text-generation":{tokenizer:n.AutoTokenizer,pipeline:T,model:o.AutoModelForSeq2SeqLM,default:{model:"Xenova/flan-t5-small"},type:"text"},"text-generation":{tokenizer:n.AutoTokenizer,pipeline:F,model:o.AutoModelForCausalLM,default:{model:"Xenova/gpt2"},type:"text"},"zero-shot-classification":{tokenizer:n.AutoTokenizer,pipeline:k,model:o.AutoModelForSequenceClassification,default:{model:"Xenova/distilbert-base-uncased-mnli"},type:"text"},"audio-classification":{pipeline:C,model:o.AutoModelForAudioClassification,processor:s.AutoProcessor,default:{model:"Xenova/wav2vec2-base-superb-ks"},type:"audio"},"zero-shot-audio-classification":{tokenizer:n.AutoTokenizer,pipeline:S,model:o.AutoModel,processor:s.AutoProcessor,default:{model:"Xenova/clap-htsat-unfused"},type:"multimodal"},"automatic-speech-recognition":{tokenizer:n.AutoTokenizer,pipeline:E,model:[o.AutoModelForSpeechSeq2Seq,o.AutoModelForCTC],processor:s.AutoProcessor,default:{model:"Xenova/whisper-tiny.en"},type:"multimodal"},"text-to-audio":{tokenizer:n.AutoTokenizer,pipeline:N,model:[o.AutoModelForTextToWaveform,o.AutoModelForTextToSpectrogram],processor:[s.AutoProcessor,null],default:{model:"Xenova/speecht5_tts"},type:"text"},"image-to-text":{tokenizer:n.AutoTokenizer,pipeline:A,model:o.AutoModelForVision2Seq,processor:s.AutoProcessor,default:{model:"Xenova/vit-gpt2-image-captioning"},type:"multimodal"},"image-classification":{pipeline:L,model:o.AutoModelForImageClassification,processor:s.AutoProcessor,default:{model:"Xenova/vit-base-patch16-224"},type:"multimodal"},"image-segmentation":{pipeline:I,model:[o.AutoModelForImageSegmentation,o.AutoModelForSemanticSegmentation,o.AutoModelForUniversalSegmentation],processor:s.AutoProcessor,default:{model:"Xenova/detr-resnet-50-panoptic"},type:"multimodal"},"background-removal":{pipeline:D,model:[o.AutoModelForImageSegmentation,o.AutoModelForSemanticSegmentation,o.AutoModelForUniversalSegmentation],processor:s.AutoProcessor,default:{model:"Xenova/modnet"},type:"image"},"zero-shot-image-classification":{tokenizer:n.AutoTokenizer,pipeline:z,model:o.AutoModel,processor:s.AutoProcessor,default:{model:"Xenova/clip-vit-base-patch32"},type:"multimodal"},"object-detection":{pipeline:j,model:o.AutoModelForObjectDetection,processor:s.AutoProcessor,default:{model:"Xenova/detr-resnet-50"},type:"multimodal"},"zero-shot-object-detection":{tokenizer:n.AutoTokenizer,pipeline:V,model:o.AutoModelForZeroShotObjectDetection,processor:s.AutoProcessor,default:{model:"Xenova/owlvit-base-patch32"},type:"multimodal"},"document-question-answering":{tokenizer:n.AutoTokenizer,pipeline:O,model:o.AutoModelForDocumentQuestionAnswering,processor:s.AutoProcessor,default:{model:"Xenova/donut-base-finetuned-docvqa"},type:"multimodal"},"image-to-image":{pipeline:B,model:o.AutoModelForImageToImage,processor:s.AutoProcessor,default:{model:"Xenova/swin2SR-classical-sr-x2-64"},type:"image"},"depth-estimation":{pipeline:G,model:o.AutoModelForDepthEstimation,processor:s.AutoProcessor,default:{model:"Xenova/dpt-large"},type:"image"},"feature-extraction":{tokenizer:n.AutoTokenizer,pipeline:y,model:o.AutoModel,default:{model:"Xenova/all-MiniLM-L6-v2"},type:"text"},"image-feature-extraction":{processor:s.AutoProcessor,pipeline:v,model:[o.AutoModelForImageFeatureExtraction,o.AutoModel],default:{model:"Xenova/vit-base-patch16-224-in21k"},type:"image"}}),q=Object.freeze({"sentiment-analysis":"text-classification",ner:"token-classification",asr:"automatic-speech-recognition","text-to-speech":"text-to-audio",embeddings:"feature-extraction"});async function $(e,t=null,{progress_callback:r=null,config:n=null,cache_dir:o=null,local_files_only:s=!1,revision:i="main",device:l=null,dtype:c=null,subfolder:u="onnx",use_external_data_format:d=null,model_file_name:m=null,session_options:p={}}={}){let _=R[(e=q[e]??e).split("_",1)[0]];if(!_)throw Error(`Unsupported pipeline: ${e}. Must be one of [${Object.keys(R)}]`);t||(t=_.default.model,console.log(`No model specified. Using default model: "${t}".`));let h=new Map([["tokenizer",_.tokenizer],["model",_.model],["processor",_.processor]]),f=await W(h,t,{progress_callback:r,config:n,cache_dir:o,local_files_only:s,revision:i,device:l,dtype:c,subfolder:u,use_external_data_format:d,model_file_name:m,session_options:p});return f.task=e,(0,a.dispatchCallback)(r,{status:"ready",task:e,model:t}),new _.pipeline(f)}async function W(e,t,r){let n=Object.create(null),o=[];for(let[s,i]of e.entries()){let e;i&&(e=Array.isArray(i)?new Promise(async(e,n)=>{let o;for(let s of i){if(null===s){e(null);return}try{e(await s.from_pretrained(t,r));return}catch(e){if(e.message?.includes("Unsupported model type"))o=e;else if(e.message?.includes("Could not locate file"))o=e;else{n(e);return}}}n(o)}):i.from_pretrained(t,r),n[s]=e,o.push(e))}for(let[e,t]of(await Promise.all(o),Object.entries(n)))n[e]=await t;return n}},"./src/tokenizers.js":/*!***************************!*\
  !*** ./src/tokenizers.js ***!
  \***************************/(e,t,r)=>{r.r(t),r.d(t,{AlbertTokenizer:()=>eP,AutoTokenizer:()=>to,BartTokenizer:()=>ej,BertTokenizer:()=>ex,BlenderbotSmallTokenizer:()=>e6,BlenderbotTokenizer:()=>e8,BloomTokenizer:()=>eB,CLIPTokenizer:()=>e2,CamembertTokenizer:()=>eA,CodeGenTokenizer:()=>e1,CodeLlamaTokenizer:()=>eR,CohereTokenizer:()=>tt,ConvBertTokenizer:()=>eC,DebertaTokenizer:()=>ek,DebertaV2Tokenizer:()=>ey,DistilBertTokenizer:()=>eE,ElectraTokenizer:()=>eI,Ernie4_5_Tokenizer:()=>tn,EsmTokenizer:()=>eQ,FalconTokenizer:()=>eW,GPT2Tokenizer:()=>ez,GPTNeoXTokenizer:()=>eU,GemmaTokenizer:()=>eH,Grok1Tokenizer:()=>eJ,HerbertTokenizer:()=>ev,LlamaTokenizer:()=>eG,M2M100Tokenizer:()=>eZ,MBart50Tokenizer:()=>eO,MBartTokenizer:()=>eV,MPNetTokenizer:()=>e$,MarianTokenizer:()=>e4,MgpstrTokenizer:()=>tr,MobileBertTokenizer:()=>eb,NllbTokenizer:()=>eK,NougatTokenizer:()=>e7,PreTrainedTokenizer:()=>eT,Qwen2Tokenizer:()=>eX,RoFormerTokenizer:()=>eS,RobertaTokenizer:()=>eN,SiglipTokenizer:()=>e3,SpeechT5Tokenizer:()=>e9,SqueezeBertTokenizer:()=>eF,T5Tokenizer:()=>eD,TokenizerModel:()=>b,VitsTokenizer:()=>te,Wav2Vec2CTCTokenizer:()=>e5,WhisperTokenizer:()=>e0,XLMRobertaTokenizer:()=>eq,XLMTokenizer:()=>eL,is_chinese_char:()=>g});var n=r(/*! ./utils/generic.js */"./src/utils/generic.js"),o=r(/*! ./utils/core.js */"./src/utils/core.js"),s=r(/*! ./utils/hub.js */"./src/utils/hub.js"),i=r(/*! ./utils/maths.js */"./src/utils/maths.js"),a=r(/*! ./utils/tensor.js */"./src/utils/tensor.js"),l=r(/*! ./utils/data-structures.js */"./src/utils/data-structures.js"),c=r(/*! @huggingface/jinja */"./node_modules/@huggingface/jinja/dist/index.js"),u=r(/*! ./models/whisper/common_whisper.js */"./src/models/whisper/common_whisper.js");async function d(e,t){let r=await Promise.all([(0,s.getModelJSON)(e,"tokenizer.json",!0,t),(0,s.getModelJSON)(e,"tokenizer_config.json",!0,t)]);return null!==t.legacy&&(r[1].legacy=t.legacy),r}function m(e,t=!0){if(void 0!==e.Regex){let t=e.Regex.replace(/\\([#&~])/g,"$1");for(let[e,r]of x)t=t.replaceAll(e,r);return RegExp(t,"gu")}if(void 0===e.String)return console.warn("Unknown pattern type:",e),null;{let r=(0,o.escapeRegExp)(e.String);return RegExp(t?r:`(${r})`,"gu")}}function p(e){return new Map(Object.entries(e))}function _(e){let t=e.dims;switch(t.length){case 1:return e.tolist();case 2:if(1!==t[0])throw Error("Unable to decode tensor with `batch size !== 1`. Use `tokenizer.batch_decode(...)` for batched inputs.");return e.tolist()[0];default:throw Error(`Expected tensor to have 1-2 dimensions, got ${t.length}.`)}}function h(e){return e.replace(/ \./g,".").replace(/ \?/g,"?").replace(/ \!/g,"!").replace(/ ,/g,",").replace(/ \' /g,"'").replace(/ n\'t/g,"n't").replace(/ \'m/g,"'m").replace(/ \'s/g,"'s").replace(/ \'ve/g,"'ve").replace(/ \'re/g,"'re")}function f(e){return e.replace(/\p{M}/gu,"")}function g(e){return e>=19968&&e<=40959||e>=13312&&e<=19903||e>=131072&&e<=173791||e>=173824&&e<=177983||e>=177984&&e<=178207||e>=178208&&e<=183983||e>=63744&&e<=64255||e>=194560&&e<=195103}let M="\\p{P}\\u0021-\\u002F\\u003A-\\u0040\\u005B-\\u0060\\u007B-\\u007E",w=RegExp(`^[${M}]+$`,"gu"),T=".,!?…。，、।۔،",x=new Map([["(?i:'s|'t|'re|'ve|'m|'ll|'d)","(?:'([sS]|[tT]|[rR][eE]|[vV][eE]|[mM]|[lL][lL]|[dD]))"],[` ?[^(\\s|[${T}])]+`,` ?[^\\s${T}]+`]]);class P{constructor(e){this.content=e.content,this.id=e.id,this.single_word=e.single_word??!1,this.lstrip=e.lstrip??!1,this.rstrip=e.rstrip??!1,this.special=e.special??!1,this.normalized=e.normalized??null}}class b extends n.Callable{constructor(e){super(),this.config=e,this.vocab=[],this.tokens_to_ids=new Map,this.unk_token_id=void 0,this.unk_token=void 0,this.end_of_word_suffix=void 0,this.fuse_unk=this.config.fuse_unk??!1}static fromConfig(e,...t){switch(e.type){case"WordPiece":return new F(e);case"Unigram":return new k(e,...t);case"BPE":return new C(e);default:if(e.vocab){if(Array.isArray(e.vocab))return new k(e,...t);if(!(Object.hasOwn(e,"continuing_subword_prefix")&&Object.hasOwn(e,"unk_token")))return new S(e,...t);if(Object.hasOwn(e,"merges"))return new C(e);return new F(e)}throw Error(`Unknown TokenizerModel type: ${e.type}`)}}_call(e){return e=this.encode(e),this.fuse_unk&&(e=function(e,t,r){let n=[],o=0;for(;o<e.length;){if(n.push(e[o]),(t.get(e[o])??r)!==r){++o;continue}for(;++o<e.length&&(t.get(e[o])??r)===r;)t.get(n.at(-1))!==r&&(n[n.length-1]+=e[o])}return n}(e,this.tokens_to_ids,this.unk_token_id)),e}encode(e){throw Error("encode should be implemented in subclass.")}convert_tokens_to_ids(e){return e.map(e=>this.tokens_to_ids.get(e)??this.unk_token_id)}convert_ids_to_tokens(e){return e.map(e=>this.vocab[e]??this.unk_token)}}class F extends b{constructor(e){for(let[t,r]of(super(e),this.tokens_to_ids=p(e.vocab),this.unk_token_id=this.tokens_to_ids.get(e.unk_token),this.unk_token=e.unk_token,this.max_input_chars_per_word=e.max_input_chars_per_word??100,this.vocab=Array(this.tokens_to_ids.size),this.tokens_to_ids))this.vocab[r]=t}encode(e){let t=[];for(let r of e){let e=[...r];if(e.length>this.max_input_chars_per_word){t.push(this.unk_token);continue}let n=!1,o=0,s=[];for(;o<e.length;){let t=e.length,r=null;for(;o<t;){let n=e.slice(o,t).join("");if(o>0&&(n=this.config.continuing_subword_prefix+n),this.tokens_to_ids.has(n)){r=n;break}--t}if(null===r){n=!0;break}s.push(r),o=t}n?t.push(this.unk_token):t.push(...s)}return t}}class k extends b{constructor(e,t){super(e);let r=e.vocab.length;this.vocab=Array(r),this.scores=Array(r);for(let t=0;t<r;++t)[this.vocab[t],this.scores[t]]=e.vocab[t];this.unk_token_id=e.unk_id,this.unk_token=this.vocab[e.unk_id],this.tokens_to_ids=new Map(this.vocab.map((e,t)=>[e,t])),this.bos_token=" ",this.bos_token_id=this.tokens_to_ids.get(this.bos_token),this.eos_token=t.eos_token,this.eos_token_id=this.tokens_to_ids.get(this.eos_token),this.unk_token=this.vocab[this.unk_token_id],this.minScore=(0,i.min)(this.scores)[0],this.unk_score=this.minScore-10,this.scores[this.unk_token_id]=this.unk_score,this.trie=new l.CharTrie,this.trie.extend(this.vocab),this.fuse_unk=!0}populateNodes(e){let t=e.chars,r=0;for(;r<t.length;){let n=!1,s=[],i=t.slice(r).join("");for(let t of this.trie.commonPrefixSearch(i)){s.push(t);let i=this.tokens_to_ids.get(t),a=this.scores[i],l=(0,o.len)(t);e.insert(r,l,a,i),n||1!==l||(n=!0)}n||e.insert(r,1,this.unk_score,this.unk_token_id),r+=1}}tokenize(e){let t=new l.TokenLattice(e,this.bos_token_id,this.eos_token_id);return this.populateNodes(t),t.tokens()}encode(e){let t=[];for(let r of e){let e=this.tokenize(r);t.push(...e)}return t}}let y=(()=>{let e=[...Array.from({length:94},(e,t)=>t+33),...Array.from({length:12},(e,t)=>t+161),...Array.from({length:82},(e,t)=>t+174)],t=e.slice(),r=0;for(let n=0;n<256;++n)e.includes(n)||(e.push(n),t.push(256+r),r+=1);let n=t.map(e=>String.fromCharCode(e));return Object.fromEntries(e.map((e,t)=>[e,n[t]]))})(),v=(0,o.reverseDictionary)(y);class C extends b{constructor(e){for(let[t,r]of(super(e),this.tokens_to_ids=p(e.vocab),this.unk_token_id=this.tokens_to_ids.get(e.unk_token),this.unk_token=e.unk_token,this.vocab=Array(this.tokens_to_ids.size),this.tokens_to_ids))this.vocab[r]=t;let t=Array.isArray(e.merges[0]);this.merges=t?e.merges:e.merges.map(e=>e.split(" ",2)),this.bpe_ranks=new Map(this.merges.map((e,t)=>[JSON.stringify(e),t])),this.end_of_word_suffix=e.end_of_word_suffix,this.continuing_subword_suffix=e.continuing_subword_suffix??null,this.byte_fallback=this.config.byte_fallback??!1,this.byte_fallback&&(this.text_encoder=new TextEncoder),this.ignore_merges=this.config.ignore_merges??!1,this.max_length_to_cache=256,this.cache_capacity=1e4,this.cache=new l.LRUCache(this.cache_capacity)}clear_cache(){this.cache.clear()}bpe(e){if(0===e.length)return[];let t=this.cache.get(e);if(void 0!==t)return t;let r=Array.from(e);this.end_of_word_suffix&&(r[r.length-1]+=this.end_of_word_suffix);let n=[];if(r.length>1){let e=new l.PriorityQueue((e,t)=>e.score<t.score),t={token:r[0],bias:0,prev:null,next:null},o=t;for(let t=1;t<r.length;++t){let n={bias:t/r.length,token:r[t],prev:o,next:null};o.next=n,this._add_node(e,o),o=n}for(;!e.isEmpty();){let r=e.pop();if(r.deleted||!r.next||r.next.deleted)continue;if(r.deleted=!0,r.next.deleted=!0,r.prev){let e={...r.prev};r.prev.deleted=!0,r.prev=e,e.prev?e.prev.next=e:t=e}let n={token:r.token+r.next.token,bias:r.bias,prev:r.prev,next:r.next.next};n.prev?(n.prev.next=n,this._add_node(e,n.prev)):t=n,n.next&&(n.next.prev=n,this._add_node(e,n))}for(let e=t;null!==e;e=e.next)n.push(e.token)}else n=r;if(this.continuing_subword_suffix)for(let e=0;e<n.length-1;++e)n[e]+=this.continuing_subword_suffix;return e.length<this.max_length_to_cache&&this.cache.put(e,n),n}_add_node(e,t){let r=this.bpe_ranks.get(JSON.stringify([t.token,t.next.token]));void 0!==r&&(t.score=r+t.bias,e.push(t))}encode(e){let t=[];for(let r of e){if(this.ignore_merges&&this.tokens_to_ids.has(r)){t.push(r);continue}for(let e of this.bpe(r))if(this.tokens_to_ids.has(e))t.push(e);else if(this.byte_fallback){let r=Array.from(this.text_encoder.encode(e)).map(e=>`<0x${e.toString(16).toUpperCase().padStart(2,"0")}>`);r.every(e=>this.tokens_to_ids.has(e))?t.push(...r):t.push(this.unk_token)}else t.push(this.unk_token)}return t}}class S extends b{constructor(e,t){for(let[r,n]of(super(e),this.tokens_to_ids=p(t.target_lang?e.vocab[t.target_lang]:e.vocab),this.bos_token=t.bos_token,this.bos_token_id=this.tokens_to_ids.get(this.bos_token),this.eos_token=t.eos_token,this.eos_token_id=this.tokens_to_ids.get(this.eos_token),this.pad_token=t.pad_token,this.pad_token_id=this.tokens_to_ids.get(this.pad_token),this.unk_token=t.unk_token,this.unk_token_id=this.tokens_to_ids.get(this.unk_token),this.vocab=Array(this.tokens_to_ids.size),this.tokens_to_ids))this.vocab[n]=r}encode(e){return e}}class E extends n.Callable{constructor(e){super(),this.config=e}static fromConfig(e){if(null===e)return null;switch(e.type){case"BertNormalizer":return new R(e);case"Precompiled":return new e_(e);case"Sequence":return new G(e);case"Replace":return new A(e);case"NFC":return new I(e);case"NFD":return new D(e);case"NFKC":return new z(e);case"NFKD":return new j(e);case"Strip":return new V(e);case"StripAccents":return new O(e);case"Lowercase":return new N(e);case"Prepend":return new B(e);default:throw Error(`Unknown Normalizer type: ${e.type}`)}}normalize(e){throw Error("normalize should be implemented in subclass.")}_call(e){return this.normalize(e)}}class A extends E{normalize(e){let t=m(this.config.pattern);return null===t?e:e.replaceAll(t,this.config.content)}}class L extends E{form=void 0;normalize(e){return e=e.normalize(this.form)}}class I extends L{form="NFC"}class D extends L{form="NFD"}class z extends L{form="NFKC"}class j extends L{form="NFKD"}class V extends E{normalize(e){return this.config.strip_left&&this.config.strip_right?e=e.trim():(this.config.strip_left&&(e=e.trimStart()),this.config.strip_right&&(e=e.trimEnd())),e}}class O extends E{normalize(e){return e=f(e)}}class N extends E{normalize(e){return e=e.toLowerCase()}}class B extends E{normalize(e){return e=this.config.prepend+e}}class G extends E{constructor(e){super(e),this.normalizers=e.normalizers.map(e=>E.fromConfig(e))}normalize(e){return this.normalizers.reduce((e,t)=>t.normalize(e),e)}}class R extends E{_tokenize_chinese_chars(e){let t=[];for(let r=0;r<e.length;++r){let n=e[r];g(n.charCodeAt(0))?(t.push(" "),t.push(n),t.push(" ")):t.push(n)}return t.join("")}stripAccents(e){return e.normalize("NFD").replace(/\p{Mn}/gu,"")}_is_control(e){switch(e){case"	":case"\n":case"\r":return!1;default:return/^\p{Cc}|\p{Cf}|\p{Co}|\p{Cs}$/u.test(e)}}_clean_text(e){let t=[];for(let r of e){let e=r.charCodeAt(0);0===e||65533===e||this._is_control(r)||(/^\s$/.test(r)?t.push(" "):t.push(r))}return t.join("")}normalize(e){return this.config.clean_text&&(e=this._clean_text(e)),this.config.handle_chinese_chars&&(e=this._tokenize_chinese_chars(e)),this.config.lowercase?(e=e.toLowerCase(),!1!==this.config.strip_accents&&(e=this.stripAccents(e))):this.config.strip_accents&&(e=this.stripAccents(e)),e}}class q extends n.Callable{static fromConfig(e){if(null===e)return null;switch(e.type){case"BertPreTokenizer":return new $(e);case"Sequence":return new eh(e);case"Whitespace":return new ef(e);case"WhitespaceSplit":return new eg(e);case"Metaspace":return new em(e);case"ByteLevel":return new W(e);case"Split":return new U(e);case"Punctuation":return new Q(e);case"Digits":return new X(e);case"Replace":return new eM(e);default:throw Error(`Unknown PreTokenizer type: ${e.type}`)}}pre_tokenize_text(e,t){throw Error("pre_tokenize_text should be implemented in subclass.")}pre_tokenize(e,t){return(Array.isArray(e)?e.map(e=>this.pre_tokenize_text(e,t)):this.pre_tokenize_text(e,t)).flat()}_call(e,t){return this.pre_tokenize(e,t)}}class $ extends q{constructor(e){super(),this.pattern=RegExp(`[^\\s${M}]+|[${M}]`,"gu")}pre_tokenize_text(e,t){return e.trim().match(this.pattern)||[]}}class W extends q{constructor(e){super(),this.config=e,this.add_prefix_space=this.config.add_prefix_space,this.trim_offsets=this.config.trim_offsets,this.use_regex=this.config.use_regex??!0,this.pattern=/'s|'t|'re|'ve|'m|'ll|'d| ?\p{L}+| ?\p{N}+| ?[^\s\p{L}\p{N}]+|\s+(?!\S)|\s+/gu,this.byte_encoder=y,this.text_encoder=new TextEncoder}pre_tokenize_text(e,t){return this.add_prefix_space&&!e.startsWith(" ")&&(e=" "+e),(this.use_regex?e.match(this.pattern)||[]:[e]).map(e=>Array.from(this.text_encoder.encode(e),e=>this.byte_encoder[e]).join(""))}}class U extends q{constructor(e){super(),this.config=e,this.pattern=m(this.config.pattern,this.config.invert)}pre_tokenize_text(e,t){return null===this.pattern?[]:this.config.invert?e.match(this.pattern)||[]:this.config.behavior?.toLowerCase()==="removed"?e.split(this.pattern).filter(e=>e):function(e,t){let r=[],n=0;for(let o of e.matchAll(t)){let t=o[0];n<o.index&&r.push(e.slice(n,o.index)),t.length>0&&r.push(t),n=o.index+t.length}return n<e.length&&r.push(e.slice(n)),r}(e,this.pattern)}}class Q extends q{constructor(e){super(),this.config=e,this.pattern=RegExp(`[^${M}]+|[${M}]+`,"gu")}pre_tokenize_text(e,t){return e.match(this.pattern)||[]}}class X extends q{constructor(e){super(),this.config=e;let t=`[^\\d]+|\\d${this.config.individual_digits?"":"+"}`;this.pattern=RegExp(t,"gu")}pre_tokenize_text(e,t){return e.match(this.pattern)||[]}}class H extends n.Callable{constructor(e){super(),this.config=e}static fromConfig(e){if(null===e)return null;switch(e.type){case"TemplateProcessing":return new K(e);case"ByteLevel":return new Z(e);case"RobertaProcessing":return new Y(e);case"BertProcessing":return new J(e);case"Sequence":return new ee(e);default:throw Error(`Unknown PostProcessor type: ${e.type}`)}}post_process(e,...t){throw Error("post_process should be implemented in subclass.")}_call(e,...t){return this.post_process(e,...t)}}class J extends H{constructor(e){super(e),this.cls=e.cls[0],this.sep=e.sep[0]}post_process(e,t=null,{add_special_tokens:r=!0}={}){r&&(e=(0,o.mergeArrays)([this.cls],e,[this.sep]));let n=Array(e.length).fill(0);if(null!==t){let s=r&&this instanceof Y?[this.sep]:[],i=r?[this.sep]:[];e=(0,o.mergeArrays)(e,s,t,i),n=(0,o.mergeArrays)(n,Array(t.length+s.length+i.length).fill(1))}return{tokens:e,token_type_ids:n}}}class Y extends J{}class K extends H{constructor(e){super(e),this.single=e.single,this.pair=e.pair}post_process(e,t=null,{add_special_tokens:r=!0}={}){let n=null===t?this.single:this.pair,s=[],i=[];for(let a of n)"SpecialToken"in a?r&&(s.push(a.SpecialToken.id),i.push(a.SpecialToken.type_id)):"Sequence"in a&&("A"===a.Sequence.id?(s=(0,o.mergeArrays)(s,e),i=(0,o.mergeArrays)(i,Array(e.length).fill(a.Sequence.type_id))):"B"===a.Sequence.id&&(s=(0,o.mergeArrays)(s,t),i=(0,o.mergeArrays)(i,Array(t.length).fill(a.Sequence.type_id))));return{tokens:s,token_type_ids:i}}}class Z extends H{post_process(e,t=null){return t&&(e=(0,o.mergeArrays)(e,t)),{tokens:e}}}class ee extends H{constructor(e){super(e),this.processors=e.processors.map(e=>H.fromConfig(e))}post_process(e,t=null,r={}){let n;for(let o of this.processors)if(o instanceof Z)e=o.post_process(e).tokens,t&&(t=o.post_process(t).tokens);else{let s=o.post_process(e,t,r);e=s.tokens,n=s.token_type_ids}return{tokens:e,token_type_ids:n}}}class et extends n.Callable{constructor(e){super(),this.config=e,this.added_tokens=[],this.end_of_word_suffix=null,this.trim_offsets=e.trim_offsets}static fromConfig(e){if(null===e)return null;switch(e.type){case"WordPiece":return new ei(e);case"Metaspace":return new ep(e);case"ByteLevel":return new ea(e);case"Replace":return new er(e);case"ByteFallback":return new en(e);case"Fuse":return new eo(e);case"Strip":return new es(e);case"Sequence":return new ec(e);case"CTC":return new el(e);case"BPEDecoder":return new eu(e);default:throw Error(`Unknown Decoder type: ${e.type}`)}}_call(e){return this.decode(e)}decode(e){return this.decode_chain(e).join("")}decode_chain(e){throw Error("`decode_chain` should be implemented in subclass.")}}class er extends et{decode_chain(e){let t=m(this.config.pattern);return null===t?e:e.map(e=>e.replaceAll(t,this.config.content))}}class en extends et{constructor(e){super(e),this.text_decoder=new TextDecoder}decode_chain(e){let t=[],r=[];for(let n of e){let e=null;if(6===n.length&&n.startsWith("<0x")&&n.endsWith(">")){let t=parseInt(n.slice(3,5),16);isNaN(t)||(e=t)}if(null!==e)r.push(e);else{if(r.length>0){let e=this.text_decoder.decode(Uint8Array.from(r));t.push(e),r=[]}t.push(n)}}if(r.length>0){let e=this.text_decoder.decode(Uint8Array.from(r));t.push(e),r=[]}return t}}class eo extends et{decode_chain(e){return[e.join("")]}}class es extends et{constructor(e){super(e),this.content=this.config.content,this.start=this.config.start,this.stop=this.config.stop}decode_chain(e){return e.map(e=>{let t=0;for(let r=0;r<this.start;++r){if(e[r]===this.content){t=r+1;continue}break}let r=e.length;for(let t=0;t<this.stop;++t){let n=e.length-t-1;if(e[n]===this.content){r=n;continue}break}return e.slice(t,r)})}}class ei extends et{constructor(e){super(e),this.cleanup=e.cleanup}decode_chain(e){return e.map((e,t)=>(0!==t&&(e=e.startsWith(this.config.prefix)?e.replace(this.config.prefix,""):" "+e),this.cleanup&&(e=h(e)),e))}}class ea extends et{constructor(e){super(e),this.byte_decoder=v,this.text_decoder=new TextDecoder("utf-8",{fatal:!1,ignoreBOM:!0}),this.end_of_word_suffix=null}convert_tokens_to_string(e){let t=e.join(""),r=new Uint8Array([...t].map(e=>this.byte_decoder[e]));return this.text_decoder.decode(r)}decode_chain(e){let t=[],r=[];for(let n of e)void 0!==this.added_tokens.find(e=>e.content===n)?(r.length>0&&(t.push(this.convert_tokens_to_string(r)),r=[]),t.push(n)):r.push(n);return r.length>0&&t.push(this.convert_tokens_to_string(r)),t}}class el extends et{constructor(e){super(e),this.pad_token=this.config.pad_token,this.word_delimiter_token=this.config.word_delimiter_token,this.cleanup=this.config.cleanup}convert_tokens_to_string(e){if(0===e.length)return"";let t=[e[0]];for(let r=1;r<e.length;++r)e[r]!==t.at(-1)&&t.push(e[r]);let r=t.filter(e=>e!==this.pad_token).join("");return this.cleanup&&(r=h(r).replaceAll(this.word_delimiter_token," ").trim()),r}decode_chain(e){return[this.convert_tokens_to_string(e)]}}class ec extends et{constructor(e){super(e),this.decoders=e.decoders.map(e=>et.fromConfig(e))}decode_chain(e){return this.decoders.reduce((e,t)=>t.decode_chain(e),e)}}class eu extends et{constructor(e){super(e),this.suffix=this.config.suffix}decode_chain(e){return e.map((t,r)=>t.replaceAll(this.suffix,r===e.length-1?"":" "))}}class ed extends et{decode_chain(e){let t="";for(let r=1;r<e.length;r+=2)t+=e[r];return[t]}}class em extends q{constructor(e){super(),this.addPrefixSpace=e.add_prefix_space,this.replacement=e.replacement,this.strRep=e.str_rep||this.replacement,this.prepend_scheme=e.prepend_scheme??"always"}pre_tokenize_text(e,{section_index:t}={}){let r=e.replaceAll(" ",this.strRep);return this.addPrefixSpace&&!r.startsWith(this.replacement)&&("always"===this.prepend_scheme||"first"===this.prepend_scheme&&0===t)&&(r=this.strRep+r),[r]}}class ep extends et{constructor(e){super(e),this.addPrefixSpace=e.add_prefix_space,this.replacement=e.replacement}decode_chain(e){let t=[];for(let r=0;r<e.length;++r){let n=e[r].replaceAll(this.replacement," ");this.addPrefixSpace&&0==r&&n.startsWith(" ")&&(n=n.substring(1)),t.push(n)}return t}}class e_ extends E{constructor(e){super(e),this.charsmap=e.precompiled_charsmap}normalize(e){return e=(e=(e=e.replace(/[\u0001-\u0008\u000B\u000E-\u001F\u007F\u008F\u009F]/gm,"")).replace(/[\u0009\u000A\u000C\u000D\u00A0\u1680\u2000-\u200F\u2028\u2029\u202F\u205F\u2581\u3000\uFEFF\uFFFD]/gm," ")).includes("～")?e.split("～").map(e=>e.normalize("NFKC")).join("～"):e.normalize("NFKC")}}class eh extends q{constructor(e){super(),this.tokenizers=e.pretokenizers.map(e=>q.fromConfig(e))}pre_tokenize_text(e,t){return this.tokenizers.reduce((e,r)=>r.pre_tokenize(e,t),[e])}}class ef extends q{constructor(e){super()}pre_tokenize_text(e,t){return e.match(/\w+|[^\w\s]+/g)||[]}}class eg extends q{constructor(e){super()}pre_tokenize_text(e,t){return e.match(/\S+/g)||[]}}class eM extends q{constructor(e){super(),this.config=e,this.pattern=m(this.config.pattern),this.content=this.config.content}pre_tokenize_text(e,t){return null===this.pattern?[e]:[e.replaceAll(this.pattern,this.config.content)]}}let ew=["bos_token","eos_token","unk_token","sep_token","pad_token","cls_token","mask_token"];class eT extends n.Callable{return_token_type_ids=!1;padding_side="right";constructor(e,t){for(let r of(super(),this.config=t,this.normalizer=E.fromConfig(e.normalizer),this.pre_tokenizer=q.fromConfig(e.pre_tokenizer),this.model=b.fromConfig(e.model,t),this.post_processor=H.fromConfig(e.post_processor),this.decoder=et.fromConfig(e.decoder),this.special_tokens=[],this.all_special_ids=[],this.added_tokens=[],e.added_tokens)){let e=new P(r);this.added_tokens.push(e),this.model.tokens_to_ids.set(e.content,e.id),this.model.vocab[e.id]=e.content,e.special&&(this.special_tokens.push(e.content),this.all_special_ids.push(e.id))}if(this.additional_special_tokens=t.additional_special_tokens??[],this.special_tokens.push(...this.additional_special_tokens),this.special_tokens=[...new Set(this.special_tokens)],this.decoder&&(this.decoder.added_tokens=this.added_tokens,this.decoder.end_of_word_suffix=this.model.end_of_word_suffix),this.added_tokens_splitter=new l.DictionarySplitter(this.added_tokens.map(e=>e.content)),this.added_tokens_map=new Map(this.added_tokens.map(e=>[e.content,e])),this.mask_token=this.getToken("mask_token"),this.mask_token_id=this.model.tokens_to_ids.get(this.mask_token),this.pad_token=this.getToken("pad_token","eos_token"),this.pad_token_id=this.model.tokens_to_ids.get(this.pad_token),this.sep_token=this.getToken("sep_token"),this.sep_token_id=this.model.tokens_to_ids.get(this.sep_token),this.unk_token=this.getToken("unk_token"),this.unk_token_id=this.model.tokens_to_ids.get(this.unk_token),this.bos_token=this.getToken("bos_token"),this.bos_token_id=this.model.tokens_to_ids.get(this.bos_token),this.eos_token=this.getToken("eos_token"),this.eos_token_id=this.model.tokens_to_ids.get(this.eos_token),this.model_max_length=t.model_max_length,this.remove_space=t.remove_space,this.clean_up_tokenization_spaces=t.clean_up_tokenization_spaces??!0,this.do_lowercase_and_remove_accent=t.do_lowercase_and_remove_accent??!1,t.padding_side&&(this.padding_side=t.padding_side),this.add_bos_token=t.add_bos_token,this.add_eos_token=t.add_eos_token,this.legacy=!1,this.chat_template=t.chat_template??null,Array.isArray(this.chat_template)){let e=Object.create(null);for(let{name:t,template:r}of this.chat_template){if("string"!=typeof t||"string"!=typeof r)throw Error('Chat template must be a list of objects with "name" and "template" properties');e[t]=r}this.chat_template=e}this._compiled_template_cache=new Map}getToken(...e){for(let t of e){let e=this.config[t];if(e){if("object"!=typeof e)return e;if("AddedToken"===e.__type)return e.content;throw Error(`Unknown token: ${e}`)}}return null}static async from_pretrained(e,{progress_callback:t=null,config:r=null,cache_dir:n=null,local_files_only:o=!1,revision:s="main",legacy:i=null}={}){return new this(...await d(e,{progress_callback:t,config:r,cache_dir:n,local_files_only:o,revision:s,legacy:i}))}_call(e,{text_pair:t=null,add_special_tokens:r=!0,padding:n=!1,truncation:s=null,max_length:l=null,return_tensor:c=!0,return_token_type_ids:u=null}={}){let d;let m=Array.isArray(e);if(m){if(0===e.length)throw Error("text array must be non-empty");if(null!==t){if(Array.isArray(t)){if(e.length!==t.length)throw Error("text and text_pair must have the same length")}else throw Error("text_pair must also be an array");d=e.map((e,n)=>this._encode_plus(e,{text_pair:t[n],add_special_tokens:r,return_token_type_ids:u}))}else d=e.map(e=>this._encode_plus(e,{add_special_tokens:r,return_token_type_ids:u}))}else{if(null==e)throw Error("text may not be null or undefined");if(Array.isArray(t))throw Error("When specifying `text_pair`, since `text` is a string, `text_pair` must also be a string (i.e., not an array).");d=[this._encode_plus(e,{text_pair:t,add_special_tokens:r,return_token_type_ids:u})]}if(null===l?l=this.model_max_length:null===s&&(!0===n?(console.warn("`max_length` is ignored when `padding: true` and there is no truncation strategy. To pad to max length, use `padding: 'max_length'`."),l=this.model_max_length):!1===n&&(console.warn("Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation: true` to explicitly truncate examples to max length."),s=!0)),!0===n&&(l=Math.min((0,i.max)(d.map(e=>e.input_ids.length))[0],l??1/0)),l=Math.min(l,this.model_max_length??1/0),n||s)for(let e=0;e<d.length;++e)d[e].input_ids.length!==l&&(d[e].input_ids.length>l?s&&function(e,t){for(let r of Object.keys(e))e[r].length=t}(d[e],l):n&&function(e,t,r,n){for(let s of Object.keys(e)){let i=t-e[s].length,a=r(s),l=Array(i).fill(a);e[s]="right"===n?(0,o.mergeArrays)(e[s],l):(0,o.mergeArrays)(l,e[s])}}(d[e],l,e=>"input_ids"===e?this.pad_token_id:0,this.padding_side));let p={};if(c){if(!(n&&s)&&d.some(e=>{for(let t of Object.keys(e))if(e[t].length!==d[0][t]?.length)return!0;return!1}))throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=true' and 'truncation=true' to have batched tensors with the same length.");let e=[d.length,d[0].input_ids.length];for(let t of Object.keys(d[0]))p[t]=new a.Tensor("int64",BigInt64Array.from(d.flatMap(e=>e[t]).map(BigInt)),e)}else{for(let e of Object.keys(d[0]))p[e]=d.map(t=>t[e]);if(!m)for(let e of Object.keys(p))p[e]=p[e][0]}return p}_encode_text(e){if(null===e)return null;let t=this.added_tokens_splitter.split(e);for(let e=0;e<t.length;++e){let r=this.added_tokens_map.get(t[e]);r&&(r.lstrip&&e>0&&(t[e-1]=t[e-1].trimEnd()),r.rstrip&&e<t.length-1&&(t[e+1]=t[e+1].trimStart()))}return t.flatMap((e,t)=>{if(0===e.length)return[];if(this.added_tokens_map.has(e))return[e];if(!0===this.remove_space&&(e=e.trim().split(/\s+/).join(" ")),this.do_lowercase_and_remove_accent&&(e=f(e.toLowerCase())),null!==this.normalizer&&(e=this.normalizer(e)),0===e.length)return[];let r=null!==this.pre_tokenizer?this.pre_tokenizer(e,{section_index:t}):[e];return this.model(r)})}_encode_plus(e,{text_pair:t=null,add_special_tokens:r=!0,return_token_type_ids:n=null}={}){let{tokens:o,token_type_ids:s}=this._tokenize_helper(e,{pair:t,add_special_tokens:r}),i=this.model.convert_tokens_to_ids(o),a={input_ids:i,attention_mask:Array(i.length).fill(1)};return(n??this.return_token_type_ids)&&s&&(a.token_type_ids=s),a}_tokenize_helper(e,{pair:t=null,add_special_tokens:r=!1}={}){let n=this._encode_text(e),s=this._encode_text(t);return this.post_processor?this.post_processor(n,s,{add_special_tokens:r}):{tokens:(0,o.mergeArrays)(n??[],s??[])}}tokenize(e,{pair:t=null,add_special_tokens:r=!1}={}){return this._tokenize_helper(e,{pair:t,add_special_tokens:r}).tokens}encode(e,{text_pair:t=null,add_special_tokens:r=!0,return_token_type_ids:n=null}={}){return this._encode_plus(e,{text_pair:t,add_special_tokens:r,return_token_type_ids:n}).input_ids}batch_decode(e,t={}){return e instanceof a.Tensor&&(e=e.tolist()),e.map(e=>this.decode(e,t))}decode(e,t={}){if(e instanceof a.Tensor&&(e=_(e)),!Array.isArray(e)||0===e.length||!(0,o.isIntegralNumber)(e[0]))throw Error("token_ids must be a non-empty array of integers.");return this.decode_single(e,t)}decode_single(e,{skip_special_tokens:t=!1,clean_up_tokenization_spaces:r=null}){let n=this.model.convert_ids_to_tokens(e);t&&(n=n.filter(e=>!this.special_tokens.includes(e)));let o=this.decoder?this.decoder(n):n.join(" ");return this.decoder&&this.decoder.end_of_word_suffix&&(o=o.replaceAll(this.decoder.end_of_word_suffix," "),t&&(o=o.trim())),(r??this.clean_up_tokenization_spaces)&&(o=h(o)),o}get_chat_template({chat_template:e=null,tools:t=null}={}){if(this.chat_template&&"object"==typeof this.chat_template){let r=this.chat_template;if(null!==e&&Object.hasOwn(r,e))e=r[e];else if(null===e){if(null!==t&&"tool_use"in r)e=r.tool_use;else if("default"in r)e=r.default;else throw Error(`This model has multiple chat templates with no default specified! Please either pass a chat template or the name of the template you wish to use to the 'chat_template' argument. Available template names are ${Object.keys(r).sort()}.`)}}else if(null===e){if(this.chat_template)e=this.chat_template;else throw Error("Cannot use apply_chat_template() because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating")}return e}apply_chat_template(e,{tools:t=null,documents:r=null,chat_template:n=null,add_generation_prompt:o=!1,tokenize:s=!0,padding:i=!1,truncation:a=!1,max_length:l=null,return_tensor:u=!0,return_dict:d=!1,tokenizer_kwargs:m={},...p}={}){if("string"!=typeof(n=this.get_chat_template({chat_template:n,tools:t})))throw Error(`chat_template must be a string, but got ${typeof n}`);let _=this._compiled_template_cache.get(n);void 0===_&&(_=new c.Template(n),this._compiled_template_cache.set(n,_));let h=Object.create(null);for(let e of ew){let t=this.getToken(e);t&&(h[e]=t)}let f=_.render({messages:e,add_generation_prompt:o,tools:t,documents:r,...h,...p});if(s){let e=this._call(f,{add_special_tokens:!1,padding:i,truncation:a,max_length:l,return_tensor:u,...m});return d?e:e.input_ids}return f}}class ex extends eT{return_token_type_ids=!0}class eP extends eT{return_token_type_ids=!0}class eb extends eT{return_token_type_ids=!0}class eF extends eT{return_token_type_ids=!0}class ek extends eT{return_token_type_ids=!0}class ey extends eT{return_token_type_ids=!0}class ev extends eT{return_token_type_ids=!0}class eC extends eT{return_token_type_ids=!0}class eS extends eT{return_token_type_ids=!0}class eE extends eT{}class eA extends eT{}class eL extends eT{return_token_type_ids=!0;constructor(e,t){super(e,t),console.warn('WARNING: `XLMTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.')}}class eI extends eT{return_token_type_ids=!0}class eD extends eT{}class ez extends eT{}class ej extends eT{}class eV extends eT{constructor(e,t){super(e,t),this.languageRegex=/^[a-z]{2}_[A-Z]{2}$/,this.language_codes=this.special_tokens.filter(e=>this.languageRegex.test(e)),this.lang_to_token=e=>e}_build_translation_inputs(e,t,r){return eY(this,e,t,r)}}class eO extends eV{}class eN extends eT{}class eB extends eT{}class eG extends eT{padding_side="left";constructor(e,t){super(e,t),this.legacy=t.legacy??!0,this.legacy||(this.normalizer=null,this.pre_tokenizer=new em({replacement:"▁",add_prefix_space:!0,prepend_scheme:"first"}))}_encode_text(e){if(null===e)return null;if(this.legacy||0===e.length)return super._encode_text(e);let t=super._encode_text("▁"+e.replaceAll("▁"," "));return t.length>1&&"▁"===t[0]&&this.special_tokens.includes(t[1])&&(t=t.slice(1)),t}}class eR extends eT{}class eq extends eT{}class e$ extends eT{}class eW extends eT{}class eU extends eT{}class eQ extends eT{}class eX extends eT{}class eH extends eT{}class eJ extends eT{}function eY(e,t,r,n){if(!("language_codes"in e)||!Array.isArray(e.language_codes))throw Error("Tokenizer must have `language_codes` attribute set and it should be an array of language ids.");if(!("languageRegex"in e)||!(e.languageRegex instanceof RegExp))throw Error("Tokenizer must have `languageRegex` attribute set and it should be a regular expression.");if(!("lang_to_token"in e)||"function"!=typeof e.lang_to_token)throw Error("Tokenizer must have `lang_to_token` attribute set and it should be a function.");let o=n.src_lang,s=n.tgt_lang;if(!e.language_codes.includes(s))throw Error(`Target language code "${s}" is not valid. Must be one of: {${e.language_codes.join(", ")}}`);if(void 0!==o){if(!e.language_codes.includes(o))throw Error(`Source language code "${o}" is not valid. Must be one of: {${e.language_codes.join(", ")}}`);for(let t of e.post_processor.config.single)if("SpecialToken"in t&&e.languageRegex.test(t.SpecialToken.id)){t.SpecialToken.id=e.lang_to_token(o);break}}return n.forced_bos_token_id=e.model.convert_tokens_to_ids([e.lang_to_token(s)])[0],e._call(t,r)}class eK extends eT{constructor(e,t){super(e,t),this.languageRegex=/^[a-z]{3}_[A-Z][a-z]{3}$/,this.language_codes=this.special_tokens.filter(e=>this.languageRegex.test(e)),this.lang_to_token=e=>e}_build_translation_inputs(e,t,r){return eY(this,e,t,r)}}class eZ extends eT{constructor(e,t){super(e,t),this.languageRegex=/^__[a-z]{2,3}__$/,this.language_codes=this.special_tokens.filter(e=>this.languageRegex.test(e)).map(e=>e.slice(2,-2)),this.lang_to_token=e=>`__${e}__`}_build_translation_inputs(e,t,r){return eY(this,e,t,r)}}class e0 extends eT{get timestamp_begin(){return this.model.convert_tokens_to_ids(["<|notimestamps|>"])[0]+1}_decode_asr(e,{return_timestamps:t=!1,return_language:r=!1,time_precision:n=null,force_full_sequences:o=!0}={}){if(null===n)throw Error("Must specify time_precision");let s=null,a="word"===t;function l(){return{language:s,timestamp:[null,null],text:""}}let c=[],d=l(),m=0,p=this.timestamp_begin,_=p+1500,h=[],f=[],g=!1,M=null,T=new Set(this.all_special_ids);for(let r of e){let e=r.tokens,o=a?r.token_timestamps:null,x=null,P=p;if("stride"in r){let[t,o,s]=r.stride;if(m-=o,M=t-s,o&&(P=o/n+p),s)for(let t=e.length-1;t>=0;--t){let r=Number(e[t]);if(r>=p){if(null!==x&&(r-p)*n<M)break;x=r}}}let b=[],F=[];for(let r=0;r<e.length;++r){let M=Number(e[r]);if(T.has(M)){let e=this.decode([M]),r=u.WHISPER_LANGUAGE_MAPPING.get(e.slice(2,-2));if(void 0!==r){if(null!==s&&r!==s&&!t){h.push(b);let e=this.findLongestCommonSequence(h)[0],t=this.decode(e);d.text=t,c.push(d),h=[],b=[],d=l()}s=d.language=r}}else if(M>=p&&M<=_){let e=(M-p)*n+m,t=(0,i.round)(e,2);if(null!==x&&M>=x)g=!0;else if(g||h.length>0&&M<P)g=!1;else if(null===d.timestamp[0])d.timestamp[0]=t;else if(t===d.timestamp[0]);else{d.timestamp[1]=t,h.push(b),a&&f.push(F);let[e,r]=this.findLongestCommonSequence(h,f),n=this.decode(e);d.text=n,a&&(d.words=this.collateWordTimestamps(e,r,s)),c.push(d),h=[],b=[],f=[],F=[],d=l()}}else if(b.push(M),a){let e,t=(0,i.round)(o[r]+m,2);if(r+1<o.length){e=(0,i.round)(o[r+1]+m,2);let s=this.decode([M]);w.test(s)&&(e=(0,i.round)(Math.min(t+n,e),2))}else e=null;F.push([t,e])}}if("stride"in r){let[e,t,n]=r.stride;m+=e-n}b.length>0?(h.push(b),a&&f.push(F)):h.every(e=>0===e.length)&&(d=l(),h=[],b=[],f=[],F=[])}if(h.length>0){if(o&&t)throw Error("Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.");let[e,r]=this.findLongestCommonSequence(h,f),n=this.decode(e);d.text=n,a&&(d.words=this.collateWordTimestamps(e,r,s)),c.push(d)}let x=Object.create(null),P=c.map(e=>e.text).join("");if(t||r){for(let e=0;e<c.length;++e){let n=c[e];t||delete n.timestamp,r||delete n.language}if(a){let e=[];for(let t of c)for(let r of t.words)e.push(r);x={chunks:e}}else x={chunks:c}}return[P,x]}findLongestCommonSequence(e,t=null){let r=e[0],n=r.length,o=[],s=Array.isArray(t)&&t.length>0,i=s?[]:null,a=s?t[0]:null;for(let l=1;l<e.length;++l){let c=e[l],u=0,d=[n,n,0,0],m=c.length;for(let e=1;e<n+m;++e){let o;let i=Math.max(0,n-e),p=Math.min(n,n+m-e),_=r.slice(i,p),h=Math.max(0,e-n),f=Math.min(m,e),g=c.slice(h,f);if(_.length!==g.length)throw Error("There is a bug within whisper `decode_asr` function, please report it. Dropping to prevent bad inference.");o=s?_.filter((e,r)=>e===g[r]&&a[i+r]<=t[l][h+r]).length:_.filter((e,t)=>e===g[t]).length;let M=e/1e4,w=o/e+M;o>1&&w>u&&(u=w,d=[i,p,h,f])}let[p,_,h,f]=d,g=Math.floor((_+p)/2),M=Math.floor((f+h)/2);o.push(...r.slice(0,g)),n=(r=c.slice(M)).length,s&&(i.push(...a.slice(0,g)),a=t[l].slice(M))}return(o.push(...r),s)?(i.push(...a),[o,i]):[o,[]]}collateWordTimestamps(e,t,r){let[n,o,s]=this.combineTokensIntoWords(e,r),i=[];for(let e=0;e<n.length;++e){let r=s[e];i.push({text:n[e],timestamp:[t[r.at(0)][0],t[r.at(-1)][1]]})}return i}combineTokensIntoWords(e,t,r="\"'“\xa1\xbf([{-",n="\"'.。,，!！?？:：”)]}、"){let o,s,i;return["chinese","japanese","thai","lao","myanmar"].includes(t=t??"english")?[o,s,i]=this.splitTokensOnUnicode(e):[o,s,i]=this.splitTokensOnSpaces(e),this.mergePunctuations(o,s,i,r,n)}decode(e,t){let r;return t?.decode_with_timestamps?(e instanceof a.Tensor&&(e=_(e)),r=this.decodeWithTimestamps(e,t)):r=super.decode(e,t),r}decodeWithTimestamps(e,t){let r=t?.time_precision??.02,n=Array.from(this.all_special_ids).at(-1)+1,o=[[]];for(let t of e)if((t=Number(t))>=n){let e=((t-n)*r).toFixed(2);o.push(`<|${e}|>`),o.push([])}else o[o.length-1].push(t);return(o=o.map(e=>"string"==typeof e?e:super.decode(e,t))).join("")}splitTokensOnUnicode(e){let t=this.decode(e,{decode_with_timestamps:!0}),r=[],n=[],o=[],s=[],i=[],a=0;for(let l=0;l<e.length;++l){let c=e[l];s.push(c),i.push(l);let u=this.decode(s,{decode_with_timestamps:!0});u.includes("�")&&"�"!==t[a+u.indexOf("�")]||(r.push(u),n.push(s),o.push(i),s=[],i=[],a+=u.length)}return[r,n,o]}splitTokensOnSpaces(e){let[t,r,n]=this.splitTokensOnUnicode(e),o=[],s=[],i=[],a=RegExp(`^[${M}]$`,"gu");for(let e=0;e<t.length;++e){let l=t[e],c=r[e],u=n[e],d=c[0]>=this.model.tokens_to_ids.get("<|endoftext|>"),m=l.startsWith(" "),p=l.trim(),_=a.test(p);if(d||m||_||0===o.length)o.push(l),s.push(c),i.push(u);else{let e=o.length-1;o[e]+=l,s[e].push(...c),i[e].push(...u)}}return[o,s,i]}mergePunctuations(e,t,r,n,s){let i=structuredClone(e),a=structuredClone(t),l=structuredClone(r),c=i.length-2,u=i.length-1;for(;c>=0;)i[c].startsWith(" ")&&n.includes(i[c].trim())?(i[u]=i[c]+i[u],a[u]=(0,o.mergeArrays)(a[c],a[u]),l[u]=(0,o.mergeArrays)(l[c],l[u]),i[c]="",a[c]=[],l[c]=[]):u=c,--c;for(c=0,u=1;u<i.length;)!i[c].endsWith(" ")&&s.includes(i[u])?(i[c]+=i[u],a[c]=(0,o.mergeArrays)(a[c],a[u]),l[c]=(0,o.mergeArrays)(l[c],l[u]),i[u]="",a[u]=[],l[u]=[]):c=u,++u;return[i.filter(e=>e),a.filter(e=>e.length>0),l.filter(e=>e.length>0)]}}class e1 extends eT{}class e2 extends eT{}class e3 extends eT{}class e4 extends eT{constructor(e,t){super(e,t),this.languageRegex=/^(>>\w+<<)\s*/g,this.supported_language_codes=this.model.vocab.filter(e=>this.languageRegex.test(e)),console.warn('WARNING: `MarianTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.')}_encode_text(e){if(null===e)return null;let[t,...r]=e.trim().split(this.languageRegex);if(0===r.length)return super._encode_text(t);if(2===r.length){let[e,t]=r;return this.supported_language_codes.includes(e)||console.warn(`Unsupported language code "${e}" detected, which may lead to unexpected behavior. Should be one of: ${JSON.stringify(this.supported_language_codes)}`),(0,o.mergeArrays)([e],super._encode_text(t))}}}class e5 extends eT{}class e8 extends eT{}class e6 extends eT{}class e9 extends eT{}class e7 extends eT{}class te extends eT{constructor(e,t){super(e,t),this.decoder=new ed({})}}class tt extends eT{}class tr extends eT{}class tn extends eT{}class to{static TOKENIZER_CLASS_MAPPING={T5Tokenizer:eD,DistilBertTokenizer:eE,CamembertTokenizer:eA,DebertaTokenizer:ek,DebertaV2Tokenizer:ey,BertTokenizer:ex,HerbertTokenizer:ev,ConvBertTokenizer:eC,RoFormerTokenizer:eS,XLMTokenizer:eL,ElectraTokenizer:eI,MobileBertTokenizer:eb,SqueezeBertTokenizer:eF,AlbertTokenizer:eP,GPT2Tokenizer:ez,BartTokenizer:ej,MBartTokenizer:eV,MBart50Tokenizer:eO,RobertaTokenizer:eN,WhisperTokenizer:e0,CodeGenTokenizer:e1,CLIPTokenizer:e2,SiglipTokenizer:e3,MarianTokenizer:e4,BloomTokenizer:eB,NllbTokenizer:eK,M2M100Tokenizer:eZ,LlamaTokenizer:eG,CodeLlamaTokenizer:eR,XLMRobertaTokenizer:eq,MPNetTokenizer:e$,FalconTokenizer:eW,GPTNeoXTokenizer:eU,EsmTokenizer:eQ,Wav2Vec2CTCTokenizer:e5,BlenderbotTokenizer:e8,BlenderbotSmallTokenizer:e6,SpeechT5Tokenizer:e9,NougatTokenizer:e7,VitsTokenizer:te,Qwen2Tokenizer:eX,GemmaTokenizer:eH,Grok1Tokenizer:eJ,CohereTokenizer:tt,MgpstrTokenizer:tr,Ernie4_5_Tokenizer:tn,PreTrainedTokenizer:eT};static async from_pretrained(e,{progress_callback:t=null,config:r=null,cache_dir:n=null,local_files_only:o=!1,revision:s="main",legacy:i=null}={}){let[a,l]=await d(e,{progress_callback:t,config:r,cache_dir:n,local_files_only:o,revision:s,legacy:i}),c=l.tokenizer_class?.replace(/Fast$/,"")??"PreTrainedTokenizer",u=this.TOKENIZER_CLASS_MAPPING[c];return u||(console.warn(`Unknown tokenizer class "${c}", attempting to construct from base class.`),u=eT),new u(a,l)}}},"./src/utils/audio.js":/*!****************************!*\
  !*** ./src/utils/audio.js ***!
  \****************************/(e,t,r)=>{r.r(t),r.d(t,{RawAudio:()=>P,hamming:()=>m,hanning:()=>d,mel_filter_bank:()=>g,read_audio:()=>c,spectrogram:()=>w,window_function:()=>T});var n=r(/*! ./hub.js */"./src/utils/hub.js"),o=r(/*! ./maths.js */"./src/utils/maths.js"),s=r(/*! ./core.js */"./src/utils/core.js"),i=r(/*! ../env.js */"./src/env.js"),a=r(/*! ./tensor.js */"./src/utils/tensor.js"),l=r(/*! node:fs */"?7992");async function c(e,t){let r;if("undefined"==typeof AudioContext)throw Error("Unable to load audio from path/URL since `AudioContext` is not available in your environment. Instead, audio data should be passed directly to the pipeline/processor. For more information and some example code, see https://huggingface.co/docs/transformers.js/guides/node-audio-processing.");let o=await (await (0,n.getFile)(e)).arrayBuffer(),s=new AudioContext({sampleRate:t});void 0===t&&console.warn(`No sampling rate provided, using default of ${s.sampleRate}Hz.`);let i=await s.decodeAudioData(o);if(2===i.numberOfChannels){let e=Math.sqrt(2),t=i.getChannelData(0),n=i.getChannelData(1);r=new Float32Array(t.length);for(let o=0;o<i.length;++o)r[o]=e*(t[o]+n[o])/2}else r=i.getChannelData(0);return r}function u(e,t){if(e<1)return new Float64Array;if(1===e)return new Float64Array([1]);let r=1-t,n=2*Math.PI/(e-1),o=new Float64Array(e);for(let s=0;s<e;++s)o[s]=t-r*Math.cos(s*n);return o}function d(e){return u(e,.5)}function m(e){return u(e,.54)}let p={htk:e=>2595*Math.log10(1+e/700),kaldi:e=>1127*Math.log(1+e/700),slaney:(e,t=1e3,r=15,n=27/Math.log(6.4))=>e>=t?r+Math.log(e/t)*n:3*e/200};function _(e,t="htk"){let r=p[t];if(!r)throw Error('mel_scale should be one of "htk", "slaney" or "kaldi".');return"number"==typeof e?r(e):e.map(e=>r(e))}let h={htk:e=>700*(10**(e/2595)-1),kaldi:e=>700*(Math.exp(e/1127)-1),slaney:(e,t=1e3,r=15,n=Math.log(6.4)/27)=>e>=r?t*Math.exp(n*(e-r)):200*e/3};function f(e,t,r){let n=(t-e)/(r-1);return Float64Array.from({length:r},(t,r)=>e+n*r)}function g(e,t,r,n,o,s=null,i="htk",a=!1){let l;if(null!==s&&"slaney"!==s)throw Error('norm must be one of null or "slaney"');if(e<2)throw Error(`Require num_frequency_bins: ${e} >= 2`);if(r>n)throw Error(`Require min_frequency: ${r} <= max_frequency: ${n}`);let c=f(_(r,i),_(n,i),t+2),u=function(e,t="htk"){let r=h[t];if(!r)throw Error('mel_scale should be one of "htk", "slaney" or "kaldi".');return"number"==typeof e?r(e):e.map(e=>r(e))}(c,i);if(a){let t=o/((e-1)*2);l=_(Float64Array.from({length:e},(e,r)=>r*t),i),u=c}else l=f(0,Math.floor(o/2),e);let d=function(e,t){let r=Float64Array.from({length:t.length-1},(e,r)=>t[r+1]-t[r]),n=Array.from({length:e.length},()=>Array(t.length));for(let r=0;r<e.length;++r){let o=n[r];for(let n=0;n<t.length;++n)o[n]=t[n]-e[r]}let o=t.length-2,s=Array.from({length:o},()=>Array(e.length));for(let t=0;t<e.length;++t){let e=n[t];for(let n=0;n<o;++n){let o=-e[n]/r[n],i=e[n+2]/r[n+1];s[n][t]=Math.max(0,Math.min(o,i))}}return s}(l,u);if(null!==s&&"slaney"===s)for(let r=0;r<t;++r){let t=d[r],n=2/(u[r+2]-u[r]);for(let r=0;r<e;++r)t[r]*=n}return d}function M(e,t,r,n,s){if(r<=0)throw Error("reference must be greater than zero");if(n<=0)throw Error("min_value must be greater than zero");let i=Math.log10(r=Math.max(n,r));for(let r=0;r<e.length;++r)e[r]=t*Math.log10(Math.max(n,e[r])-i);if(null!==s){if(s<=0)throw Error("db_range must be greater than zero");let t=(0,o.max)(e)[0]-s;for(let r=0;r<e.length;++r)e[r]=Math.max(e[r],t)}return e}async function w(e,t,r,n,{fft_length:i=null,power:l=1,center:c=!0,pad_mode:u="reflect",onesided:d=!0,preemphasis:m=null,preemphasis_htk_flavor:p=!0,mel_filters:_=null,mel_floor:h=1e-10,log_mel:f=null,reference:g=1,min_value:w=1e-10,db_range:T=null,remove_dc_offset:x=null,min_num_frames:P=null,max_num_frames:b=null,do_pad:F=!0,transpose:k=!1}={}){let y=t.length;if(null===i&&(i=r),r>i)throw Error(`frame_length (${r}) may not be larger than fft_length (${i})`);if(y!==r)throw Error(`Length of the window (${y}) must equal frame_length (${r})`);if(n<=0)throw Error("hop_length must be greater than zero");if(null===l&&null!==_)throw Error("You have provided `mel_filters` but `power` is `None`. Mel spectrogram computation is not yet supported for complex-valued spectrogram. Specify `power` to fix this issue.");if(!p)throw Error("`preemphasis_htk_flavor=false` is not currently supported.");if(c){if("reflect"!==u)throw Error(`pad_mode="${u}" not implemented yet.`);let t=Math.floor((i-1)/2)+1;e=function(e,t,r){let n=new e.constructor(e.length+t+r),o=e.length-1;for(let r=0;r<e.length;++r)n[t+r]=e[r];for(let r=1;r<=t;++r)n[t-r]=e[(0,s.calculateReflectOffset)(r,o)];for(let i=1;i<=r;++i)n[o+t+i]=e[(0,s.calculateReflectOffset)(o-i,o)];return n}(e,t,t)}let v=Math.floor(1+Math.floor((e.length-r)/n));null!==P&&v<P&&(v=P);let C=d?Math.floor(i/2)+1:i,S=v,E=v;null!==b&&(b>v?F&&(E=b):E=S=b);let A=new o.FFT(i),L=new Float64Array(i),I=new Float64Array(A.outputBufferSize),D=new Float32Array(C*E);for(let o=0;o<S;++o){let s=o*n,i=Math.min(e.length-s,r);i!==r&&L.fill(0,0,r);for(let t=0;t<i;++t)L[t]=e[s+t];if(x){let e=0;for(let t=0;t<i;++t)e+=L[t];let t=e/i;for(let e=0;e<i;++e)L[e]-=t}if(null!==m){for(let e=i-1;e>=1;--e)L[e]-=m*L[e-1];L[0]*=1-m}for(let e=0;e<t.length;++e)L[e]*=t[e];A.realTransform(I,L);for(let e=0;e<C;++e){let t=e<<1;D[e*E+o]=I[t]**2+I[t+1]**2}}if(null!==l&&2!==l){let e=l/2;for(let t=0;t<D.length;++t)D[t]**=e}let z=_.length,j=await (0,a.matmul)(new a.Tensor("float32",_.flat(),[z,C]),new a.Tensor("float32",D,[C,E]));k&&(j=j.transpose(1,0));let V=j.data;for(let e=0;e<V.length;++e)V[e]=Math.max(h,V[e]);if(null!==l&&null!==f){let e=Math.min(V.length,S*z);switch(f){case"log":for(let t=0;t<e;++t)V[t]=Math.log(V[t]);break;case"log10":for(let t=0;t<e;++t)V[t]=Math.log10(V[t]);break;case"dB":if(1===l)!function(e,t=1,r=1e-5,n=null){M(e,20,t,r,n)}(V,g,w,T);else if(2===l)!function(e,t=1,r=1e-10,n=null){M(e,10,t,r,n)}(V,g,w,T);else throw Error(`Cannot use log_mel option '${f}' with power ${l}`);break;default:throw Error(`log_mel must be one of null, 'log', 'log10' or 'dB'. Got '${f}'`)}}return j}function T(e,t,{periodic:r=!0,frame_length:n=null,center:o=!0}={}){let s;let i=r?e+1:e;switch(t){case"boxcar":s=new Float64Array(i).fill(1);break;case"hann":case"hann_window":s=d(i);break;case"hamming":s=m(i);break;case"povey":s=d(i).map(e=>Math.pow(e,.85));break;default:throw Error(`Unknown window type ${t}.`)}if(r&&(s=s.subarray(0,e)),null===n)return s;if(e>n)throw Error(`Length of the window (${e}) may not be larger than frame_length (${n})`);return s}function x(e,t,r){for(let n=0;n<r.length;++n)e.setUint8(t+n,r.charCodeAt(n))}class P{constructor(e,t){this.audio=e,this.sampling_rate=t}toWav(){return function(e,t){let r=44,n=new ArrayBuffer(r+4*e.length),o=new DataView(n);x(o,0,"RIFF"),o.setUint32(4,36+4*e.length,!0),x(o,8,"WAVE"),x(o,12,"fmt "),o.setUint32(16,16,!0),o.setUint16(20,3,!0),o.setUint16(22,1,!0),o.setUint32(24,t,!0),o.setUint32(28,4*t,!0),o.setUint16(32,4,!0),o.setUint16(34,32,!0),x(o,36,"data"),o.setUint32(40,4*e.length,!0);for(let t=0;t<e.length;++t,r+=4)o.setFloat32(r,e[t],!0);return n}(this.audio,this.sampling_rate)}toBlob(){let e=this.toWav();return new Blob([e],{type:"audio/wav"})}async save(e){let t;if(i.apis.IS_BROWSER_ENV){if(i.apis.IS_WEBWORKER_ENV)throw Error("Unable to save a file from a Web Worker.");t=s.saveBlob}else if(i.apis.IS_FS_AVAILABLE)t=async(e,t)=>{let r=await t.arrayBuffer();l.writeFileSync(e,A.from(r))};else throw Error("Unable to save because filesystem is disabled in this environment.");await t(e,this.toBlob())}}},"./src/utils/constants.js":/*!********************************!*\
  !*** ./src/utils/constants.js ***!
  \********************************/(e,t,r)=>{r.r(t),r.d(t,{CHAT_TEMPLATE_NAME:()=>l,CONFIG_NAME:()=>o,FEATURE_EXTRACTOR_NAME:()=>s,GENERATION_CONFIG_NAME:()=>c,GITHUB_ISSUE_URL:()=>n,IMAGE_PROCESSOR_NAME:()=>i,PROCESSOR_NAME:()=>a});let n="https://github.com/huggingface/transformers.js/issues/new/choose",o="config.json",s="preprocessor_config.json",i=s,a="processor_config.json",l="chat_template.jinja",c="generation_config.json"},"./src/utils/core.js":/*!***************************!*\
  !*** ./src/utils/core.js ***!
  \***************************/(e,t,r)=>{function n(e,t){e&&e(t)}function o(e){return Object.fromEntries(Object.entries(e).map(([e,t])=>[t,e]))}function s(e){return e.replace(/[.*+?^${}()|[\]\\]/g,"\\$&")}function i(e){return e?.prototype?.__proto__?.constructor?.name==="TypedArray"}function a(e){return Number.isInteger(e)||"bigint"==typeof e}function l(e){return null==e||-1===e}function c(e){let t=[],r=e;for(;Array.isArray(r);)t.push(r.length),r=r[0];return t}function u(e,t,r){let n=e[t];if(void 0!==n)return delete e[t],n;if(void 0===r)throw Error(`Key ${t} does not exist in object.`);return r}function d(...e){return Array.prototype.concat.apply([],e)}function m(...e){return e.reduce((e,t)=>e.flatMap(e=>t.map(t=>[e,t])))}function p(e,t){return Math.abs((e+t)%(2*t)-t)}function _(e,t){let r=URL.createObjectURL(t),n=document.createElement("a");n.href=r,n.download=e,n.click(),n.remove(),URL.revokeObjectURL(r)}function h(e,t){return Object.assign({},...t.map(t=>{if(void 0!==e[t])return{[t]:e[t]}}))}function f(e){let t=0;for(let r of e)++t;return t}function g(e,t){let r=0;for(let n of e)n===t&&++r;return r}r.r(t),r.d(t,{calculateDimensions:()=>c,calculateReflectOffset:()=>p,count:()=>g,dispatchCallback:()=>n,escapeRegExp:()=>s,isIntegralNumber:()=>a,isNullishDimension:()=>l,isTypedArray:()=>i,len:()=>f,mergeArrays:()=>d,pick:()=>h,pop:()=>u,product:()=>m,reverseDictionary:()=>o,saveBlob:()=>_})},"./src/utils/data-structures.js":/*!**************************************!*\
  !*** ./src/utils/data-structures.js ***!
  \**************************************/(e,t,r)=>{r.r(t),r.d(t,{CharTrie:()=>o,DictionarySplitter:()=>l,LRUCache:()=>c,PriorityQueue:()=>n,TokenLattice:()=>i});class n{constructor(e=(e,t)=>e>t,t=1/0){this._heap=[],this._comparator=e,this._maxSize=t}get size(){return this._heap.length}isEmpty(){return 0===this.size}peek(){return this._heap[0]}push(...e){return this.extend(e)}extend(e){for(let t of e)if(this.size<this._maxSize)this._heap.push(t),this._siftUp();else{let e=this._smallest();this._comparator(t,this._heap[e])&&(this._heap[e]=t,this._siftUpFrom(e))}return this.size}pop(){let e=this.peek(),t=this.size-1;return t>0&&this._swap(0,t),this._heap.pop(),this._siftDown(),e}replace(e){let t=this.peek();return this._heap[0]=e,this._siftDown(),t}_parent(e){return(e+1>>>1)-1}_left(e){return(e<<1)+1}_right(e){return e+1<<1}_greater(e,t){return this._comparator(this._heap[e],this._heap[t])}_swap(e,t){let r=this._heap[e];this._heap[e]=this._heap[t],this._heap[t]=r}_siftUp(){this._siftUpFrom(this.size-1)}_siftUpFrom(e){for(;e>0&&this._greater(e,this._parent(e));)this._swap(e,this._parent(e)),e=this._parent(e)}_siftDown(){let e=0;for(;this._left(e)<this.size&&this._greater(this._left(e),e)||this._right(e)<this.size&&this._greater(this._right(e),e);){let t=this._right(e)<this.size&&this._greater(this._right(e),this._left(e))?this._right(e):this._left(e);this._swap(e,t),e=t}}_smallest(){return 2**Math.floor(Math.log2(this.size))-1}}class o{constructor(){this.root=s.default()}extend(e){for(let t of e)this.push(t)}push(e){let t=this.root;for(let r of e){let e=t.children.get(r);void 0===e&&(e=s.default(),t.children.set(r,e)),t=e}t.isLeaf=!0}*commonPrefixSearch(e){let t=this.root;if(void 0===t)return;let r="";for(let n of e){if(r+=n,void 0===(t=t.children.get(n)))return;t.isLeaf&&(yield r)}}}class s{constructor(e,t){this.isLeaf=e,this.children=t}static default(){return new s(!1,new Map)}}class i{constructor(e,t,r){this.chars=Array.from(e),this.len=this.chars.length,this.bosTokenId=t,this.eosTokenId=r,this.nodes=[],this.beginNodes=Array.from({length:this.len+1},()=>[]),this.endNodes=Array.from({length:this.len+1},()=>[]);let n=new a(this.bosTokenId,0,0,0,0),o=new a(this.eosTokenId,1,this.len,0,0);this.nodes.push(n.clone()),this.nodes.push(o.clone()),this.beginNodes[this.len].push(o),this.endNodes[0].push(n)}insert(e,t,r,n){let o=new a(n,this.nodes.length,e,t,r);this.beginNodes[e].push(o),this.endNodes[e+t].push(o),this.nodes.push(o)}viterbi(){let e=this.len,t=0;for(;t<=e;){if(0==this.beginNodes[t].length)return[];for(let e of this.beginNodes[t]){e.prev=null;let r=0,n=null;for(let o of this.endNodes[t]){let t=o.backtraceScore+e.score;(null===n||t>r)&&(n=o.clone(),r=t)}if(null===n)return[];e.prev=n,e.backtraceScore=r}++t}let r=[],n=this.beginNodes[e][0].prev;if(null===n)return[];let o=n.clone();for(;null!==o.prev;)r.push(o.clone()),o=o.clone().prev.clone();return r.reverse(),r}piece(e){return this.chars.slice(e.pos,e.pos+e.length).join("")}tokens(){return this.viterbi().map(e=>this.piece(e))}tokenIds(){return this.viterbi().map(e=>e.tokenId)}}class a{constructor(e,t,r,n,o){this.tokenId=e,this.nodeId=t,this.pos=r,this.length=n,this.score=o,this.prev=null,this.backtraceScore=0}clone(){let e=new a(this.tokenId,this.nodeId,this.pos,this.length,this.score);return e.prev=this.prev,e.backtraceScore=this.backtraceScore,e}}class l{constructor(e){this.trie=this._buildTrie(e)}_buildTrie(e){let t=Object.create(null);for(let r of e){let e=t;for(let t=0;t<r.length;++t)e=e[r[t]]??=Object.create(null);e.end=r}return t}split(e){let t=[],r=e.length,n=0,o=0;for(;o<r;){let s=this.trie,i=null,a=o;for(;a<r&&(s=s[e[a]]);)s.end&&(i=s.end),++a;i?(o>n&&t.push(e.slice(n,o)),t.push(i),o+=i.length,n=o):++o}return n<r&&t.push(e.slice(n)),t}}class c{constructor(e){this.capacity=e,this.cache=new Map}get(e){if(!this.cache.has(e))return;let t=this.cache.get(e);return this.cache.delete(e),this.cache.set(e,t),t}put(e,t){this.cache.has(e)&&this.cache.delete(e),this.cache.set(e,t),this.cache.size>this.capacity&&this.cache.delete(this.cache.keys().next().value)}clear(){this.cache.clear()}}},"./src/utils/devices.js":/*!******************************!*\
  !*** ./src/utils/devices.js ***!
  \******************************/(e,t,r)=>{r.r(t),r.d(t,{DEVICE_TYPES:()=>n});let n=Object.freeze({auto:"auto",gpu:"gpu",cpu:"cpu",wasm:"wasm",webgpu:"webgpu",cuda:"cuda",dml:"dml",webnn:"webnn","webnn-npu":"webnn-npu","webnn-gpu":"webnn-gpu","webnn-cpu":"webnn-cpu"})},"./src/utils/dtypes.js":/*!*****************************!*\
  !*** ./src/utils/dtypes.js ***!
  \*****************************/(e,t,r)=>{let n;r.r(t),r.d(t,{DATA_TYPES:()=>a,DEFAULT_DEVICE_DTYPE_MAPPING:()=>l,DEFAULT_DTYPE_SUFFIX_MAPPING:()=>c,isWebGpuFp16Supported:()=>i});var o=r(/*! ../env.js */"./src/env.js"),s=r(/*! ./devices.js */"./src/utils/devices.js");let i=async function(){if(void 0===n){if(o.apis.IS_WEBGPU_AVAILABLE)try{n=(await navigator.gpu.requestAdapter()).features.has("shader-f16")}catch(e){n=!1}else n=!1}return n},a=Object.freeze({auto:"auto",fp32:"fp32",fp16:"fp16",q8:"q8",int8:"int8",uint8:"uint8",q4:"q4",bnb4:"bnb4",q4f16:"q4f16"}),l=Object.freeze({[s.DEVICE_TYPES.wasm]:a.q8}),c=Object.freeze({[a.fp32]:"",[a.fp16]:"_fp16",[a.int8]:"_int8",[a.uint8]:"_uint8",[a.q8]:"_quantized",[a.q4]:"_q4",[a.q4f16]:"_q4f16",[a.bnb4]:"_bnb4"})},"./src/utils/generic.js":/*!******************************!*\
  !*** ./src/utils/generic.js ***!
  \******************************/(e,t,r)=>{r.r(t),r.d(t,{Callable:()=>n});let n=class{constructor(){let e=function(...t){return e._call(...t)};return Object.setPrototypeOf(e,new.target.prototype)}_call(...e){throw Error("Must implement _call method in subclass")}}},"./src/utils/hub.js":/*!**************************!*\
  !*** ./src/utils/hub.js ***!
  \**************************/(e,t,r)=>{r.r(t),r.d(t,{MAX_EXTERNAL_DATA_CHUNKS:()=>a,getFile:()=>m,getModelFile:()=>f,getModelJSON:()=>M,getModelText:()=>g});var n=r(/*! node:fs */"?7992"),o=r(/*! node:path */"?5af5"),s=r(/*! ../env.js */"./src/env.js"),i=r(/*! ./core.js */"./src/utils/core.js");let a=100,l={txt:"text/plain",html:"text/html",css:"text/css",js:"text/javascript",json:"application/json",png:"image/png",jpg:"image/jpeg",jpeg:"image/jpeg",gif:"image/gif"};class c{constructor(e){if(this.filePath=e,this.headers=new Headers,this.exists=n.existsSync(e),this.exists){this.status=200,this.statusText="OK";let t=n.statSync(e);this.headers.set("content-length",t.size.toString()),this.updateContentType();let r=n.createReadStream(e);this.body=new ReadableStream({start(e){r.on("data",t=>e.enqueue(t)),r.on("end",()=>e.close()),r.on("error",t=>e.error(t))},cancel(){r.destroy()}})}else this.status=404,this.statusText="Not Found",this.body=null}updateContentType(){let e=this.filePath.toString().split(".").pop().toLowerCase();this.headers.set("content-type",l[e]??"application/octet-stream")}clone(){let e=new c(this.filePath);return e.exists=this.exists,e.status=this.status,e.statusText=this.statusText,e.headers=new Headers(this.headers),e}async arrayBuffer(){return(await n.promises.readFile(this.filePath)).buffer}async blob(){let e=await n.promises.readFile(this.filePath);return new Blob([e],{type:this.headers.get("content-type")})}async text(){return await n.promises.readFile(this.filePath,"utf8")}async json(){return JSON.parse(await this.text())}}function u(e,t=null,r=null){let n;try{n=new URL(e)}catch(e){return!1}return(!t||!!t.includes(n.protocol))&&(!r||!!r.includes(n.hostname))}let d=/^(\b[\w\-.]+\b\/)?\b[\w\-.]{1,96}\b$/;async function m(e){if(s.env.useFS&&!u(e,["http:","https:","blob:"]))return new c(e instanceof URL?"file:"===e.protocol?e.pathname:e.toString():e);if(void 0===E||E?.release?.name!=="node")return fetch(e);{let t=!!E.env?.TESTING_REMOTELY,r=s.env.version,n=new Headers;if(n.set("User-Agent",`transformers.js/${r}; is_ci/${t};`),u(e,["http:","https:"],["huggingface.co","hf.co"])){let e=E.env?.HF_TOKEN??E.env?.HF_ACCESS_TOKEN;e&&n.set("Authorization",`Bearer ${e}`)}return fetch(e,{headers:n})}}let p={400:"Bad request error occurred while trying to load file",401:"Unauthorized access to file",403:"Forbidden access to file",404:"Could not locate file",408:"Request timeout error occurred while trying to load file",500:"Internal server error error occurred while trying to load file",502:"Bad gateway error occurred while trying to load file",503:"Service unavailable error occurred while trying to load file",504:"Gateway timeout error occurred while trying to load file"};class _{constructor(e){this.path=e}async match(e){let t=new c(o.join(this.path,e));return t.exists?t:void 0}async put(e,t,r){let s=o.join(this.path,e);try{let e=t.headers.get("Content-Length"),i=parseInt(e??"0"),a=0;await n.promises.mkdir(o.dirname(s),{recursive:!0});let l=n.createWriteStream(s),c=t.body.getReader();for(;;){let{done:e,value:t}=await c.read();if(e)break;await new Promise((e,r)=>{l.write(t,t=>{if(t){r(t);return}e()})}),a+=t.length;let n=i?a/i*100:0;r?.({progress:n,loaded:a,total:i})}l.close()}catch(e){try{await n.promises.unlink(s)}catch{}throw e}}}async function h(e,...t){for(let r of t)try{let t=await e.match(r);if(t)return t}catch(e){continue}}async function f(e,t,r=!0,n={},o=!1){let a,l,f,g;if(!s.env.allowLocalModels){if(n.local_files_only)throw Error("Invalid configuration detected: local models are disabled (`env.allowLocalModels=false`) but you have requested to only use local models (`local_files_only=true`).");if(!s.env.allowRemoteModels)throw Error("Invalid configuration detected: both local and remote models are disabled. Fix by setting `env.allowLocalModels` or `env.allowRemoteModels` to `true`.")}if((0,i.dispatchCallback)(n.progress_callback,{status:"initiate",name:e,file:t}),!a&&s.env.useCustomCache){if(!s.env.customCache)throw Error("`env.useCustomCache=true`, but `env.customCache` is not defined.");if(!s.env.customCache.match||!s.env.customCache.put)throw Error("`env.customCache` must be an object which implements the `match` and `put` functions of the Web Cache API. For more information, see https://developer.mozilla.org/en-US/docs/Web/API/Cache");a=s.env.customCache}if(!a&&s.env.useBrowserCache){if("undefined"==typeof caches)throw Error("Browser cache is not available in this environment.");try{a=await caches.open("transformers-cache")}catch(e){console.warn("An error occurred while opening the browser cache:",e)}}if(!a&&s.env.useFSCache){if(!s.apis.IS_FS_AVAILABLE)throw Error("File System Cache is not available in this environment.");a=new _(n.cache_dir??s.env.cacheDir)}let M=n.revision??"main",x=T(e,t),P=!(!d.test(e)||e.includes("..")||e.includes("--")||e.endsWith(".git")||e.endsWith(".ipynb")),b=P?T(s.env.localModelPath,x):x,F=T(s.env.remoteHost,s.env.remotePathTemplate.replaceAll("{model}",e).replaceAll("{revision}",encodeURIComponent(M)),t),k=a instanceof _?"main"===M?x:T(e,M,t):F,y=!1;a&&(f=await h(a,b,k));let v=void 0!==f;if(void 0===f){if(s.env.allowLocalModels){if(u(x,["http:","https:"])){if(n.local_files_only)throw Error(`\`local_files_only=true\`, but attempted to load a remote file from: ${x}.`);if(!s.env.allowRemoteModels)throw Error(`\`env.allowRemoteModels=false\`, but attempted to load a remote file from: ${x}.`)}else try{f=await m(b),l=b}catch(e){console.warn(`Unable to load from local path "${b}": "${e}"`)}}if(void 0===f||404===f.status){if(n.local_files_only||!s.env.allowRemoteModels){if(!r)return null;throw Error(`\`local_files_only=true\` or \`env.allowRemoteModels=false\` and file was not found locally at "${b}".`)}if(!P)throw Error(`Local file missing at "${b}" and download aborted due to invalid model ID "${e}".`);if(200!==(f=await m(F)).status)return function(e,t,r){if(!r)return null;let n=p[e]??`Error (${e}) occurred while trying to load file`;throw Error(`${n}: "${t}".`)}(f.status,F,r);l=k}y=a&&"undefined"!=typeof Response&&f instanceof Response&&200===f.status}if((0,i.dispatchCallback)(n.progress_callback,{status:"download",name:e,file:t}),!(s.apis.IS_NODE_ENV&&o)){let r;n.progress_callback?v&&"undefined"!=typeof navigator&&/firefox/i.test(navigator.userAgent)?(r=new Uint8Array(await f.arrayBuffer()),(0,i.dispatchCallback)(n.progress_callback,{status:"progress",name:e,file:t,progress:100,loaded:r.length,total:r.length})):r=await w(f,r=>{(0,i.dispatchCallback)(n.progress_callback,{status:"progress",name:e,file:t,...r})}):r=new Uint8Array(await f.arrayBuffer()),g=r}if(y&&l&&await a.match(l)===void 0&&(g?await a.put(l,new Response(g,{headers:f.headers})).catch(e=>{console.warn(`Unable to add response to browser cache: ${e}.`)}):await a.put(l,f,n.progress_callback)),(0,i.dispatchCallback)(n.progress_callback,{status:"done",name:e,file:t}),g){if(!s.apis.IS_NODE_ENV&&o)throw Error("Cannot return path in a browser environment.");return g}if(f instanceof c)return f.filePath;let C=await a?.match(l);if(C instanceof c)return C.filePath;if(C instanceof Response)return new Uint8Array(await C.arrayBuffer());if("string"==typeof C)return C;throw Error("Unable to get model file path or buffer.")}async function g(e,t,r=!0,n={}){let o=await f(e,t,r,n,!1);return null===o?null:new TextDecoder("utf-8").decode(o)}async function M(e,t,r=!0,n={}){let o=await g(e,t,r,n);return null===o?{}:JSON.parse(o)}async function w(e,t){let r=e.headers.get("Content-Length");null===r&&console.warn("Unable to determine content-length from response headers. Will expand buffer when needed.");let n=parseInt(r??"0"),o=new Uint8Array(n),s=0,i=e.body.getReader();async function a(){let{done:e,value:r}=await i.read();if(e)return;let l=s+r.length;if(l>n){n=l;let e=new Uint8Array(n);e.set(o),o=e}return o.set(r,s),t({progress:(s=l)/n*100,loaded:s,total:n}),a()}return await a(),o}function T(...e){return(e=e.map((t,r)=>(r&&(t=t.replace(RegExp("^/"),"")),r!==e.length-1&&(t=t.replace(RegExp("/$"),"")),t))).join("/")}},"./src/utils/image.js":/*!****************************!*\
  !*** ./src/utils/image.js ***!
  \****************************/(e,t,r)=>{let n,o,s;r.r(t),r.d(t,{RawImage:()=>_,load_image:()=>h});var i=r(/*! ./core.js */"./src/utils/core.js"),a=r(/*! ./hub.js */"./src/utils/hub.js"),l=r(/*! ../env.js */"./src/env.js"),c=r(/*! ./tensor.js */"./src/utils/tensor.js"),u=r(/*! sharp */"?2b25");let d=l.apis.IS_BROWSER_ENV||l.apis.IS_WEBWORKER_ENV;if(d)n=(e,t)=>{if(!self.OffscreenCanvas)throw Error("OffscreenCanvas not supported by this browser.");return new self.OffscreenCanvas(e,t)},s=self.createImageBitmap,o=self.ImageData;else if(u)s=async e=>{let t=(await e.metadata()).channels,{data:r,info:n}=await e.rotate().raw().toBuffer({resolveWithObject:!0}),o=new _(new Uint8ClampedArray(r),n.width,n.height,n.channels);return void 0!==t&&t!==n.channels&&o.convert(t),o};else throw Error("Unable to load image processing library.");let m={0:"nearest",1:"lanczos",2:"bilinear",3:"bicubic",4:"box",5:"hamming"},p=new Map([["png","image/png"],["jpg","image/jpeg"],["jpeg","image/jpeg"],["gif","image/gif"]]);class _{constructor(e,t,r,n){this.data=e,this.width=t,this.height=r,this.channels=n}get size(){return[this.width,this.height]}static async read(e){if(e instanceof _)return e;if("string"==typeof e||e instanceof URL)return await this.fromURL(e);if(e instanceof Blob)return await this.fromBlob(e);if("undefined"!=typeof HTMLCanvasElement&&e instanceof HTMLCanvasElement||"undefined"!=typeof OffscreenCanvas&&e instanceof OffscreenCanvas)return this.fromCanvas(e);throw Error(`Unsupported input type: ${typeof e}`)}static fromCanvas(e){if(!d)throw Error("fromCanvas() is only supported in browser environments.");return new _(e.getContext("2d").getImageData(0,0,e.width,e.height).data,e.width,e.height,4)}static async fromURL(e){let t=await (0,a.getFile)(e);if(200!==t.status)throw Error(`Unable to read image from "${e}" (${t.status} ${t.statusText})`);let r=await t.blob();return this.fromBlob(r)}static async fromBlob(e){if(d){let t=await s(e),r=n(t.width,t.height).getContext("2d");return r.drawImage(t,0,0),new this(r.getImageData(0,0,t.width,t.height).data,t.width,t.height,4)}{let t=u(await e.arrayBuffer());return await s(t)}}static fromTensor(e,t="CHW"){if(3!==e.dims.length)throw Error(`Tensor should have 3 dimensions, but has ${e.dims.length} dimensions.`);if("CHW"===t)e=e.transpose(1,2,0);else if("HWC"===t);else throw Error(`Unsupported channel format: ${t}`);if(!(e.data instanceof Uint8ClampedArray||e.data instanceof Uint8Array))throw Error(`Unsupported tensor type: ${e.type}`);switch(e.dims[2]){case 1:case 2:case 3:case 4:return new _(e.data,e.dims[1],e.dims[0],e.dims[2]);default:throw Error(`Unsupported number of channels: ${e.dims[2]}`)}}grayscale(){if(1===this.channels)return this;let e=new Uint8ClampedArray(this.width*this.height*1);switch(this.channels){case 3:case 4:for(let t=0,r=0;t<this.data.length;t+=this.channels){let n=this.data[t],o=this.data[t+1],s=this.data[t+2];e[r++]=Math.round(.2989*n+.587*o+.114*s)}break;default:throw Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this._update(e,this.width,this.height,1)}rgb(){if(3===this.channels)return this;let e=new Uint8ClampedArray(this.width*this.height*3);switch(this.channels){case 1:for(let t=0,r=0;t<this.data.length;++t)e[r++]=this.data[t],e[r++]=this.data[t],e[r++]=this.data[t];break;case 4:for(let t=0,r=0;t<this.data.length;t+=4)e[r++]=this.data[t],e[r++]=this.data[t+1],e[r++]=this.data[t+2];break;default:throw Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this._update(e,this.width,this.height,3)}rgba(){if(4===this.channels)return this;let e=new Uint8ClampedArray(this.width*this.height*4);switch(this.channels){case 1:for(let t=0,r=0;t<this.data.length;++t)e[r++]=this.data[t],e[r++]=this.data[t],e[r++]=this.data[t],e[r++]=255;break;case 3:for(let t=0,r=0;t<this.data.length;t+=3)e[r++]=this.data[t],e[r++]=this.data[t+1],e[r++]=this.data[t+2],e[r++]=255;break;default:throw Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this._update(e,this.width,this.height,4)}putAlpha(e){if(e.width!==this.width||e.height!==this.height)throw Error(`Expected mask size to be ${this.width}x${this.height}, but got ${e.width}x${e.height}`);if(1!==e.channels)throw Error(`Expected mask to have 1 channel, but got ${e.channels}`);let t=this.data,r=e.data,n=this.width*this.height;if(3===this.channels){let e=new Uint8ClampedArray(4*n);for(let o=0,s=0,i=0;o<n;++o)e[i++]=t[s++],e[i++]=t[s++],e[i++]=t[s++],e[i++]=r[o];return this._update(e,this.width,this.height,4)}if(4===this.channels){for(let e=0;e<n;++e)t[4*e+3]=r[e];return this}throw Error(`Expected image to have 3 or 4 channels, but got ${this.channels}`)}async resize(e,t,{resample:r=2}={}){if(this.width===e&&this.height===t)return this;let o=m[r]??r,a=(0,i.isNullishDimension)(e),l=(0,i.isNullishDimension)(t);if(a&&l)return this;if(a?e=t/this.height*this.width:l&&(t=e/this.width*this.height),d){let r=this.channels,o=this.toCanvas(),s=n(e,t).getContext("2d");return s.drawImage(o,0,0,e,t),new _(s.getImageData(0,0,e,t).data,e,t,4).convert(r)}{let r=this.toSharp();switch(o){case"box":case"hamming":("box"===o||"hamming"===o)&&(console.warn(`Resampling method ${o} is not yet supported. Using bilinear instead.`),o="bilinear");case"nearest":case"bilinear":case"bicubic":r=r.affine([e/this.width,0,0,t/this.height],{interpolator:o});break;case"lanczos":r=r.resize({width:e,height:t,fit:"fill",kernel:"lanczos3"});break;default:throw Error(`Resampling method ${o} is not supported.`)}return await s(r)}}async pad([e,t,r,o]){if(e=Math.max(e,0),t=Math.max(t,0),r=Math.max(r,0),o=Math.max(o,0),0===e&&0===t&&0===r&&0===o)return this;if(d){let s=this.channels,i=this.toCanvas(),a=this.width+e+t,l=this.height+r+o,c=n(a,l).getContext("2d");return c.drawImage(i,0,0,this.width,this.height,e,r,this.width,this.height),new _(c.getImageData(0,0,a,l).data,a,l,4).convert(s)}{let n=this.toSharp().extend({left:e,right:t,top:r,bottom:o});return await s(n)}}async crop([e,t,r,o]){if(e=Math.max(e,0),t=Math.max(t,0),r=Math.min(r,this.width-1),o=Math.min(o,this.height-1),0===e&&0===t&&r===this.width-1&&o===this.height-1)return this;let i=r-e+1,a=o-t+1;if(d){let r=this.channels,o=this.toCanvas(),s=n(i,a).getContext("2d");return s.drawImage(o,e,t,i,a,0,0,i,a),new _(s.getImageData(0,0,i,a).data,i,a,4).convert(r)}{let r=this.toSharp().extract({left:e,top:t,width:i,height:a});return await s(r)}}async center_crop(e,t){if(this.width===e&&this.height===t)return this;let r=(this.width-e)/2,o=(this.height-t)/2;if(d){let s=this.channels,i=this.toCanvas(),a=n(e,t).getContext("2d"),l=0,c=0,u=0,d=0;return r>=0?l=r:u=-r,o>=0?c=o:d=-o,a.drawImage(i,l,c,e,t,u,d,e,t),new _(a.getImageData(0,0,e,t).data,e,t,4).convert(s)}{let n=this.toSharp();if(r>=0&&o>=0)n=n.extract({left:Math.floor(r),top:Math.floor(o),width:e,height:t});else if(r<=0&&o<=0){let s=Math.floor(-o),i=Math.floor(-r);n=n.extend({top:s,left:i,right:e-this.width-i,bottom:t-this.height-s})}else{let s=[0,0],i=0;o<0?(s[0]=Math.floor(-o),s[1]=t-this.height-s[0]):i=Math.floor(o);let a=[0,0],l=0;r<0?(a[0]=Math.floor(-r),a[1]=e-this.width-a[0]):l=Math.floor(r),n=n.extend({top:s[0],bottom:s[1],left:a[0],right:a[1]}).extract({left:l,top:i,width:e,height:t})}return await s(n)}}async toBlob(e="image/png",t=1){if(!d)throw Error("toBlob() is only supported in browser environments.");let r=this.toCanvas();return await r.convertToBlob({type:e,quality:t})}toTensor(e="CHW"){let t=new c.Tensor("uint8",new Uint8Array(this.data),[this.height,this.width,this.channels]);if("HWC"===e);else if("CHW"===e)t=t.permute(2,0,1);else throw Error(`Unsupported channel format: ${e}`);return t}toCanvas(){if(!d)throw Error("toCanvas() is only supported in browser environments.");let e=this.clone().rgba(),t=n(e.width,e.height),r=new o(e.data,e.width,e.height);return t.getContext("2d").putImageData(r,0,0),t}split(){let{data:e,width:t,height:r,channels:n}=this,o=e.constructor,s=e.length/n,i=Array.from({length:n},()=>new o(s));for(let t=0;t<s;++t){let r=n*t;for(let o=0;o<n;++o)i[o][t]=e[r+o]}return i.map(e=>new _(e,t,r,1))}_update(e,t,r,n=null){return this.data=e,this.width=t,this.height=r,null!==n&&(this.channels=n),this}clone(){return new _(this.data.slice(),this.width,this.height,this.channels)}convert(e){if(this.channels===e)return this;switch(e){case 1:this.grayscale();break;case 3:this.rgb();break;case 4:this.rgba();break;default:throw Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this}async save(e){if(d){if(l.apis.IS_WEBWORKER_ENV)throw Error("Unable to save an image from a Web Worker.");let t=e.split(".").pop().toLowerCase(),r=p.get(t)??"image/png",n=await this.toBlob(r);(0,i.saveBlob)(e,n)}else if(l.apis.IS_FS_AVAILABLE){let t=this.toSharp();return await t.toFile(e)}else throw Error("Unable to save the image because filesystem is disabled in this environment.")}toSharp(){if(d)throw Error("toSharp() is only supported in server-side environments.");return u(this.data,{raw:{width:this.width,height:this.height,channels:this.channels}})}}let h=_.read.bind(_)},"./src/utils/maths.js":/*!****************************!*\
  !*** ./src/utils/maths.js ***!
  \****************************/(e,t,r)=>{function n(e,[t,r,n],[o,s],i="bilinear",a=!1){let l=s/n,c=o/r,u=new e.constructor(o*s*t),d=r*n,m=o*s;for(let i=0;i<o;++i)for(let o=0;o<s;++o){let a=i*s+o,p=(o+.5)/l-.5,_=(i+.5)/c-.5,h=Math.floor(p),f=Math.floor(_),g=Math.min(h+1,n-1),M=Math.min(f+1,r-1),w=p-(h=Math.max(h,0)),T=_-(f=Math.max(f,0)),x=(1-w)*(1-T),P=w*(1-T),b=(1-w)*T,F=w*T,k=f*n,y=M*n,v=k+h,C=k+g,S=y+h,E=y+g;for(let r=0;r<t;++r){let t=r*d;u[r*m+a]=x*e[t+v]+P*e[t+C]+b*e[t+S]+F*e[t+E]}}return u}function o(e,t,r){let n=Array(r.length),o=Array(r.length);for(let e=r.length-1,s=1;e>=0;--e)o[e]=s,n[e]=t[r[e]],s*=n[e];let s=r.map((e,t)=>o[r.indexOf(t)]),i=new e.constructor(e.length);for(let r=0;r<e.length;++r){let n=0;for(let e=t.length-1,o=r;e>=0;--e)n+=o%t[e]*s[e],o=Math.floor(o/t[e]);i[n]=e[r]}return[i,n]}function s(e){let t=d(e)[0],r=e.map(e=>Math.exp(e-t)),n=r.reduce((e,t)=>e+t,0);return r.map(e=>e/n)}function i(e){let t=d(e)[0],r=0;for(let n=0;n<e.length;++n)r+=Math.exp(e[n]-t);let n=Math.log(r);return e.map(e=>e-t-n)}function a(e,t){let r=0;for(let n=0;n<e.length;++n)r+=e[n]*t[n];return r}function l(e,t){let r=a(e,t);return r/(c(e)*c(t))}function c(e){return Math.sqrt(e.reduce((e,t)=>e+t*t,0))}function u(e){if(0===e.length)throw Error("Array must not be empty");let t=e[0],r=0;for(let n=1;n<e.length;++n)e[n]<t&&(t=e[n],r=n);return[t,r]}function d(e){if(0===e.length)throw Error("Array must not be empty");let t=e[0],r=0;for(let n=1;n<e.length;++n)e[n]>t&&(t=e[n],r=n);return[t,r]}function m(e){return e>0&&(e&e-1)==0}r.r(t),r.d(t,{FFT:()=>h,bankers_round:()=>M,cos_sim:()=>l,dot:()=>a,dynamic_time_warping:()=>w,interpolate_data:()=>n,log_softmax:()=>i,magnitude:()=>c,max:()=>d,medianFilter:()=>f,min:()=>u,permute_data:()=>o,round:()=>g,softmax:()=>s});class p{constructor(e){if(this.size=0|e,this.size<=1||!m(this.size))throw Error("FFT size must be a power of two larger than 1");this._csize=e<<1,this.table=new Float64Array(2*this.size);for(let e=0;e<this.table.length;e+=2){let t=Math.PI*e/this.size;this.table[e]=Math.cos(t),this.table[e+1]=-Math.sin(t)}let t=0;for(let e=1;this.size>e;e<<=1)++t;this._width=t%2==0?t-1:t,this._bitrev=new Int32Array(1<<this._width);for(let e=0;e<this._bitrev.length;++e){this._bitrev[e]=0;for(let t=0;t<this._width;t+=2){let r=this._width-t-2;this._bitrev[e]|=(e>>>t&3)<<r}}}createComplexArray(){return new Float64Array(this._csize)}fromComplexArray(e,t){let r=t||Array(e.length>>>1);for(let t=0;t<e.length;t+=2)r[t>>>1]=e[t];return r}toComplexArray(e,t){let r=t||this.createComplexArray();for(let t=0;t<r.length;t+=2)r[t]=e[t>>>1],r[t+1]=0;return r}transform(e,t){if(e===t)throw Error("Input and output buffers must be different");this._transform4(e,t,1)}realTransform(e,t){if(e===t)throw Error("Input and output buffers must be different");this._realTransform4(e,t,1)}inverseTransform(e,t){if(e===t)throw Error("Input and output buffers must be different");this._transform4(e,t,-1);for(let t=0;t<e.length;++t)e[t]/=this.size}_transform4(e,t,r){let n,o;let s=this._csize,i=1<<this._width,a=s/i<<1,l=this._bitrev;if(4===a)for(n=0,o=0;n<s;n+=a,++o){let r=l[o];this._singleTransform2(t,e,n,r,i)}else for(n=0,o=0;n<s;n+=a,++o){let s=l[o];this._singleTransform4(t,e,n,s,i,r)}let c=this.table;for(i>>=2;i>=2;i>>=2){let t=(a=s/i<<1)>>>2;for(n=0;n<s;n+=a){let o=n+t-1;for(let s=n,a=0;s<o;s+=2,a+=i){let n=s,o=n+t,i=o+t,l=i+t,u=e[n],d=e[n+1],m=e[o],p=e[o+1],_=e[i],h=e[i+1],f=e[l],g=e[l+1],M=c[a],w=r*c[a+1],T=m*M-p*w,x=m*w+p*M,P=c[2*a],b=r*c[2*a+1],F=_*P-h*b,k=_*b+h*P,y=c[3*a],v=r*c[3*a+1],C=f*y-g*v,S=f*v+g*y,E=u+F,A=d+k,L=u-F,I=d-k,D=T+C,z=x+S,j=r*(T-C),V=r*(x-S);e[n]=E+D,e[n+1]=A+z,e[o]=L+V,e[o+1]=I-j,e[i]=E-D,e[i+1]=A-z,e[l]=L-V,e[l+1]=I+j}}}}_singleTransform2(e,t,r,n,o){let s=e[n],i=e[n+1],a=e[n+o],l=e[n+o+1];t[r]=s+a,t[r+1]=i+l,t[r+2]=s-a,t[r+3]=i-l}_singleTransform4(e,t,r,n,o,s){let i=2*o,a=3*o,l=e[n],c=e[n+1],u=e[n+o],d=e[n+o+1],m=e[n+i],p=e[n+i+1],_=e[n+a],h=e[n+a+1],f=l+m,g=c+p,M=l-m,w=c-p,T=u+_,x=d+h,P=s*(u-_),b=s*(d-h);t[r]=f+T,t[r+1]=g+x,t[r+2]=M+b,t[r+3]=w-P,t[r+4]=f-T,t[r+5]=g-x,t[r+6]=M-b,t[r+7]=w+P}_realTransform4(e,t,r){let n,o;let s=this._csize,i=1<<this._width,a=s/i<<1,l=this._bitrev;if(4===a)for(n=0,o=0;n<s;n+=a,++o){let r=l[o];this._singleRealTransform2(t,e,n,r>>>1,i>>>1)}else for(n=0,o=0;n<s;n+=a,++o){let s=l[o];this._singleRealTransform4(t,e,n,s>>>1,i>>>1,r)}let c=this.table;for(i>>=2;i>=2;i>>=2){let t=(a=s/i<<1)>>>1,o=t>>>1,l=o>>>1;for(n=0;n<s;n+=a)for(let s=0,a=0;s<=l;s+=2,a+=i){let i=n+s,u=i+o,d=u+o,m=d+o,p=e[i],_=e[i+1],h=e[u],f=e[u+1],g=e[d],M=e[d+1],w=e[m],T=e[m+1],x=c[a],P=r*c[a+1],b=h*x-f*P,F=h*P+f*x,k=c[2*a],y=r*c[2*a+1],v=g*k-M*y,C=g*y+M*k,S=c[3*a],E=r*c[3*a+1],A=w*S-T*E,L=w*E+T*S,I=p+v,D=_+C,z=p-v,j=_-C,V=b+A,O=F+L,N=r*(b-A),B=r*(F-L);if(e[i]=I+V,e[i+1]=D+O,e[u]=z+B,e[u+1]=j-N,0===s){e[d]=I-V,e[d+1]=D-O;continue}if(s===l)continue;let G=n+o-s,R=n+t-s;e[G]=z-r*B,e[G+1]=-j-r*N,e[R]=I-r*V,e[R+1]=-D+r*O}}let u=s>>>1;for(let t=2;t<u;t+=2)e[s-t]=e[t],e[s-t+1]=-e[t+1]}_singleRealTransform2(e,t,r,n,o){let s=e[n],i=e[n+o];t[r]=s+i,t[r+1]=0,t[r+2]=s-i,t[r+3]=0}_singleRealTransform4(e,t,r,n,o,s){let i=e[n],a=e[n+o],l=e[n+2*o],c=e[n+3*o],u=i+l,d=i-l,m=a+c,p=s*(a-c);t[r]=u+m,t[r+1]=0,t[r+2]=d,t[r+3]=-p,t[r+4]=u-m,t[r+5]=0,t[r+6]=d,t[r+7]=p}}class _{constructor(e){let t=2*(e-1),r=2*(2*e-1),n=2**Math.ceil(Math.log2(r));this.bufferSize=n,this._a=t;let o=new Float64Array(r),s=new Float64Array(n);this._chirpBuffer=new Float64Array(n),this._buffer1=new Float64Array(n),this._buffer2=new Float64Array(n),this._outBuffer1=new Float64Array(n),this._outBuffer2=new Float64Array(n);let i=-2*Math.PI/e,a=Math.cos(i),l=Math.sin(i);for(let t=0;t<r>>1;++t){let r=(t+1-e)**2/2,n=Math.sqrt(a**2+l**2)**r,i=r*Math.atan2(l,a),c=2*t;o[c]=n*Math.cos(i),o[c+1]=n*Math.sin(i),s[c]=o[c],s[c+1]=-o[c+1]}this._slicedChirpBuffer=o.subarray(t,r),this._f=new p(n>>1),this._f.transform(this._chirpBuffer,s)}_transform(e,t,r){let n=this._buffer1,o=this._buffer2,s=this._outBuffer1,i=this._outBuffer2,a=this._chirpBuffer,l=this._slicedChirpBuffer,c=this._a;if(r)for(let e=0;e<l.length;e+=2){let r=e+1,o=t[e>>1];n[e]=o*l[e],n[r]=o*l[r]}else for(let e=0;e<l.length;e+=2){let r=e+1;n[e]=t[e]*l[e]-t[r]*l[r],n[r]=t[e]*l[r]+t[r]*l[e]}this._f.transform(s,n);for(let e=0;e<a.length;e+=2){let t=e+1;o[e]=s[e]*a[e]-s[t]*a[t],o[t]=s[e]*a[t]+s[t]*a[e]}this._f.inverseTransform(i,o);for(let t=0;t<i.length;t+=2){let r=i[t+c],n=i[t+c+1],o=l[t],s=l[t+1];e[t]=r*o-n*s,e[t+1]=r*s+n*o}}transform(e,t){this._transform(e,t,!1)}realTransform(e,t){this._transform(e,t,!0)}}class h{constructor(e){this.fft_length=e,this.isPowerOfTwo=m(e),this.isPowerOfTwo?(this.fft=new p(e),this.outputBufferSize=2*e):(this.fft=new _(e),this.outputBufferSize=this.fft.bufferSize)}realTransform(e,t){this.fft.realTransform(e,t)}transform(e,t){this.fft.transform(e,t)}}function f(e,t){if(t%2==0||t<=0)throw Error("Window size must be a positive odd number");let r=new e.constructor(e.length),n=new e.constructor(t),o=Math.floor(t/2);for(let t=0;t<e.length;++t){let s=0;for(let r=-o;r<=o;++r){let o=t+r;o<0?o=Math.abs(o):o>=e.length&&(o=2*(e.length-1)-o),n[s++]=e[o]}n.sort(),r[t]=n[o]}return r}function g(e,t){let r=Math.pow(10,t);return Math.round(e*r)/r}function M(e){let t=Math.round(e);return Math.abs(e)%1==.5?t%2==0?t:t-1:t}function w(e){let t=e.length,r=e[0].length,n=[t+1,r+1],o=Array.from({length:n[0]},()=>Array(n[1]).fill(1/0));o[0][0]=0;let s=Array.from({length:n[0]},()=>Array(n[1]).fill(-1));for(let t=1;t<n[1];++t)for(let r=1;r<n[0];++r){let n,i;let a=o[r-1][t-1],l=o[r-1][t],c=o[r][t-1];a<l&&a<c?(n=a,i=0):l<a&&l<c?(n=l,i=1):(n=c,i=2),o[r][t]=e[r-1][t-1]+n,s[r][t]=i}for(let e=0;e<n[1];++e)s[0][e]=2;for(let e=0;e<n[0];++e)s[e][0]=1;let i=t,a=r,l=[],c=[];for(;i>0||a>0;)switch(l.push(i-1),c.push(a-1),s[i][a]){case 0:--i,--a;break;case 1:--i;break;case 2:--a;break;default:throw Error(`Internal error in dynamic time warping. Unexpected trace[${i}, ${a}]. Please file a bug report.`)}return l.reverse(),c.reverse(),[l,c]}},"./src/utils/tensor.js":/*!*****************************!*\
  !*** ./src/utils/tensor.js ***!
  \*****************************/(e,t,r)=>{r.r(t),r.d(t,{DataTypeMap:()=>i,Tensor:()=>a,cat:()=>x,full:()=>v,full_like:()=>C,interpolate:()=>c,interpolate_4d:()=>u,layer_norm:()=>g,matmul:()=>d,mean:()=>k,mean_pooling:()=>f,ones:()=>S,ones_like:()=>E,permute:()=>l,quantize_embeddings:()=>D,rand:()=>I,rfft:()=>m,slice:()=>h,stack:()=>P,std_mean:()=>F,topk:()=>p,zeros:()=>A,zeros_like:()=>L});var n=r(/*! ./maths.js */"./src/utils/maths.js"),o=r(/*! ../backends/onnx.js */"./src/backends/onnx.js"),s=r(/*! ../ops/registry.js */"./src/ops/registry.js");let i=Object.freeze({float32:Float32Array,float16:"undefined"!=typeof Float16Array?Float16Array:Uint16Array,float64:Float64Array,string:Array,int8:Int8Array,uint8:Uint8Array,int16:Int16Array,uint16:Uint16Array,int32:Int32Array,uint32:Uint32Array,int64:BigInt64Array,uint64:BigUint64Array,bool:Uint8Array,uint4:Uint8Array,int4:Int8Array});class a{get dims(){return this.ort_tensor.dims}set dims(e){this.ort_tensor.dims=e}get type(){return this.ort_tensor.type}get data(){return this.ort_tensor.data}get size(){return this.ort_tensor.size}get location(){return this.ort_tensor.location}ort_tensor;constructor(...e){return(0,o.isONNXTensor)(e[0])?this.ort_tensor=e[0]:this.ort_tensor=new o.Tensor(e[0],e[1],e[2]),new Proxy(this,{get:(e,t)=>{if("string"==typeof t){let r=Number(t);if(Number.isInteger(r))return e._getitem(r)}return e[t]},set:(e,t,r)=>e[t]=r})}dispose(){this.ort_tensor.dispose()}*[Symbol.iterator](){let[e,...t]=this.dims;if(t.length>0){let r=t.reduce((e,t)=>e*t);for(let n=0;n<e;++n)yield this._subarray(n,r,t)}else yield*this.data}_getitem(e){let[t,...r]=this.dims;if(e=T(e,t),!(r.length>0))return new a(this.type,[this.data[e]],r);{let t=r.reduce((e,t)=>e*t);return this._subarray(e,t,r)}}indexOf(e){let t=this.data;for(let r=0;r<t.length;++r)if(t[r]==e)return r;return -1}_subarray(e,t,r){let n=e*t,o=(e+1)*t,s="subarray"in this.data?this.data.subarray(n,o):this.data.slice(n,o);return new a(this.type,s,r)}item(){let e=this.data;if(1!==e.length)throw Error(`a Tensor with ${e.length} elements cannot be converted to Scalar`);return e[0]}tolist(){return function(e,t){let r=e.length;if(r!==t.reduce((e,t)=>e*t))throw Error(`cannot reshape array of size ${r} into shape (${t})`);let n=e;for(let e=t.length-1;e>=0;e--)n=n.reduce((r,n)=>{let o=r[r.length-1];return o.length<t[e]?o.push(n):r.push([n]),r},[[]]);return n[0]}(this.data,this.dims)}sigmoid(){return this.clone().sigmoid_()}sigmoid_(){let e=this.data;for(let t=0;t<e.length;++t)e[t]=1/(1+Math.exp(-e[t]));return this}map(e){return this.clone().map_(e)}map_(e){let t=this.data;for(let r=0;r<t.length;++r)t[r]=e(t[r],r,t);return this}mul(e){return this.clone().mul_(e)}mul_(e){let t=this.data;for(let r=0;r<t.length;++r)t[r]*=e;return this}div(e){return this.clone().div_(e)}div_(e){let t=this.data;for(let r=0;r<t.length;++r)t[r]/=e;return this}add(e){return this.clone().add_(e)}add_(e){let t=this.data;for(let r=0;r<t.length;++r)t[r]+=e;return this}sub(e){return this.clone().sub_(e)}sub_(e){let t=this.data;for(let r=0;r<t.length;++r)t[r]-=e;return this}clone(){return new a(this.type,this.data.slice(),this.dims.slice())}slice(...e){let t=[],r=[];for(let n=0;n<this.dims.length;++n){let o=e[n];if(null==o)r.push([0,this.dims[n]]),t.push(this.dims[n]);else if("number"==typeof o)o=T(o,this.dims[n],n),r.push([o,o+1]);else if(Array.isArray(o)&&2===o.length){let[e,s]=o;if((e=null===e?0:T(e,this.dims[n],n,!1))>(s=null===s?this.dims[n]:T(s,this.dims[n],n,!1)))throw Error(`Invalid slice: ${o}`);let i=[Math.max(e,0),Math.min(s,this.dims[n])];r.push(i),t.push(i[1]-i[0])}else throw Error(`Invalid slice: ${o}`)}let n=r.map(([e,t])=>t-e),o=n.reduce((e,t)=>e*t),s=this.data,i=new s.constructor(o),l=this.stride(),c=!0;for(let e=1;e<n.length;++e)if(0!==r[e][0]||r[e][1]!==this.dims[e]){c=!1;break}if(c){let e=r[0][0]*l[0],t=r[0][1]*l[0];if(ArrayBuffer.isView(s))i.set(s.subarray(e,t));else if(Array.isArray(s)){let r=s.slice(e,t);for(let e=0;e<r.length;++e)i[e]=r[e]}else throw Error("Unsupported data type for slicing")}else for(let e=0;e<o;++e){let t=0;for(let o=n.length-1,s=e;o>=0;--o){let e=n[o];t+=(s%e+r[o][0])*l[o],s=Math.floor(s/e)}i[e]=s[t]}return new a(this.type,i,t)}permute(...e){return l(this,e)}transpose(...e){return this.permute(...e)}sum(e=null,t=!1){return this.norm(1,e,t)}norm(e="fro",t=null,r=!1){if("fro"===e)e=2;else if("string"==typeof e)throw Error(`Unsupported norm: ${e}`);let n=this.data,o=(t,r)=>t+r**e;if(null===t){let t=n.reduce(o,0)**(1/e);return new a(this.type,[t],[])}let[s,i,l]=b(o,this,t,r);if(1!==e)for(let t=0;t<i.length;++t)i[t]=i[t]**(1/e);return new a(s,i,l)}normalize_(e=2,t=1){t=T(t,this.dims.length);let r=this.norm(e,t,!0),n=this.data,o=r.data;for(let e=0;e<n.length;++e){let r=0;for(let n=this.dims.length-1,o=e,s=1;n>=0;--n){let e=this.dims[n];n!==t&&(r+=o%e*s,s*=this.dims[n]),o=Math.floor(o/e)}n[e]/=o[r]}return this}normalize(e=2,t=1){return this.clone().normalize_(e,t)}stride(){return function(e){let t=Array(e.length);for(let r=e.length-1,n=1;r>=0;--r)t[r]=n,n*=e[r];return t}(this.dims)}squeeze(e=null){return new a(this.type,this.data,M(this.dims,e))}squeeze_(e=null){return this.dims=M(this.dims,e),this}unsqueeze(e=null){return new a(this.type,this.data,w(this.dims,e))}unsqueeze_(e=null){return this.dims=w(this.dims,e),this}flatten_(e=0,t=-1){t=(t+this.dims.length)%this.dims.length;let r=this.dims.slice(0,e),n=this.dims.slice(e,t+1),o=this.dims.slice(t+1);return this.dims=[...r,n.reduce((e,t)=>e*t,1),...o],this}flatten(e=0,t=-1){return this.clone().flatten_(e,t)}view(...e){let t=-1;for(let r=0;r<e.length;++r)if(-1===e[r]){if(-1!==t)throw Error("Only one dimension can be inferred");t=r}let r=this.data;if(-1!==t){let n=e.reduce((e,r,n)=>n!==t?e*r:e,1);e[t]=r.length/n}return new a(this.type,r,e)}neg_(){let e=this.data;for(let t=0;t<e.length;++t)e[t]=-e[t];return this}neg(){return this.clone().neg_()}gt(e){let t=new Uint8Array(this.data.length),r=this.data;for(let n=0;n<r.length;++n)t[n]=r[n]>e?1:0;return new a("bool",t,this.dims)}lt(e){let t=new Uint8Array(this.data.length),r=this.data;for(let n=0;n<r.length;++n)t[n]=r[n]<e?1:0;return new a("bool",t,this.dims)}clamp_(e,t){let r=this.data;for(let n=0;n<r.length;++n)r[n]=Math.min(Math.max(r[n],e),t);return this}clamp(e,t){return this.clone().clamp_(e,t)}round_(){let e=this.data;for(let t=0;t<e.length;++t)e[t]=Math.round(e[t]);return this}round(){return this.clone().round_()}mean(e=null,t=!1){return k(this,e,t)}min(e=null,t=!1){if(null===e){let e=(0,n.min)(this.data)[0];return new a(this.type,[e],[])}let[r,o,s]=b((e,t)=>Math.min(e,t),this,e,t,1/0);return new a(r,o,s)}max(e=null,t=!1){if(null===e){let e=(0,n.max)(this.data)[0];return new a(this.type,[e],[])}let[r,o,s]=b((e,t)=>Math.max(e,t),this,e,t,-1/0);return new a(r,o,s)}argmin(e=null,t=!1){if(null!==e)throw Error("`dim !== null` not yet implemented.");return new a("int64",[BigInt((0,n.min)(this.data)[1])],[])}argmax(e=null,t=!1){if(null!==e)throw Error("`dim !== null` not yet implemented.");return new a("int64",[BigInt((0,n.max)(this.data)[1])],[])}to(e){let t;if(this.type===e)return this;if(!i.hasOwnProperty(e))throw Error(`Unsupported type: ${e}`);let r=["int64","uint64"].includes(this.type),n=["int64","uint64"].includes(e);return r&&!n?t=Number:!r&&n&&(t=BigInt),new a(e,i[e].from(this.data,t),this.dims)}}function l(e,t){let[r,o]=(0,n.permute_data)(e.data,e.dims,t);return new a(e.type,r,o)}function c(e,[t,r],o="bilinear",s=!1){let i=e.dims.at(-3)??1,l=e.dims.at(-2),c=e.dims.at(-1),u=(0,n.interpolate_data)(e.data,[i,l,c],[t,r],o,s);return new a(e.type,u,[i,t,r])}async function u(e,{size:t=null,mode:r="bilinear"}={}){let n,o;if(4!==e.dims.length)throw Error("`interpolate_4d` currently only supports 4D input.");if(!t)throw Error("`interpolate_4d` requires a `size` argument.");if(2===t.length)n=[...e.dims.slice(0,2),...t];else if(3===t.length)n=[e.dims[0],...t];else if(4===t.length)n=t;else throw Error("`size` must be of length 2, 3, or 4.");if("nearest"===r)o=await s.TensorOpRegistry.nearest_interpolate_4d;else if("bilinear"===r)o=await s.TensorOpRegistry.bilinear_interpolate_4d;else if("bicubic"===r)o=await s.TensorOpRegistry.bicubic_interpolate_4d;else throw Error(`Unsupported mode: ${r}`);let i=new a("int64",new BigInt64Array(n.map(BigInt)),[n.length]);return await o({x:e,s:i})}async function d(e,t){let r=await s.TensorOpRegistry.matmul;return await r({a:e,b:t})}async function m(e,t){let r=await s.TensorOpRegistry.rfft;return await r({x:e,a:t})}async function p(e,t){let r=await s.TensorOpRegistry.top_k;return t=null==t?e.dims.at(-1):Math.min(t,e.dims.at(-1)),await r({x:e,k:new a("int64",[BigInt(t)],[1])})}let _=e=>new a("int64",e,[e.length]);async function h(e,t,r,n,o){let i=await s.TensorOpRegistry.slice;return await i({x:e,s:_(t),e:_(r),a:_(n),t:_(o??Array(n.length).fill(1))})}function f(e,t){let r=e.data,n=t.data,o=[e.dims[0],e.dims[2]],s=new r.constructor(o[0]*o[1]),[i,l,c]=e.dims,u=0;for(let e=0;e<i;++e){let t=e*c*l;for(let o=0;o<c;++o){let i=0,a=0,d=e*l,m=t+o;for(let e=0;e<l;++e){let t=Number(n[d+e]);a+=t,i+=r[m+e*c]*t}let p=i/a;s[u++]=p}}return new a(e.type,s,o)}function g(e,t,{eps:r=1e-5}={}){if(2!==e.dims.length)throw Error("`layer_norm` currently only supports 2D input.");let[n,o]=e.dims;if(1!==t.length&&t[0]!==o)throw Error("`normalized_shape` must be a 1D array with shape `[input.dims[1]]`.");let[s,i]=F(e,1,0,!0),l=s.data,c=i.data,u=e.data,d=new u.constructor(u.length);for(let e=0;e<n;++e){let t=e*o;for(let n=0;n<o;++n){let o=t+n;d[o]=(u[o]-c[e])/(l[e]+r)}}return new a(e.type,d,e.dims)}function M(e,t){return e=e.slice(),null===t?e=e.filter(e=>1!==e):"number"==typeof t?1===e[t]&&e.splice(t,1):Array.isArray(t)&&(e=e.filter((e,r)=>1!==e||!t.includes(r))),e}function w(e,t){return t=T(t,e.length+1),(e=e.slice()).splice(t,0,1),e}function T(e,t,r=null,n=!0){if(e<-t||e>=t){if(!n)return e<-t?0:t;throw Error(`IndexError: index ${e} is out of bounds for dimension${null===r?"":" "+r} with size ${t}`)}return e<0&&(e=(e%t+t)%t),e}function x(e,t=0){t=T(t,e[0].dims.length);let r=e[0].dims.slice();r[t]=e.reduce((e,r)=>e+r.dims[t],0);let n=r.reduce((e,t)=>e*t,1),o=new e[0].data.constructor(n),s=e[0].type;if(0===t){let t=0;for(let r of e){let e=r.data;o.set(e,t),t+=e.length}}else{let n=0;for(let s=0;s<e.length;++s){let{data:i,dims:a}=e[s];for(let e=0;e<i.length;++e){let s=0;for(let o=a.length-1,i=e,l=1;o>=0;--o){let e=a[o],c=i%e;o===t&&(c+=n),s+=c*l,l*=r[o],i=Math.floor(i/e)}o[s]=i[e]}n+=a[t]}}return new a(s,o,r)}function P(e,t=0){return x(e.map(e=>e.unsqueeze(t)),t)}function b(e,t,r=null,n=!1,o=null){let s=t.data,i=t.dims;r=T(r,i.length);let a=i.slice();a[r]=1;let l=new s.constructor(s.length/i[r]);null!==o&&l.fill(o);for(let t=0;t<s.length;++t){let n=0;for(let e=i.length-1,o=t,s=1;e>=0;--e){let t=i[e];e!==r&&(n+=o%t*s,s*=a[e]),o=Math.floor(o/t)}l[n]=e(l[n],s[t],t,n)}return n||a.splice(r,1),[t.type,l,a]}function F(e,t=null,r=1,n=!1){let o=e.data,s=e.dims;if(null===t){let t=o.reduce((e,t)=>e+t,0)/o.length,n=Math.sqrt(o.reduce((e,r)=>e+(r-t)**2,0)/(o.length-r)),s=new a(e.type,[t],[]);return[new a(e.type,[n],[]),s]}let i=k(e,t=T(t,s.length),n),l=i.data,[c,u,d]=b((e,t,r,n)=>e+(t-l[n])**2,e,t,n);for(let e=0;e<u.length;++e)u[e]=Math.sqrt(u[e]/(s[t]-r));return[new a(c,u,d),i]}function k(e,t=null,r=!1){let n=e.dims,o=e.data;if(null===t){let t=o.reduce((e,t)=>e+t,0);return new a(e.type,[t/o.length],[])}let[s,i,l]=b((e,t)=>e+t,e,t=T(t,n.length),r);if(1!==n[t])for(let e=0;e<i.length;++e)i[e]/=n[t];return new a(s,i,l)}function y(e,t,r,n){return new a(r,new n(e.reduce((e,t)=>e*t,1)).fill(t),e)}function v(e,t){let r,n;if("number"==typeof t)r="float32",n=Float32Array;else if("bigint"==typeof t)r="int64",n=BigInt64Array;else if("boolean"==typeof t)r="bool",n=Uint8Array;else throw Error(`Unsupported data type: ${typeof t}`);return y(e,t,r,n)}function C(e,t){return v(e.dims,t)}function S(e){return y(e,1n,"int64",BigInt64Array)}function E(e){return S(e.dims)}function A(e){return y(e,0n,"int64",BigInt64Array)}function L(e){return A(e.dims)}function I(e){let t=e.reduce((e,t)=>e*t,1);return new a("float32",Float32Array.from({length:t},()=>Math.random()),e)}function D(e,t){if(2!==e.dims.length)throw Error("The tensor must have 2 dimensions");if(e.dims.at(-1)%8!=0)throw Error("The last dimension of the tensor must be a multiple of 8");if(!["binary","ubinary"].includes(t))throw Error("The precision must be either 'binary' or 'ubinary'");let r="binary"===t,n=r?Int8Array:Uint8Array,o=e.data,s=new n(o.length/8);for(let e=0;e<o.length;++e){let t=o[e]>0?1:0,n=Math.floor(e/8),i=e%8;s[n]|=t<<7-i,r&&0===i&&(s[n]-=128)}return new a(r?"int8":"uint8",s,[e.dims[0],e.dims[1]/8])}},"./src/utils/video.js":/*!****************************!*\
  !*** ./src/utils/video.js ***!
  \****************************/(e,t,r)=>{r.r(t),r.d(t,{RawVideo:()=>i,RawVideoFrame:()=>s,load_video:()=>a});var n=r(/*! ./image.js */"./src/utils/image.js"),o=r(/*! ../env.js */"./src/env.js");class s{constructor(e,t){this.image=e,this.timestamp=t}}class i{constructor(e,t){e.length>0&&e[0]instanceof n.RawImage&&(e=e.map((r,n)=>new s(r,(n+1)/(e.length+1)*t))),this.frames=e,this.duration=t}get width(){return this.frames[0].image.width}get height(){return this.frames[0].image.height}get fps(){return this.frames.length/this.duration}}async function a(e,{num_frames:t=null,fps:r=null}={}){let a,l;if(!o.apis.IS_BROWSER_ENV)throw Error("`load_video` is currently only supported in browser environments.");if(null==t&&null==r)throw Error("Either num_frames or fps must be provided.");let c=[],u=document.createElement("video");if(u.crossOrigin="anonymous",u.muted=!0,"string"==typeof e)u.src=e;else if(e instanceof Blob)u.src=URL.createObjectURL(e);else if(e instanceof HTMLVideoElement)u.src=e.src;else throw Error("Invalid URL or video element provided.");if(await new Promise(e=>u.onloadedmetadata=e),u.seekable.start(0)===u.seekable.end(0)){let e=await fetch(u.src),t=await e.blob();u.src=URL.createObjectURL(t),await new Promise(e=>u.onloadedmetadata=e)}let d=u.duration;null!=t?(a=t,l=1===t?0:d/(t-1)):a=Math.floor(d/(l=1/r));let m=[];for(let e=0;e<a;++e)m.push(1===t?d/2:e*l);let p=document.createElement("canvas");p.width=u.videoWidth,p.height=u.videoHeight;let _=p.getContext("2d",{willReadFrequently:!0});for(let e of m){u.currentTime=e,await new Promise(e=>{u.onseeked=e}),_.drawImage(u,0,0,p.width,p.height);let t=_.getImageData(0,0,p.width,p.height),r=new s(new n.RawImage(t.data,p.width,p.height,4),e);c.push(r)}return u.remove(),new i(c,d)}}},I={};function D(e){var t=I[e];if(void 0!==t)return t.exports;var r=I[e]={exports:{}};return L[e](r,r.exports,D),r.exports}o=Object.getPrototypeOf?e=>Object.getPrototypeOf(e):e=>e.__proto__,D.t=function(e,t){if(1&t&&(e=this(e)),8&t||"object"==typeof e&&e&&(4&t&&e.__esModule||16&t&&"function"==typeof e.then))return e;var r=Object.create(null);D.r(r);var s={};n=n||[null,o({}),o([]),o(o)];for(var i=2&t&&e;"object"==typeof i&&!~n.indexOf(i);i=o(i))Object.getOwnPropertyNames(i).forEach(t=>s[t]=()=>e[t]);return s.default=()=>e,D.d(r,s),r},D.d=(e,t)=>{for(var r in t)D.o(t,r)&&!D.o(e,r)&&Object.defineProperty(e,r,{enumerable:!0,get:t[r]})},D.o=(e,t)=>Object.prototype.hasOwnProperty.call(e,t),D.r=e=>{"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})};var z={};/*!*****************************!*\
  !*** ./src/transformers.js ***!
  \*****************************/D.r(z),D.d(z,{ASTFeatureExtractor:()=>f.ASTFeatureExtractor,ASTForAudioClassification:()=>a.ASTForAudioClassification,ASTModel:()=>a.ASTModel,ASTPreTrainedModel:()=>a.ASTPreTrainedModel,AlbertForMaskedLM:()=>a.AlbertForMaskedLM,AlbertForQuestionAnswering:()=>a.AlbertForQuestionAnswering,AlbertForSequenceClassification:()=>a.AlbertForSequenceClassification,AlbertModel:()=>a.AlbertModel,AlbertPreTrainedModel:()=>a.AlbertPreTrainedModel,AlbertTokenizer:()=>l.AlbertTokenizer,ArceeForCausalLM:()=>a.ArceeForCausalLM,ArceeModel:()=>a.ArceeModel,ArceePreTrainedModel:()=>a.ArceePreTrainedModel,AudioClassificationPipeline:()=>i.AudioClassificationPipeline,AutoConfig:()=>c.AutoConfig,AutoFeatureExtractor:()=>g.AutoFeatureExtractor,AutoImageProcessor:()=>T.AutoImageProcessor,AutoModel:()=>a.AutoModel,AutoModelForAudioClassification:()=>a.AutoModelForAudioClassification,AutoModelForAudioFrameClassification:()=>a.AutoModelForAudioFrameClassification,AutoModelForAudioTextToText:()=>a.AutoModelForAudioTextToText,AutoModelForCTC:()=>a.AutoModelForCTC,AutoModelForCausalLM:()=>a.AutoModelForCausalLM,AutoModelForDepthEstimation:()=>a.AutoModelForDepthEstimation,AutoModelForDocumentQuestionAnswering:()=>a.AutoModelForDocumentQuestionAnswering,AutoModelForImageClassification:()=>a.AutoModelForImageClassification,AutoModelForImageFeatureExtraction:()=>a.AutoModelForImageFeatureExtraction,AutoModelForImageMatting:()=>a.AutoModelForImageMatting,AutoModelForImageSegmentation:()=>a.AutoModelForImageSegmentation,AutoModelForImageTextToText:()=>a.AutoModelForImageTextToText,AutoModelForImageToImage:()=>a.AutoModelForImageToImage,AutoModelForMaskGeneration:()=>a.AutoModelForMaskGeneration,AutoModelForMaskedLM:()=>a.AutoModelForMaskedLM,AutoModelForNormalEstimation:()=>a.AutoModelForNormalEstimation,AutoModelForObjectDetection:()=>a.AutoModelForObjectDetection,AutoModelForPoseEstimation:()=>a.AutoModelForPoseEstimation,AutoModelForQuestionAnswering:()=>a.AutoModelForQuestionAnswering,AutoModelForSemanticSegmentation:()=>a.AutoModelForSemanticSegmentation,AutoModelForSeq2SeqLM:()=>a.AutoModelForSeq2SeqLM,AutoModelForSequenceClassification:()=>a.AutoModelForSequenceClassification,AutoModelForSpeechSeq2Seq:()=>a.AutoModelForSpeechSeq2Seq,AutoModelForTextToSpectrogram:()=>a.AutoModelForTextToSpectrogram,AutoModelForTextToWaveform:()=>a.AutoModelForTextToWaveform,AutoModelForTokenClassification:()=>a.AutoModelForTokenClassification,AutoModelForUniversalSegmentation:()=>a.AutoModelForUniversalSegmentation,AutoModelForVision2Seq:()=>a.AutoModelForVision2Seq,AutoModelForXVector:()=>a.AutoModelForXVector,AutoModelForZeroShotObjectDetection:()=>a.AutoModelForZeroShotObjectDetection,AutoProcessor:()=>b.AutoProcessor,AutoTokenizer:()=>l.AutoTokenizer,AutomaticSpeechRecognitionPipeline:()=>i.AutomaticSpeechRecognitionPipeline,BackgroundRemovalPipeline:()=>i.BackgroundRemovalPipeline,BartForConditionalGeneration:()=>a.BartForConditionalGeneration,BartForSequenceClassification:()=>a.BartForSequenceClassification,BartModel:()=>a.BartModel,BartPretrainedModel:()=>a.BartPretrainedModel,BartTokenizer:()=>l.BartTokenizer,BaseModelOutput:()=>a.BaseModelOutput,BaseStreamer:()=>F.BaseStreamer,BeitFeatureExtractor:()=>w.BeitFeatureExtractor,BeitForImageClassification:()=>a.BeitForImageClassification,BeitModel:()=>a.BeitModel,BeitPreTrainedModel:()=>a.BeitPreTrainedModel,BertForMaskedLM:()=>a.BertForMaskedLM,BertForQuestionAnswering:()=>a.BertForQuestionAnswering,BertForSequenceClassification:()=>a.BertForSequenceClassification,BertForTokenClassification:()=>a.BertForTokenClassification,BertModel:()=>a.BertModel,BertPreTrainedModel:()=>a.BertPreTrainedModel,BertTokenizer:()=>l.BertTokenizer,BitImageProcessor:()=>w.BitImageProcessor,BlenderbotForConditionalGeneration:()=>a.BlenderbotForConditionalGeneration,BlenderbotModel:()=>a.BlenderbotModel,BlenderbotPreTrainedModel:()=>a.BlenderbotPreTrainedModel,BlenderbotSmallForConditionalGeneration:()=>a.BlenderbotSmallForConditionalGeneration,BlenderbotSmallModel:()=>a.BlenderbotSmallModel,BlenderbotSmallPreTrainedModel:()=>a.BlenderbotSmallPreTrainedModel,BlenderbotSmallTokenizer:()=>l.BlenderbotSmallTokenizer,BlenderbotTokenizer:()=>l.BlenderbotTokenizer,BloomForCausalLM:()=>a.BloomForCausalLM,BloomModel:()=>a.BloomModel,BloomPreTrainedModel:()=>a.BloomPreTrainedModel,BloomTokenizer:()=>l.BloomTokenizer,CLIPFeatureExtractor:()=>w.CLIPFeatureExtractor,CLIPImageProcessor:()=>w.CLIPImageProcessor,CLIPModel:()=>a.CLIPModel,CLIPPreTrainedModel:()=>a.CLIPPreTrainedModel,CLIPSegForImageSegmentation:()=>a.CLIPSegForImageSegmentation,CLIPSegModel:()=>a.CLIPSegModel,CLIPSegPreTrainedModel:()=>a.CLIPSegPreTrainedModel,CLIPTextModel:()=>a.CLIPTextModel,CLIPTextModelWithProjection:()=>a.CLIPTextModelWithProjection,CLIPTokenizer:()=>l.CLIPTokenizer,CLIPVisionModel:()=>a.CLIPVisionModel,CLIPVisionModelWithProjection:()=>a.CLIPVisionModelWithProjection,CamembertForMaskedLM:()=>a.CamembertForMaskedLM,CamembertForQuestionAnswering:()=>a.CamembertForQuestionAnswering,CamembertForSequenceClassification:()=>a.CamembertForSequenceClassification,CamembertForTokenClassification:()=>a.CamembertForTokenClassification,CamembertModel:()=>a.CamembertModel,CamembertPreTrainedModel:()=>a.CamembertPreTrainedModel,CamembertTokenizer:()=>l.CamembertTokenizer,CausalLMOutput:()=>a.CausalLMOutput,CausalLMOutputWithPast:()=>a.CausalLMOutputWithPast,ChineseCLIPFeatureExtractor:()=>w.ChineseCLIPFeatureExtractor,ChineseCLIPModel:()=>a.ChineseCLIPModel,ChineseCLIPPreTrainedModel:()=>a.ChineseCLIPPreTrainedModel,ClapAudioModelWithProjection:()=>a.ClapAudioModelWithProjection,ClapFeatureExtractor:()=>f.ClapFeatureExtractor,ClapModel:()=>a.ClapModel,ClapPreTrainedModel:()=>a.ClapPreTrainedModel,ClapTextModelWithProjection:()=>a.ClapTextModelWithProjection,ClassifierFreeGuidanceLogitsProcessor:()=>y.ClassifierFreeGuidanceLogitsProcessor,CodeGenForCausalLM:()=>a.CodeGenForCausalLM,CodeGenModel:()=>a.CodeGenModel,CodeGenPreTrainedModel:()=>a.CodeGenPreTrainedModel,CodeGenTokenizer:()=>l.CodeGenTokenizer,CodeLlamaTokenizer:()=>l.CodeLlamaTokenizer,CohereForCausalLM:()=>a.CohereForCausalLM,CohereModel:()=>a.CohereModel,CoherePreTrainedModel:()=>a.CoherePreTrainedModel,CohereTokenizer:()=>l.CohereTokenizer,ConvBertForMaskedLM:()=>a.ConvBertForMaskedLM,ConvBertForQuestionAnswering:()=>a.ConvBertForQuestionAnswering,ConvBertForSequenceClassification:()=>a.ConvBertForSequenceClassification,ConvBertForTokenClassification:()=>a.ConvBertForTokenClassification,ConvBertModel:()=>a.ConvBertModel,ConvBertPreTrainedModel:()=>a.ConvBertPreTrainedModel,ConvBertTokenizer:()=>l.ConvBertTokenizer,ConvNextFeatureExtractor:()=>w.ConvNextFeatureExtractor,ConvNextForImageClassification:()=>a.ConvNextForImageClassification,ConvNextImageProcessor:()=>w.ConvNextImageProcessor,ConvNextModel:()=>a.ConvNextModel,ConvNextPreTrainedModel:()=>a.ConvNextPreTrainedModel,ConvNextV2ForImageClassification:()=>a.ConvNextV2ForImageClassification,ConvNextV2Model:()=>a.ConvNextV2Model,ConvNextV2PreTrainedModel:()=>a.ConvNextV2PreTrainedModel,DFineForObjectDetection:()=>a.DFineForObjectDetection,DFineModel:()=>a.DFineModel,DFinePreTrainedModel:()=>a.DFinePreTrainedModel,DINOv3ConvNextModel:()=>a.DINOv3ConvNextModel,DINOv3ConvNextPreTrainedModel:()=>a.DINOv3ConvNextPreTrainedModel,DINOv3ViTImageProcessor:()=>w.DINOv3ViTImageProcessor,DINOv3ViTModel:()=>a.DINOv3ViTModel,DINOv3ViTPreTrainedModel:()=>a.DINOv3ViTPreTrainedModel,DPTFeatureExtractor:()=>w.DPTFeatureExtractor,DPTForDepthEstimation:()=>a.DPTForDepthEstimation,DPTImageProcessor:()=>w.DPTImageProcessor,DPTModel:()=>a.DPTModel,DPTPreTrainedModel:()=>a.DPTPreTrainedModel,DacDecoderModel:()=>a.DacDecoderModel,DacDecoderOutput:()=>a.DacDecoderOutput,DacEncoderModel:()=>a.DacEncoderModel,DacEncoderOutput:()=>a.DacEncoderOutput,DacFeatureExtractor:()=>f.DacFeatureExtractor,DacModel:()=>a.DacModel,DacPreTrainedModel:()=>a.DacPreTrainedModel,DataTypeMap:()=>p.DataTypeMap,DebertaForMaskedLM:()=>a.DebertaForMaskedLM,DebertaForQuestionAnswering:()=>a.DebertaForQuestionAnswering,DebertaForSequenceClassification:()=>a.DebertaForSequenceClassification,DebertaForTokenClassification:()=>a.DebertaForTokenClassification,DebertaModel:()=>a.DebertaModel,DebertaPreTrainedModel:()=>a.DebertaPreTrainedModel,DebertaTokenizer:()=>l.DebertaTokenizer,DebertaV2ForMaskedLM:()=>a.DebertaV2ForMaskedLM,DebertaV2ForQuestionAnswering:()=>a.DebertaV2ForQuestionAnswering,DebertaV2ForSequenceClassification:()=>a.DebertaV2ForSequenceClassification,DebertaV2ForTokenClassification:()=>a.DebertaV2ForTokenClassification,DebertaV2Model:()=>a.DebertaV2Model,DebertaV2PreTrainedModel:()=>a.DebertaV2PreTrainedModel,DebertaV2Tokenizer:()=>l.DebertaV2Tokenizer,DecisionTransformerModel:()=>a.DecisionTransformerModel,DecisionTransformerPreTrainedModel:()=>a.DecisionTransformerPreTrainedModel,DeiTFeatureExtractor:()=>w.DeiTFeatureExtractor,DeiTForImageClassification:()=>a.DeiTForImageClassification,DeiTImageProcessor:()=>w.DeiTImageProcessor,DeiTModel:()=>a.DeiTModel,DeiTPreTrainedModel:()=>a.DeiTPreTrainedModel,DepthAnythingForDepthEstimation:()=>a.DepthAnythingForDepthEstimation,DepthAnythingPreTrainedModel:()=>a.DepthAnythingPreTrainedModel,DepthEstimationPipeline:()=>i.DepthEstimationPipeline,DepthProForDepthEstimation:()=>a.DepthProForDepthEstimation,DepthProPreTrainedModel:()=>a.DepthProPreTrainedModel,DetrFeatureExtractor:()=>w.DetrFeatureExtractor,DetrForObjectDetection:()=>a.DetrForObjectDetection,DetrForSegmentation:()=>a.DetrForSegmentation,DetrImageProcessor:()=>w.DetrImageProcessor,DetrModel:()=>a.DetrModel,DetrObjectDetectionOutput:()=>a.DetrObjectDetectionOutput,DetrPreTrainedModel:()=>a.DetrPreTrainedModel,DetrSegmentationOutput:()=>a.DetrSegmentationOutput,Dinov2ForImageClassification:()=>a.Dinov2ForImageClassification,Dinov2Model:()=>a.Dinov2Model,Dinov2PreTrainedModel:()=>a.Dinov2PreTrainedModel,Dinov2WithRegistersForImageClassification:()=>a.Dinov2WithRegistersForImageClassification,Dinov2WithRegistersModel:()=>a.Dinov2WithRegistersModel,Dinov2WithRegistersPreTrainedModel:()=>a.Dinov2WithRegistersPreTrainedModel,DistilBertForMaskedLM:()=>a.DistilBertForMaskedLM,DistilBertForQuestionAnswering:()=>a.DistilBertForQuestionAnswering,DistilBertForSequenceClassification:()=>a.DistilBertForSequenceClassification,DistilBertForTokenClassification:()=>a.DistilBertForTokenClassification,DistilBertModel:()=>a.DistilBertModel,DistilBertPreTrainedModel:()=>a.DistilBertPreTrainedModel,DistilBertTokenizer:()=>l.DistilBertTokenizer,DocumentQuestionAnsweringPipeline:()=>i.DocumentQuestionAnsweringPipeline,DonutFeatureExtractor:()=>w.DonutFeatureExtractor,DonutImageProcessor:()=>w.DonutImageProcessor,DonutSwinModel:()=>a.DonutSwinModel,DonutSwinPreTrainedModel:()=>a.DonutSwinPreTrainedModel,EfficientNetForImageClassification:()=>a.EfficientNetForImageClassification,EfficientNetImageProcessor:()=>w.EfficientNetImageProcessor,EfficientNetModel:()=>a.EfficientNetModel,EfficientNetPreTrainedModel:()=>a.EfficientNetPreTrainedModel,ElectraForMaskedLM:()=>a.ElectraForMaskedLM,ElectraForQuestionAnswering:()=>a.ElectraForQuestionAnswering,ElectraForSequenceClassification:()=>a.ElectraForSequenceClassification,ElectraForTokenClassification:()=>a.ElectraForTokenClassification,ElectraModel:()=>a.ElectraModel,ElectraPreTrainedModel:()=>a.ElectraPreTrainedModel,ElectraTokenizer:()=>l.ElectraTokenizer,EncodecFeatureExtractor:()=>f.EncodecFeatureExtractor,EosTokenCriteria:()=>k.EosTokenCriteria,Ernie4_5_ForCausalLM:()=>a.Ernie4_5_ForCausalLM,Ernie4_5_Model:()=>a.Ernie4_5_Model,Ernie4_5_PretrainedModel:()=>a.Ernie4_5_PretrainedModel,Ernie4_5_Tokenizer:()=>l.Ernie4_5_Tokenizer,EsmForMaskedLM:()=>a.EsmForMaskedLM,EsmForSequenceClassification:()=>a.EsmForSequenceClassification,EsmForTokenClassification:()=>a.EsmForTokenClassification,EsmModel:()=>a.EsmModel,EsmPreTrainedModel:()=>a.EsmPreTrainedModel,EsmTokenizer:()=>l.EsmTokenizer,ExaoneForCausalLM:()=>a.ExaoneForCausalLM,ExaoneModel:()=>a.ExaoneModel,ExaonePreTrainedModel:()=>a.ExaonePreTrainedModel,FFT:()=>_.FFT,FalconForCausalLM:()=>a.FalconForCausalLM,FalconModel:()=>a.FalconModel,FalconPreTrainedModel:()=>a.FalconPreTrainedModel,FalconTokenizer:()=>l.FalconTokenizer,FastViTForImageClassification:()=>a.FastViTForImageClassification,FastViTModel:()=>a.FastViTModel,FastViTPreTrainedModel:()=>a.FastViTPreTrainedModel,FeatureExtractionPipeline:()=>i.FeatureExtractionPipeline,FeatureExtractor:()=>h.FeatureExtractor,FillMaskPipeline:()=>i.FillMaskPipeline,Florence2ForConditionalGeneration:()=>a.Florence2ForConditionalGeneration,Florence2PreTrainedModel:()=>a.Florence2PreTrainedModel,Florence2Processor:()=>P.Florence2Processor,ForcedBOSTokenLogitsProcessor:()=>y.ForcedBOSTokenLogitsProcessor,ForcedEOSTokenLogitsProcessor:()=>y.ForcedEOSTokenLogitsProcessor,GLPNFeatureExtractor:()=>w.GLPNFeatureExtractor,GLPNForDepthEstimation:()=>a.GLPNForDepthEstimation,GLPNModel:()=>a.GLPNModel,GLPNPreTrainedModel:()=>a.GLPNPreTrainedModel,GPT2LMHeadModel:()=>a.GPT2LMHeadModel,GPT2Model:()=>a.GPT2Model,GPT2PreTrainedModel:()=>a.GPT2PreTrainedModel,GPT2Tokenizer:()=>l.GPT2Tokenizer,GPTBigCodeForCausalLM:()=>a.GPTBigCodeForCausalLM,GPTBigCodeModel:()=>a.GPTBigCodeModel,GPTBigCodePreTrainedModel:()=>a.GPTBigCodePreTrainedModel,GPTJForCausalLM:()=>a.GPTJForCausalLM,GPTJModel:()=>a.GPTJModel,GPTJPreTrainedModel:()=>a.GPTJPreTrainedModel,GPTNeoForCausalLM:()=>a.GPTNeoForCausalLM,GPTNeoModel:()=>a.GPTNeoModel,GPTNeoPreTrainedModel:()=>a.GPTNeoPreTrainedModel,GPTNeoXForCausalLM:()=>a.GPTNeoXForCausalLM,GPTNeoXModel:()=>a.GPTNeoXModel,GPTNeoXPreTrainedModel:()=>a.GPTNeoXPreTrainedModel,GPTNeoXTokenizer:()=>l.GPTNeoXTokenizer,Gemma2ForCausalLM:()=>a.Gemma2ForCausalLM,Gemma2Model:()=>a.Gemma2Model,Gemma2PreTrainedModel:()=>a.Gemma2PreTrainedModel,Gemma3ForCausalLM:()=>a.Gemma3ForCausalLM,Gemma3Model:()=>a.Gemma3Model,Gemma3PreTrainedModel:()=>a.Gemma3PreTrainedModel,Gemma3nAudioFeatureExtractor:()=>f.Gemma3nAudioFeatureExtractor,Gemma3nForConditionalGeneration:()=>a.Gemma3nForConditionalGeneration,Gemma3nPreTrainedModel:()=>a.Gemma3nPreTrainedModel,Gemma3nProcessor:()=>P.Gemma3nProcessor,GemmaForCausalLM:()=>a.GemmaForCausalLM,GemmaModel:()=>a.GemmaModel,GemmaPreTrainedModel:()=>a.GemmaPreTrainedModel,GemmaTokenizer:()=>l.GemmaTokenizer,GlmForCausalLM:()=>a.GlmForCausalLM,GlmModel:()=>a.GlmModel,GlmPreTrainedModel:()=>a.GlmPreTrainedModel,GraniteForCausalLM:()=>a.GraniteForCausalLM,GraniteModel:()=>a.GraniteModel,GranitePreTrainedModel:()=>a.GranitePreTrainedModel,Grok1Tokenizer:()=>l.Grok1Tokenizer,GroundingDinoForObjectDetection:()=>a.GroundingDinoForObjectDetection,GroundingDinoImageProcessor:()=>w.GroundingDinoImageProcessor,GroundingDinoPreTrainedModel:()=>a.GroundingDinoPreTrainedModel,GroundingDinoProcessor:()=>P.GroundingDinoProcessor,GroupViTModel:()=>a.GroupViTModel,GroupViTPreTrainedModel:()=>a.GroupViTPreTrainedModel,HeliumForCausalLM:()=>a.HeliumForCausalLM,HeliumModel:()=>a.HeliumModel,HeliumPreTrainedModel:()=>a.HeliumPreTrainedModel,HerbertTokenizer:()=>l.HerbertTokenizer,HieraForImageClassification:()=>a.HieraForImageClassification,HieraModel:()=>a.HieraModel,HieraPreTrainedModel:()=>a.HieraPreTrainedModel,HubertForCTC:()=>a.HubertForCTC,HubertForSequenceClassification:()=>a.HubertForSequenceClassification,HubertModel:()=>a.HubertModel,HubertPreTrainedModel:()=>a.HubertPreTrainedModel,IJepaForImageClassification:()=>a.IJepaForImageClassification,IJepaModel:()=>a.IJepaModel,IJepaPreTrainedModel:()=>a.IJepaPreTrainedModel,Idefics3ForConditionalGeneration:()=>a.Idefics3ForConditionalGeneration,Idefics3ImageProcessor:()=>w.Idefics3ImageProcessor,Idefics3PreTrainedModel:()=>a.Idefics3PreTrainedModel,Idefics3Processor:()=>P.Idefics3Processor,ImageClassificationPipeline:()=>i.ImageClassificationPipeline,ImageFeatureExtractionPipeline:()=>i.ImageFeatureExtractionPipeline,ImageFeatureExtractor:()=>f.ImageFeatureExtractor,ImageMattingOutput:()=>a.ImageMattingOutput,ImageProcessor:()=>M.ImageProcessor,ImageSegmentationPipeline:()=>i.ImageSegmentationPipeline,ImageToImagePipeline:()=>i.ImageToImagePipeline,ImageToTextPipeline:()=>i.ImageToTextPipeline,InterruptableStoppingCriteria:()=>k.InterruptableStoppingCriteria,JAISLMHeadModel:()=>a.JAISLMHeadModel,JAISModel:()=>a.JAISModel,JAISPreTrainedModel:()=>a.JAISPreTrainedModel,JinaCLIPImageProcessor:()=>w.JinaCLIPImageProcessor,JinaCLIPModel:()=>a.JinaCLIPModel,JinaCLIPPreTrainedModel:()=>a.JinaCLIPPreTrainedModel,JinaCLIPProcessor:()=>P.JinaCLIPProcessor,JinaCLIPTextModel:()=>a.JinaCLIPTextModel,JinaCLIPVisionModel:()=>a.JinaCLIPVisionModel,Lfm2ForCausalLM:()=>a.Lfm2ForCausalLM,Lfm2Model:()=>a.Lfm2Model,Lfm2PreTrainedModel:()=>a.Lfm2PreTrainedModel,LiteWhisperForConditionalGeneration:()=>a.LiteWhisperForConditionalGeneration,LlamaForCausalLM:()=>a.LlamaForCausalLM,LlamaModel:()=>a.LlamaModel,LlamaPreTrainedModel:()=>a.LlamaPreTrainedModel,LlamaTokenizer:()=>l.LlamaTokenizer,LlavaForConditionalGeneration:()=>a.LlavaForConditionalGeneration,LlavaOnevisionForConditionalGeneration:()=>a.LlavaOnevisionForConditionalGeneration,LlavaOnevisionImageProcessor:()=>w.LlavaOnevisionImageProcessor,LlavaPreTrainedModel:()=>a.LlavaPreTrainedModel,LlavaProcessor:()=>P.LlavaProcessor,LlavaQwen2ForCausalLM:()=>a.LlavaQwen2ForCausalLM,LogitsProcessor:()=>y.LogitsProcessor,LogitsProcessorList:()=>y.LogitsProcessorList,LogitsWarper:()=>y.LogitsWarper,LongT5ForConditionalGeneration:()=>a.LongT5ForConditionalGeneration,LongT5Model:()=>a.LongT5Model,LongT5PreTrainedModel:()=>a.LongT5PreTrainedModel,M2M100ForConditionalGeneration:()=>a.M2M100ForConditionalGeneration,M2M100Model:()=>a.M2M100Model,M2M100PreTrainedModel:()=>a.M2M100PreTrainedModel,M2M100Tokenizer:()=>l.M2M100Tokenizer,MBart50Tokenizer:()=>l.MBart50Tokenizer,MBartForCausalLM:()=>a.MBartForCausalLM,MBartForConditionalGeneration:()=>a.MBartForConditionalGeneration,MBartForSequenceClassification:()=>a.MBartForSequenceClassification,MBartModel:()=>a.MBartModel,MBartPreTrainedModel:()=>a.MBartPreTrainedModel,MBartTokenizer:()=>l.MBartTokenizer,MPNetForMaskedLM:()=>a.MPNetForMaskedLM,MPNetForQuestionAnswering:()=>a.MPNetForQuestionAnswering,MPNetForSequenceClassification:()=>a.MPNetForSequenceClassification,MPNetForTokenClassification:()=>a.MPNetForTokenClassification,MPNetModel:()=>a.MPNetModel,MPNetPreTrainedModel:()=>a.MPNetPreTrainedModel,MPNetTokenizer:()=>l.MPNetTokenizer,MT5ForConditionalGeneration:()=>a.MT5ForConditionalGeneration,MT5Model:()=>a.MT5Model,MT5PreTrainedModel:()=>a.MT5PreTrainedModel,MarianMTModel:()=>a.MarianMTModel,MarianModel:()=>a.MarianModel,MarianPreTrainedModel:()=>a.MarianPreTrainedModel,MarianTokenizer:()=>l.MarianTokenizer,Mask2FormerImageProcessor:()=>w.Mask2FormerImageProcessor,MaskFormerFeatureExtractor:()=>w.MaskFormerFeatureExtractor,MaskFormerForInstanceSegmentation:()=>a.MaskFormerForInstanceSegmentation,MaskFormerImageProcessor:()=>w.MaskFormerImageProcessor,MaskFormerModel:()=>a.MaskFormerModel,MaskFormerPreTrainedModel:()=>a.MaskFormerPreTrainedModel,MaskedLMOutput:()=>a.MaskedLMOutput,MaxLengthCriteria:()=>k.MaxLengthCriteria,Metric3DForDepthEstimation:()=>a.Metric3DForDepthEstimation,Metric3DPreTrainedModel:()=>a.Metric3DPreTrainedModel,Metric3Dv2ForDepthEstimation:()=>a.Metric3Dv2ForDepthEstimation,Metric3Dv2PreTrainedModel:()=>a.Metric3Dv2PreTrainedModel,MgpstrForSceneTextRecognition:()=>a.MgpstrForSceneTextRecognition,MgpstrModelOutput:()=>a.MgpstrModelOutput,MgpstrPreTrainedModel:()=>a.MgpstrPreTrainedModel,MgpstrProcessor:()=>P.MgpstrProcessor,MgpstrTokenizer:()=>l.MgpstrTokenizer,MimiDecoderModel:()=>a.MimiDecoderModel,MimiDecoderOutput:()=>a.MimiDecoderOutput,MimiEncoderModel:()=>a.MimiEncoderModel,MimiEncoderOutput:()=>a.MimiEncoderOutput,MimiModel:()=>a.MimiModel,MimiPreTrainedModel:()=>a.MimiPreTrainedModel,MinLengthLogitsProcessor:()=>y.MinLengthLogitsProcessor,MinNewTokensLengthLogitsProcessor:()=>y.MinNewTokensLengthLogitsProcessor,MistralForCausalLM:()=>a.MistralForCausalLM,MistralModel:()=>a.MistralModel,MistralPreTrainedModel:()=>a.MistralPreTrainedModel,MobileBertForMaskedLM:()=>a.MobileBertForMaskedLM,MobileBertForQuestionAnswering:()=>a.MobileBertForQuestionAnswering,MobileBertForSequenceClassification:()=>a.MobileBertForSequenceClassification,MobileBertModel:()=>a.MobileBertModel,MobileBertPreTrainedModel:()=>a.MobileBertPreTrainedModel,MobileBertTokenizer:()=>l.MobileBertTokenizer,MobileLLMForCausalLM:()=>a.MobileLLMForCausalLM,MobileLLMModel:()=>a.MobileLLMModel,MobileLLMPreTrainedModel:()=>a.MobileLLMPreTrainedModel,MobileNetV1FeatureExtractor:()=>w.MobileNetV1FeatureExtractor,MobileNetV1ForImageClassification:()=>a.MobileNetV1ForImageClassification,MobileNetV1ForSemanticSegmentation:()=>a.MobileNetV1ForSemanticSegmentation,MobileNetV1ImageProcessor:()=>w.MobileNetV1ImageProcessor,MobileNetV1Model:()=>a.MobileNetV1Model,MobileNetV1PreTrainedModel:()=>a.MobileNetV1PreTrainedModel,MobileNetV2FeatureExtractor:()=>w.MobileNetV2FeatureExtractor,MobileNetV2ForImageClassification:()=>a.MobileNetV2ForImageClassification,MobileNetV2ForSemanticSegmentation:()=>a.MobileNetV2ForSemanticSegmentation,MobileNetV2ImageProcessor:()=>w.MobileNetV2ImageProcessor,MobileNetV2Model:()=>a.MobileNetV2Model,MobileNetV2PreTrainedModel:()=>a.MobileNetV2PreTrainedModel,MobileNetV3FeatureExtractor:()=>w.MobileNetV3FeatureExtractor,MobileNetV3ForImageClassification:()=>a.MobileNetV3ForImageClassification,MobileNetV3ForSemanticSegmentation:()=>a.MobileNetV3ForSemanticSegmentation,MobileNetV3ImageProcessor:()=>w.MobileNetV3ImageProcessor,MobileNetV3Model:()=>a.MobileNetV3Model,MobileNetV3PreTrainedModel:()=>a.MobileNetV3PreTrainedModel,MobileNetV4FeatureExtractor:()=>w.MobileNetV4FeatureExtractor,MobileNetV4ForImageClassification:()=>a.MobileNetV4ForImageClassification,MobileNetV4ForSemanticSegmentation:()=>a.MobileNetV4ForSemanticSegmentation,MobileNetV4ImageProcessor:()=>w.MobileNetV4ImageProcessor,MobileNetV4Model:()=>a.MobileNetV4Model,MobileNetV4PreTrainedModel:()=>a.MobileNetV4PreTrainedModel,MobileViTFeatureExtractor:()=>w.MobileViTFeatureExtractor,MobileViTForImageClassification:()=>a.MobileViTForImageClassification,MobileViTImageProcessor:()=>w.MobileViTImageProcessor,MobileViTModel:()=>a.MobileViTModel,MobileViTPreTrainedModel:()=>a.MobileViTPreTrainedModel,MobileViTV2ForImageClassification:()=>a.MobileViTV2ForImageClassification,MobileViTV2Model:()=>a.MobileViTV2Model,MobileViTV2PreTrainedModel:()=>a.MobileViTV2PreTrainedModel,ModelOutput:()=>a.ModelOutput,ModernBertDecoderForCausalLM:()=>a.ModernBertDecoderForCausalLM,ModernBertDecoderModel:()=>a.ModernBertDecoderModel,ModernBertDecoderPreTrainedModel:()=>a.ModernBertDecoderPreTrainedModel,ModernBertForMaskedLM:()=>a.ModernBertForMaskedLM,ModernBertForSequenceClassification:()=>a.ModernBertForSequenceClassification,ModernBertForTokenClassification:()=>a.ModernBertForTokenClassification,ModernBertModel:()=>a.ModernBertModel,ModernBertPreTrainedModel:()=>a.ModernBertPreTrainedModel,Moondream1ForConditionalGeneration:()=>a.Moondream1ForConditionalGeneration,MoonshineFeatureExtractor:()=>f.MoonshineFeatureExtractor,MoonshineForConditionalGeneration:()=>a.MoonshineForConditionalGeneration,MoonshineModel:()=>a.MoonshineModel,MoonshinePreTrainedModel:()=>a.MoonshinePreTrainedModel,MoonshineProcessor:()=>P.MoonshineProcessor,MptForCausalLM:()=>a.MptForCausalLM,MptModel:()=>a.MptModel,MptPreTrainedModel:()=>a.MptPreTrainedModel,MultiModalityCausalLM:()=>a.MultiModalityCausalLM,MultiModalityPreTrainedModel:()=>a.MultiModalityPreTrainedModel,MusicgenForCausalLM:()=>a.MusicgenForCausalLM,MusicgenForConditionalGeneration:()=>a.MusicgenForConditionalGeneration,MusicgenModel:()=>a.MusicgenModel,MusicgenPreTrainedModel:()=>a.MusicgenPreTrainedModel,NeoBertForMaskedLM:()=>a.NeoBertForMaskedLM,NeoBertForQuestionAnswering:()=>a.NeoBertForQuestionAnswering,NeoBertForSequenceClassification:()=>a.NeoBertForSequenceClassification,NeoBertForTokenClassification:()=>a.NeoBertForTokenClassification,NeoBertModel:()=>a.NeoBertModel,NeoBertPreTrainedModel:()=>a.NeoBertPreTrainedModel,NllbTokenizer:()=>l.NllbTokenizer,NoBadWordsLogitsProcessor:()=>y.NoBadWordsLogitsProcessor,NoRepeatNGramLogitsProcessor:()=>y.NoRepeatNGramLogitsProcessor,NomicBertModel:()=>a.NomicBertModel,NomicBertPreTrainedModel:()=>a.NomicBertPreTrainedModel,NougatImageProcessor:()=>w.NougatImageProcessor,NougatTokenizer:()=>l.NougatTokenizer,OPTForCausalLM:()=>a.OPTForCausalLM,OPTModel:()=>a.OPTModel,OPTPreTrainedModel:()=>a.OPTPreTrainedModel,ObjectDetectionPipeline:()=>i.ObjectDetectionPipeline,Olmo2ForCausalLM:()=>a.Olmo2ForCausalLM,Olmo2Model:()=>a.Olmo2Model,Olmo2PreTrainedModel:()=>a.Olmo2PreTrainedModel,OlmoForCausalLM:()=>a.OlmoForCausalLM,OlmoModel:()=>a.OlmoModel,OlmoPreTrainedModel:()=>a.OlmoPreTrainedModel,OpenELMForCausalLM:()=>a.OpenELMForCausalLM,OpenELMModel:()=>a.OpenELMModel,OpenELMPreTrainedModel:()=>a.OpenELMPreTrainedModel,OwlViTFeatureExtractor:()=>w.OwlViTFeatureExtractor,OwlViTForObjectDetection:()=>a.OwlViTForObjectDetection,OwlViTImageProcessor:()=>w.OwlViTImageProcessor,OwlViTModel:()=>a.OwlViTModel,OwlViTPreTrainedModel:()=>a.OwlViTPreTrainedModel,OwlViTProcessor:()=>P.OwlViTProcessor,Owlv2ForObjectDetection:()=>a.Owlv2ForObjectDetection,Owlv2ImageProcessor:()=>w.Owlv2ImageProcessor,Owlv2Model:()=>a.Owlv2Model,Owlv2PreTrainedModel:()=>a.Owlv2PreTrainedModel,PaliGemmaForConditionalGeneration:()=>a.PaliGemmaForConditionalGeneration,PaliGemmaPreTrainedModel:()=>a.PaliGemmaPreTrainedModel,PaliGemmaProcessor:()=>P.PaliGemmaProcessor,PatchTSMixerForPrediction:()=>a.PatchTSMixerForPrediction,PatchTSMixerModel:()=>a.PatchTSMixerModel,PatchTSMixerPreTrainedModel:()=>a.PatchTSMixerPreTrainedModel,PatchTSTForPrediction:()=>a.PatchTSTForPrediction,PatchTSTModel:()=>a.PatchTSTModel,PatchTSTPreTrainedModel:()=>a.PatchTSTPreTrainedModel,Phi3ForCausalLM:()=>a.Phi3ForCausalLM,Phi3Model:()=>a.Phi3Model,Phi3PreTrainedModel:()=>a.Phi3PreTrainedModel,Phi3VForCausalLM:()=>a.Phi3VForCausalLM,Phi3VImageProcessor:()=>w.Phi3VImageProcessor,Phi3VPreTrainedModel:()=>a.Phi3VPreTrainedModel,Phi3VProcessor:()=>P.Phi3VProcessor,PhiForCausalLM:()=>a.PhiForCausalLM,PhiModel:()=>a.PhiModel,PhiPreTrainedModel:()=>a.PhiPreTrainedModel,Pipeline:()=>i.Pipeline,PreTrainedModel:()=>a.PreTrainedModel,PreTrainedTokenizer:()=>l.PreTrainedTokenizer,PretrainedConfig:()=>c.PretrainedConfig,PretrainedMixin:()=>a.PretrainedMixin,Processor:()=>x.Processor,PvtForImageClassification:()=>a.PvtForImageClassification,PvtImageProcessor:()=>w.PvtImageProcessor,PvtModel:()=>a.PvtModel,PvtPreTrainedModel:()=>a.PvtPreTrainedModel,PyAnnoteFeatureExtractor:()=>f.PyAnnoteFeatureExtractor,PyAnnoteForAudioFrameClassification:()=>a.PyAnnoteForAudioFrameClassification,PyAnnoteModel:()=>a.PyAnnoteModel,PyAnnotePreTrainedModel:()=>a.PyAnnotePreTrainedModel,PyAnnoteProcessor:()=>P.PyAnnoteProcessor,QuestionAnsweringModelOutput:()=>a.QuestionAnsweringModelOutput,QuestionAnsweringPipeline:()=>i.QuestionAnsweringPipeline,Qwen2ForCausalLM:()=>a.Qwen2ForCausalLM,Qwen2Model:()=>a.Qwen2Model,Qwen2PreTrainedModel:()=>a.Qwen2PreTrainedModel,Qwen2Tokenizer:()=>l.Qwen2Tokenizer,Qwen2VLForConditionalGeneration:()=>a.Qwen2VLForConditionalGeneration,Qwen2VLImageProcessor:()=>w.Qwen2VLImageProcessor,Qwen2VLPreTrainedModel:()=>a.Qwen2VLPreTrainedModel,Qwen2VLProcessor:()=>P.Qwen2VLProcessor,Qwen3ForCausalLM:()=>a.Qwen3ForCausalLM,Qwen3Model:()=>a.Qwen3Model,Qwen3PreTrainedModel:()=>a.Qwen3PreTrainedModel,RFDetrForObjectDetection:()=>a.RFDetrForObjectDetection,RFDetrModel:()=>a.RFDetrModel,RFDetrObjectDetectionOutput:()=>a.RFDetrObjectDetectionOutput,RFDetrPreTrainedModel:()=>a.RFDetrPreTrainedModel,RTDetrForObjectDetection:()=>a.RTDetrForObjectDetection,RTDetrImageProcessor:()=>w.RTDetrImageProcessor,RTDetrModel:()=>a.RTDetrModel,RTDetrObjectDetectionOutput:()=>a.RTDetrObjectDetectionOutput,RTDetrPreTrainedModel:()=>a.RTDetrPreTrainedModel,RTDetrV2ForObjectDetection:()=>a.RTDetrV2ForObjectDetection,RTDetrV2Model:()=>a.RTDetrV2Model,RTDetrV2ObjectDetectionOutput:()=>a.RTDetrV2ObjectDetectionOutput,RTDetrV2PreTrainedModel:()=>a.RTDetrV2PreTrainedModel,RawAudio:()=>u.RawAudio,RawImage:()=>d.RawImage,RawVideo:()=>m.RawVideo,RawVideoFrame:()=>m.RawVideoFrame,RepetitionPenaltyLogitsProcessor:()=>y.RepetitionPenaltyLogitsProcessor,ResNetForImageClassification:()=>a.ResNetForImageClassification,ResNetModel:()=>a.ResNetModel,ResNetPreTrainedModel:()=>a.ResNetPreTrainedModel,RoFormerForMaskedLM:()=>a.RoFormerForMaskedLM,RoFormerForQuestionAnswering:()=>a.RoFormerForQuestionAnswering,RoFormerForSequenceClassification:()=>a.RoFormerForSequenceClassification,RoFormerForTokenClassification:()=>a.RoFormerForTokenClassification,RoFormerModel:()=>a.RoFormerModel,RoFormerPreTrainedModel:()=>a.RoFormerPreTrainedModel,RoFormerTokenizer:()=>l.RoFormerTokenizer,RobertaForMaskedLM:()=>a.RobertaForMaskedLM,RobertaForQuestionAnswering:()=>a.RobertaForQuestionAnswering,RobertaForSequenceClassification:()=>a.RobertaForSequenceClassification,RobertaForTokenClassification:()=>a.RobertaForTokenClassification,RobertaModel:()=>a.RobertaModel,RobertaPreTrainedModel:()=>a.RobertaPreTrainedModel,RobertaTokenizer:()=>l.RobertaTokenizer,SamImageProcessor:()=>w.SamImageProcessor,SamImageSegmentationOutput:()=>a.SamImageSegmentationOutput,SamModel:()=>a.SamModel,SamPreTrainedModel:()=>a.SamPreTrainedModel,SamProcessor:()=>P.SamProcessor,SapiensForDepthEstimation:()=>a.SapiensForDepthEstimation,SapiensForNormalEstimation:()=>a.SapiensForNormalEstimation,SapiensForSemanticSegmentation:()=>a.SapiensForSemanticSegmentation,SapiensPreTrainedModel:()=>a.SapiensPreTrainedModel,SeamlessM4TFeatureExtractor:()=>f.SeamlessM4TFeatureExtractor,SegformerFeatureExtractor:()=>w.SegformerFeatureExtractor,SegformerForImageClassification:()=>a.SegformerForImageClassification,SegformerForSemanticSegmentation:()=>a.SegformerForSemanticSegmentation,SegformerImageProcessor:()=>w.SegformerImageProcessor,SegformerModel:()=>a.SegformerModel,SegformerPreTrainedModel:()=>a.SegformerPreTrainedModel,Seq2SeqLMOutput:()=>a.Seq2SeqLMOutput,SequenceClassifierOutput:()=>a.SequenceClassifierOutput,SiglipImageProcessor:()=>w.SiglipImageProcessor,SiglipModel:()=>a.SiglipModel,SiglipPreTrainedModel:()=>a.SiglipPreTrainedModel,SiglipTextModel:()=>a.SiglipTextModel,SiglipTokenizer:()=>l.SiglipTokenizer,SiglipVisionModel:()=>a.SiglipVisionModel,SmolLM3ForCausalLM:()=>a.SmolLM3ForCausalLM,SmolLM3Model:()=>a.SmolLM3Model,SmolLM3PreTrainedModel:()=>a.SmolLM3PreTrainedModel,SmolVLMForConditionalGeneration:()=>a.SmolVLMForConditionalGeneration,SmolVLMImageProcessor:()=>w.SmolVLMImageProcessor,SmolVLMProcessor:()=>P.SmolVLMProcessor,SnacDecoderModel:()=>a.SnacDecoderModel,SnacEncoderModel:()=>a.SnacEncoderModel,SnacFeatureExtractor:()=>f.SnacFeatureExtractor,SnacModel:()=>a.SnacModel,SnacPreTrainedModel:()=>a.SnacPreTrainedModel,SpeechT5FeatureExtractor:()=>f.SpeechT5FeatureExtractor,SpeechT5ForSpeechToText:()=>a.SpeechT5ForSpeechToText,SpeechT5ForTextToSpeech:()=>a.SpeechT5ForTextToSpeech,SpeechT5HifiGan:()=>a.SpeechT5HifiGan,SpeechT5Model:()=>a.SpeechT5Model,SpeechT5PreTrainedModel:()=>a.SpeechT5PreTrainedModel,SpeechT5Processor:()=>P.SpeechT5Processor,SpeechT5Tokenizer:()=>l.SpeechT5Tokenizer,SqueezeBertForMaskedLM:()=>a.SqueezeBertForMaskedLM,SqueezeBertForQuestionAnswering:()=>a.SqueezeBertForQuestionAnswering,SqueezeBertForSequenceClassification:()=>a.SqueezeBertForSequenceClassification,SqueezeBertModel:()=>a.SqueezeBertModel,SqueezeBertPreTrainedModel:()=>a.SqueezeBertPreTrainedModel,SqueezeBertTokenizer:()=>l.SqueezeBertTokenizer,StableLmForCausalLM:()=>a.StableLmForCausalLM,StableLmModel:()=>a.StableLmModel,StableLmPreTrainedModel:()=>a.StableLmPreTrainedModel,Starcoder2ForCausalLM:()=>a.Starcoder2ForCausalLM,Starcoder2Model:()=>a.Starcoder2Model,Starcoder2PreTrainedModel:()=>a.Starcoder2PreTrainedModel,StoppingCriteria:()=>k.StoppingCriteria,StoppingCriteriaList:()=>k.StoppingCriteriaList,StyleTextToSpeech2Model:()=>a.StyleTextToSpeech2Model,StyleTextToSpeech2PreTrainedModel:()=>a.StyleTextToSpeech2PreTrainedModel,SummarizationPipeline:()=>i.SummarizationPipeline,SuppressTokensAtBeginLogitsProcessor:()=>y.SuppressTokensAtBeginLogitsProcessor,Swin2SRForImageSuperResolution:()=>a.Swin2SRForImageSuperResolution,Swin2SRImageProcessor:()=>w.Swin2SRImageProcessor,Swin2SRModel:()=>a.Swin2SRModel,Swin2SRPreTrainedModel:()=>a.Swin2SRPreTrainedModel,SwinForImageClassification:()=>a.SwinForImageClassification,SwinForSemanticSegmentation:()=>a.SwinForSemanticSegmentation,SwinModel:()=>a.SwinModel,SwinPreTrainedModel:()=>a.SwinPreTrainedModel,T5ForConditionalGeneration:()=>a.T5ForConditionalGeneration,T5Model:()=>a.T5Model,T5PreTrainedModel:()=>a.T5PreTrainedModel,T5Tokenizer:()=>l.T5Tokenizer,TableTransformerForObjectDetection:()=>a.TableTransformerForObjectDetection,TableTransformerModel:()=>a.TableTransformerModel,TableTransformerObjectDetectionOutput:()=>a.TableTransformerObjectDetectionOutput,TableTransformerPreTrainedModel:()=>a.TableTransformerPreTrainedModel,TemperatureLogitsWarper:()=>y.TemperatureLogitsWarper,Tensor:()=>p.Tensor,Text2TextGenerationPipeline:()=>i.Text2TextGenerationPipeline,TextClassificationPipeline:()=>i.TextClassificationPipeline,TextGenerationPipeline:()=>i.TextGenerationPipeline,TextStreamer:()=>F.TextStreamer,TextToAudioPipeline:()=>i.TextToAudioPipeline,TokenClassificationPipeline:()=>i.TokenClassificationPipeline,TokenClassifierOutput:()=>a.TokenClassifierOutput,TokenizerModel:()=>l.TokenizerModel,TopKLogitsWarper:()=>y.TopKLogitsWarper,TopPLogitsWarper:()=>y.TopPLogitsWarper,TrOCRForCausalLM:()=>a.TrOCRForCausalLM,TrOCRPreTrainedModel:()=>a.TrOCRPreTrainedModel,TranslationPipeline:()=>i.TranslationPipeline,UltravoxModel:()=>a.UltravoxModel,UltravoxPreTrainedModel:()=>a.UltravoxPreTrainedModel,UltravoxProcessor:()=>P.UltravoxProcessor,UniSpeechForCTC:()=>a.UniSpeechForCTC,UniSpeechForSequenceClassification:()=>a.UniSpeechForSequenceClassification,UniSpeechModel:()=>a.UniSpeechModel,UniSpeechPreTrainedModel:()=>a.UniSpeechPreTrainedModel,UniSpeechSatForAudioFrameClassification:()=>a.UniSpeechSatForAudioFrameClassification,UniSpeechSatForCTC:()=>a.UniSpeechSatForCTC,UniSpeechSatForSequenceClassification:()=>a.UniSpeechSatForSequenceClassification,UniSpeechSatModel:()=>a.UniSpeechSatModel,UniSpeechSatPreTrainedModel:()=>a.UniSpeechSatPreTrainedModel,VLChatProcessor:()=>P.VLChatProcessor,VLMImageProcessor:()=>w.VLMImageProcessor,ViTFeatureExtractor:()=>w.ViTFeatureExtractor,ViTForImageClassification:()=>a.ViTForImageClassification,ViTImageProcessor:()=>w.ViTImageProcessor,ViTMAEModel:()=>a.ViTMAEModel,ViTMAEPreTrainedModel:()=>a.ViTMAEPreTrainedModel,ViTMSNForImageClassification:()=>a.ViTMSNForImageClassification,ViTMSNModel:()=>a.ViTMSNModel,ViTMSNPreTrainedModel:()=>a.ViTMSNPreTrainedModel,ViTModel:()=>a.ViTModel,ViTPreTrainedModel:()=>a.ViTPreTrainedModel,VisionEncoderDecoderModel:()=>a.VisionEncoderDecoderModel,VitMatteForImageMatting:()=>a.VitMatteForImageMatting,VitMatteImageProcessor:()=>w.VitMatteImageProcessor,VitMattePreTrainedModel:()=>a.VitMattePreTrainedModel,VitPoseForPoseEstimation:()=>a.VitPoseForPoseEstimation,VitPoseImageProcessor:()=>w.VitPoseImageProcessor,VitPosePreTrainedModel:()=>a.VitPosePreTrainedModel,VitsModel:()=>a.VitsModel,VitsModelOutput:()=>a.VitsModelOutput,VitsPreTrainedModel:()=>a.VitsPreTrainedModel,VitsTokenizer:()=>l.VitsTokenizer,VoxtralForConditionalGeneration:()=>a.VoxtralForConditionalGeneration,VoxtralProcessor:()=>P.VoxtralProcessor,Wav2Vec2BertForCTC:()=>a.Wav2Vec2BertForCTC,Wav2Vec2BertForSequenceClassification:()=>a.Wav2Vec2BertForSequenceClassification,Wav2Vec2BertModel:()=>a.Wav2Vec2BertModel,Wav2Vec2BertPreTrainedModel:()=>a.Wav2Vec2BertPreTrainedModel,Wav2Vec2CTCTokenizer:()=>l.Wav2Vec2CTCTokenizer,Wav2Vec2FeatureExtractor:()=>f.Wav2Vec2FeatureExtractor,Wav2Vec2ForAudioFrameClassification:()=>a.Wav2Vec2ForAudioFrameClassification,Wav2Vec2ForCTC:()=>a.Wav2Vec2ForCTC,Wav2Vec2ForSequenceClassification:()=>a.Wav2Vec2ForSequenceClassification,Wav2Vec2Model:()=>a.Wav2Vec2Model,Wav2Vec2PreTrainedModel:()=>a.Wav2Vec2PreTrainedModel,Wav2Vec2Processor:()=>P.Wav2Vec2Processor,Wav2Vec2ProcessorWithLM:()=>P.Wav2Vec2ProcessorWithLM,WavLMForAudioFrameClassification:()=>a.WavLMForAudioFrameClassification,WavLMForCTC:()=>a.WavLMForCTC,WavLMForSequenceClassification:()=>a.WavLMForSequenceClassification,WavLMForXVector:()=>a.WavLMForXVector,WavLMModel:()=>a.WavLMModel,WavLMPreTrainedModel:()=>a.WavLMPreTrainedModel,WeSpeakerFeatureExtractor:()=>f.WeSpeakerFeatureExtractor,WeSpeakerResNetModel:()=>a.WeSpeakerResNetModel,WeSpeakerResNetPreTrainedModel:()=>a.WeSpeakerResNetPreTrainedModel,WhisperFeatureExtractor:()=>f.WhisperFeatureExtractor,WhisperForConditionalGeneration:()=>a.WhisperForConditionalGeneration,WhisperModel:()=>a.WhisperModel,WhisperPreTrainedModel:()=>a.WhisperPreTrainedModel,WhisperProcessor:()=>P.WhisperProcessor,WhisperTextStreamer:()=>F.WhisperTextStreamer,WhisperTimeStampLogitsProcessor:()=>y.WhisperTimeStampLogitsProcessor,WhisperTokenizer:()=>l.WhisperTokenizer,XLMForQuestionAnswering:()=>a.XLMForQuestionAnswering,XLMForSequenceClassification:()=>a.XLMForSequenceClassification,XLMForTokenClassification:()=>a.XLMForTokenClassification,XLMModel:()=>a.XLMModel,XLMPreTrainedModel:()=>a.XLMPreTrainedModel,XLMRobertaForMaskedLM:()=>a.XLMRobertaForMaskedLM,XLMRobertaForQuestionAnswering:()=>a.XLMRobertaForQuestionAnswering,XLMRobertaForSequenceClassification:()=>a.XLMRobertaForSequenceClassification,XLMRobertaForTokenClassification:()=>a.XLMRobertaForTokenClassification,XLMRobertaModel:()=>a.XLMRobertaModel,XLMRobertaPreTrainedModel:()=>a.XLMRobertaPreTrainedModel,XLMRobertaTokenizer:()=>l.XLMRobertaTokenizer,XLMTokenizer:()=>l.XLMTokenizer,XLMWithLMHeadModel:()=>a.XLMWithLMHeadModel,XVectorOutput:()=>a.XVectorOutput,YolosFeatureExtractor:()=>w.YolosFeatureExtractor,YolosForObjectDetection:()=>a.YolosForObjectDetection,YolosImageProcessor:()=>w.YolosImageProcessor,YolosModel:()=>a.YolosModel,YolosObjectDetectionOutput:()=>a.YolosObjectDetectionOutput,YolosPreTrainedModel:()=>a.YolosPreTrainedModel,ZeroShotAudioClassificationPipeline:()=>i.ZeroShotAudioClassificationPipeline,ZeroShotClassificationPipeline:()=>i.ZeroShotClassificationPipeline,ZeroShotImageClassificationPipeline:()=>i.ZeroShotImageClassificationPipeline,ZeroShotObjectDetectionPipeline:()=>i.ZeroShotObjectDetectionPipeline,bankers_round:()=>_.bankers_round,cat:()=>p.cat,cos_sim:()=>_.cos_sim,dot:()=>_.dot,dynamic_time_warping:()=>_.dynamic_time_warping,env:()=>s.env,full:()=>p.full,full_like:()=>p.full_like,getCacheShapes:()=>c.getCacheShapes,hamming:()=>u.hamming,hanning:()=>u.hanning,interpolate:()=>p.interpolate,interpolate_4d:()=>p.interpolate_4d,interpolate_data:()=>_.interpolate_data,is_chinese_char:()=>l.is_chinese_char,layer_norm:()=>p.layer_norm,load_image:()=>d.load_image,load_video:()=>m.load_video,log_softmax:()=>_.log_softmax,magnitude:()=>_.magnitude,matmul:()=>p.matmul,max:()=>_.max,mean:()=>p.mean,mean_pooling:()=>p.mean_pooling,medianFilter:()=>_.medianFilter,mel_filter_bank:()=>u.mel_filter_bank,min:()=>_.min,ones:()=>p.ones,ones_like:()=>p.ones_like,permute:()=>p.permute,permute_data:()=>_.permute_data,pipeline:()=>i.pipeline,quantize_embeddings:()=>p.quantize_embeddings,rand:()=>p.rand,read_audio:()=>u.read_audio,rfft:()=>p.rfft,round:()=>_.round,slice:()=>p.slice,softmax:()=>_.softmax,spectrogram:()=>u.spectrogram,stack:()=>p.stack,std_mean:()=>p.std_mean,topk:()=>p.topk,window_function:()=>u.window_function,zeros:()=>p.zeros,zeros_like:()=>p.zeros_like}),s=D(/*! ./env.js */"./src/env.js"),i=D(/*! ./pipelines.js */"./src/pipelines.js"),a=D(/*! ./models.js */"./src/models.js"),l=D(/*! ./tokenizers.js */"./src/tokenizers.js"),c=D(/*! ./configs.js */"./src/configs.js"),u=D(/*! ./utils/audio.js */"./src/utils/audio.js"),d=D(/*! ./utils/image.js */"./src/utils/image.js"),m=D(/*! ./utils/video.js */"./src/utils/video.js"),p=D(/*! ./utils/tensor.js */"./src/utils/tensor.js"),_=D(/*! ./utils/maths.js */"./src/utils/maths.js"),h=D(/*! ./base/feature_extraction_utils.js */"./src/base/feature_extraction_utils.js"),f=D(/*! ./models/feature_extractors.js */"./src/models/feature_extractors.js"),g=D(/*! ./models/auto/feature_extraction_auto.js */"./src/models/auto/feature_extraction_auto.js"),M=D(/*! ./base/image_processors_utils.js */"./src/base/image_processors_utils.js"),w=D(/*! ./models/image_processors.js */"./src/models/image_processors.js"),T=D(/*! ./models/auto/image_processing_auto.js */"./src/models/auto/image_processing_auto.js"),x=D(/*! ./base/processing_utils.js */"./src/base/processing_utils.js"),P=D(/*! ./models/processors.js */"./src/models/processors.js"),b=D(/*! ./models/auto/processing_auto.js */"./src/models/auto/processing_auto.js"),F=D(/*! ./generation/streamers.js */"./src/generation/streamers.js"),k=D(/*! ./generation/stopping_criteria.js */"./src/generation/stopping_criteria.js"),y=D(/*! ./generation/logits_process.js */"./src/generation/logits_process.js");var j=z.ASTFeatureExtractor,V=z.ASTForAudioClassification,O=z.ASTModel,N=z.ASTPreTrainedModel,B=z.AlbertForMaskedLM,G=z.AlbertForQuestionAnswering,R=z.AlbertForSequenceClassification,q=z.AlbertModel,$=z.AlbertPreTrainedModel,W=z.AlbertTokenizer,U=z.ArceeForCausalLM,Q=z.ArceeModel,X=z.ArceePreTrainedModel,H=z.AudioClassificationPipeline,J=z.AutoConfig,Y=z.AutoFeatureExtractor,K=z.AutoImageProcessor,Z=z.AutoModel,ee=z.AutoModelForAudioClassification,et=z.AutoModelForAudioFrameClassification,er=z.AutoModelForAudioTextToText,en=z.AutoModelForCTC,eo=z.AutoModelForCausalLM,es=z.AutoModelForDepthEstimation,ei=z.AutoModelForDocumentQuestionAnswering,ea=z.AutoModelForImageClassification,el=z.AutoModelForImageFeatureExtraction,ec=z.AutoModelForImageMatting,eu=z.AutoModelForImageSegmentation,ed=z.AutoModelForImageTextToText,em=z.AutoModelForImageToImage,ep=z.AutoModelForMaskGeneration,e_=z.AutoModelForMaskedLM,eh=z.AutoModelForNormalEstimation,ef=z.AutoModelForObjectDetection,eg=z.AutoModelForPoseEstimation,eM=z.AutoModelForQuestionAnswering,ew=z.AutoModelForSemanticSegmentation,eT=z.AutoModelForSeq2SeqLM,ex=z.AutoModelForSequenceClassification,eP=z.AutoModelForSpeechSeq2Seq,eb=z.AutoModelForTextToSpectrogram,eF=z.AutoModelForTextToWaveform,ek=z.AutoModelForTokenClassification,ey=z.AutoModelForUniversalSegmentation,ev=z.AutoModelForVision2Seq,eC=z.AutoModelForXVector,eS=z.AutoModelForZeroShotObjectDetection,eE=z.AutoProcessor,eA=z.AutoTokenizer,eL=z.AutomaticSpeechRecognitionPipeline,eI=z.BackgroundRemovalPipeline,eD=z.BartForConditionalGeneration,ez=z.BartForSequenceClassification,ej=z.BartModel,eV=z.BartPretrainedModel,eO=z.BartTokenizer,eN=z.BaseModelOutput,eB=z.BaseStreamer,eG=z.BeitFeatureExtractor,eR=z.BeitForImageClassification,eq=z.BeitModel,e$=z.BeitPreTrainedModel,eW=z.BertForMaskedLM,eU=z.BertForQuestionAnswering,eQ=z.BertForSequenceClassification,eX=z.BertForTokenClassification,eH=z.BertModel,eJ=z.BertPreTrainedModel,eY=z.BertTokenizer,eK=z.BitImageProcessor,eZ=z.BlenderbotForConditionalGeneration,e0=z.BlenderbotModel,e1=z.BlenderbotPreTrainedModel,e2=z.BlenderbotSmallForConditionalGeneration,e3=z.BlenderbotSmallModel,e4=z.BlenderbotSmallPreTrainedModel,e5=z.BlenderbotSmallTokenizer,e8=z.BlenderbotTokenizer,e6=z.BloomForCausalLM,e9=z.BloomModel,e7=z.BloomPreTrainedModel,te=z.BloomTokenizer,tt=z.CLIPFeatureExtractor,tr=z.CLIPImageProcessor,tn=z.CLIPModel,to=z.CLIPPreTrainedModel,ts=z.CLIPSegForImageSegmentation,ti=z.CLIPSegModel,ta=z.CLIPSegPreTrainedModel,tl=z.CLIPTextModel,tc=z.CLIPTextModelWithProjection,tu=z.CLIPTokenizer,td=z.CLIPVisionModel,tm=z.CLIPVisionModelWithProjection,tp=z.CamembertForMaskedLM,t_=z.CamembertForQuestionAnswering,th=z.CamembertForSequenceClassification,tf=z.CamembertForTokenClassification,tg=z.CamembertModel,tM=z.CamembertPreTrainedModel,tw=z.CamembertTokenizer,tT=z.CausalLMOutput,tx=z.CausalLMOutputWithPast,tP=z.ChineseCLIPFeatureExtractor,tb=z.ChineseCLIPModel,tF=z.ChineseCLIPPreTrainedModel,tk=z.ClapAudioModelWithProjection,ty=z.ClapFeatureExtractor,tv=z.ClapModel,tC=z.ClapPreTrainedModel,tS=z.ClapTextModelWithProjection,tE=z.ClassifierFreeGuidanceLogitsProcessor,tA=z.CodeGenForCausalLM,tL=z.CodeGenModel,tI=z.CodeGenPreTrainedModel,tD=z.CodeGenTokenizer,tz=z.CodeLlamaTokenizer,tj=z.CohereForCausalLM,tV=z.CohereModel,tO=z.CoherePreTrainedModel,tN=z.CohereTokenizer,tB=z.ConvBertForMaskedLM,tG=z.ConvBertForQuestionAnswering,tR=z.ConvBertForSequenceClassification,tq=z.ConvBertForTokenClassification,t$=z.ConvBertModel,tW=z.ConvBertPreTrainedModel,tU=z.ConvBertTokenizer,tQ=z.ConvNextFeatureExtractor,tX=z.ConvNextForImageClassification,tH=z.ConvNextImageProcessor,tJ=z.ConvNextModel,tY=z.ConvNextPreTrainedModel,tK=z.ConvNextV2ForImageClassification,tZ=z.ConvNextV2Model,t0=z.ConvNextV2PreTrainedModel,t1=z.DFineForObjectDetection,t2=z.DFineModel,t3=z.DFinePreTrainedModel,t4=z.DINOv3ConvNextModel,t5=z.DINOv3ConvNextPreTrainedModel,t8=z.DINOv3ViTImageProcessor,t6=z.DINOv3ViTModel,t9=z.DINOv3ViTPreTrainedModel,t7=z.DPTFeatureExtractor,re=z.DPTForDepthEstimation,rt=z.DPTImageProcessor,rr=z.DPTModel,rn=z.DPTPreTrainedModel,ro=z.DacDecoderModel,rs=z.DacDecoderOutput,ri=z.DacEncoderModel,ra=z.DacEncoderOutput,rl=z.DacFeatureExtractor,rc=z.DacModel,ru=z.DacPreTrainedModel,rd=z.DataTypeMap,rm=z.DebertaForMaskedLM,rp=z.DebertaForQuestionAnswering,r_=z.DebertaForSequenceClassification,rh=z.DebertaForTokenClassification,rf=z.DebertaModel,rg=z.DebertaPreTrainedModel,rM=z.DebertaTokenizer,rw=z.DebertaV2ForMaskedLM,rT=z.DebertaV2ForQuestionAnswering,rx=z.DebertaV2ForSequenceClassification,rP=z.DebertaV2ForTokenClassification,rb=z.DebertaV2Model,rF=z.DebertaV2PreTrainedModel,rk=z.DebertaV2Tokenizer,ry=z.DecisionTransformerModel,rv=z.DecisionTransformerPreTrainedModel,rC=z.DeiTFeatureExtractor,rS=z.DeiTForImageClassification,rE=z.DeiTImageProcessor,rA=z.DeiTModel,rL=z.DeiTPreTrainedModel,rI=z.DepthAnythingForDepthEstimation,rD=z.DepthAnythingPreTrainedModel,rz=z.DepthEstimationPipeline,rj=z.DepthProForDepthEstimation,rV=z.DepthProPreTrainedModel,rO=z.DetrFeatureExtractor,rN=z.DetrForObjectDetection,rB=z.DetrForSegmentation,rG=z.DetrImageProcessor,rR=z.DetrModel,rq=z.DetrObjectDetectionOutput,r$=z.DetrPreTrainedModel,rW=z.DetrSegmentationOutput,rU=z.Dinov2ForImageClassification,rQ=z.Dinov2Model,rX=z.Dinov2PreTrainedModel,rH=z.Dinov2WithRegistersForImageClassification,rJ=z.Dinov2WithRegistersModel,rY=z.Dinov2WithRegistersPreTrainedModel,rK=z.DistilBertForMaskedLM,rZ=z.DistilBertForQuestionAnswering,r0=z.DistilBertForSequenceClassification,r1=z.DistilBertForTokenClassification,r2=z.DistilBertModel,r3=z.DistilBertPreTrainedModel,r4=z.DistilBertTokenizer,r5=z.DocumentQuestionAnsweringPipeline,r8=z.DonutFeatureExtractor,r6=z.DonutImageProcessor,r9=z.DonutSwinModel,r7=z.DonutSwinPreTrainedModel,ne=z.EfficientNetForImageClassification,nt=z.EfficientNetImageProcessor,nr=z.EfficientNetModel,nn=z.EfficientNetPreTrainedModel,no=z.ElectraForMaskedLM,ns=z.ElectraForQuestionAnswering,ni=z.ElectraForSequenceClassification,na=z.ElectraForTokenClassification,nl=z.ElectraModel,nc=z.ElectraPreTrainedModel,nu=z.ElectraTokenizer,nd=z.EncodecFeatureExtractor,nm=z.EosTokenCriteria,np=z.Ernie4_5_ForCausalLM,n_=z.Ernie4_5_Model,nh=z.Ernie4_5_PretrainedModel,nf=z.Ernie4_5_Tokenizer,ng=z.EsmForMaskedLM,nM=z.EsmForSequenceClassification,nw=z.EsmForTokenClassification,nT=z.EsmModel,nx=z.EsmPreTrainedModel,nP=z.EsmTokenizer,nb=z.ExaoneForCausalLM,nF=z.ExaoneModel,nk=z.ExaonePreTrainedModel,ny=z.FFT,nv=z.FalconForCausalLM,nC=z.FalconModel,nS=z.FalconPreTrainedModel,nE=z.FalconTokenizer,nA=z.FastViTForImageClassification,nL=z.FastViTModel,nI=z.FastViTPreTrainedModel,nD=z.FeatureExtractionPipeline,nz=z.FeatureExtractor,nj=z.FillMaskPipeline,nV=z.Florence2ForConditionalGeneration,nO=z.Florence2PreTrainedModel,nN=z.Florence2Processor,nB=z.ForcedBOSTokenLogitsProcessor,nG=z.ForcedEOSTokenLogitsProcessor,nR=z.GLPNFeatureExtractor,nq=z.GLPNForDepthEstimation,n$=z.GLPNModel,nW=z.GLPNPreTrainedModel,nU=z.GPT2LMHeadModel,nQ=z.GPT2Model,nX=z.GPT2PreTrainedModel,nH=z.GPT2Tokenizer,nJ=z.GPTBigCodeForCausalLM,nY=z.GPTBigCodeModel,nK=z.GPTBigCodePreTrainedModel,nZ=z.GPTJForCausalLM,n0=z.GPTJModel,n1=z.GPTJPreTrainedModel,n2=z.GPTNeoForCausalLM,n3=z.GPTNeoModel,n4=z.GPTNeoPreTrainedModel,n5=z.GPTNeoXForCausalLM,n8=z.GPTNeoXModel,n6=z.GPTNeoXPreTrainedModel,n9=z.GPTNeoXTokenizer,n7=z.Gemma2ForCausalLM,oe=z.Gemma2Model,ot=z.Gemma2PreTrainedModel,or=z.Gemma3ForCausalLM,on=z.Gemma3Model,oo=z.Gemma3PreTrainedModel,os=z.Gemma3nAudioFeatureExtractor,oi=z.Gemma3nForConditionalGeneration,oa=z.Gemma3nPreTrainedModel,ol=z.Gemma3nProcessor,oc=z.GemmaForCausalLM,ou=z.GemmaModel,od=z.GemmaPreTrainedModel,om=z.GemmaTokenizer,op=z.GlmForCausalLM,o_=z.GlmModel,oh=z.GlmPreTrainedModel,of=z.GraniteForCausalLM,og=z.GraniteModel,oM=z.GranitePreTrainedModel,ow=z.Grok1Tokenizer,oT=z.GroundingDinoForObjectDetection,ox=z.GroundingDinoImageProcessor,oP=z.GroundingDinoPreTrainedModel,ob=z.GroundingDinoProcessor,oF=z.GroupViTModel,ok=z.GroupViTPreTrainedModel,oy=z.HeliumForCausalLM,ov=z.HeliumModel,oC=z.HeliumPreTrainedModel,oS=z.HerbertTokenizer,oE=z.HieraForImageClassification,oA=z.HieraModel,oL=z.HieraPreTrainedModel,oI=z.HubertForCTC,oD=z.HubertForSequenceClassification,oz=z.HubertModel,oj=z.HubertPreTrainedModel,oV=z.IJepaForImageClassification,oO=z.IJepaModel,oN=z.IJepaPreTrainedModel,oB=z.Idefics3ForConditionalGeneration,oG=z.Idefics3ImageProcessor,oR=z.Idefics3PreTrainedModel,oq=z.Idefics3Processor,o$=z.ImageClassificationPipeline,oW=z.ImageFeatureExtractionPipeline,oU=z.ImageFeatureExtractor,oQ=z.ImageMattingOutput,oX=z.ImageProcessor,oH=z.ImageSegmentationPipeline,oJ=z.ImageToImagePipeline,oY=z.ImageToTextPipeline,oK=z.InterruptableStoppingCriteria,oZ=z.JAISLMHeadModel,o0=z.JAISModel,o1=z.JAISPreTrainedModel,o2=z.JinaCLIPImageProcessor,o3=z.JinaCLIPModel,o4=z.JinaCLIPPreTrainedModel,o5=z.JinaCLIPProcessor,o8=z.JinaCLIPTextModel,o6=z.JinaCLIPVisionModel,o9=z.Lfm2ForCausalLM,o7=z.Lfm2Model,se=z.Lfm2PreTrainedModel,st=z.LiteWhisperForConditionalGeneration,sr=z.LlamaForCausalLM,sn=z.LlamaModel,so=z.LlamaPreTrainedModel,ss=z.LlamaTokenizer,si=z.LlavaForConditionalGeneration,sa=z.LlavaOnevisionForConditionalGeneration,sl=z.LlavaOnevisionImageProcessor,sc=z.LlavaPreTrainedModel,su=z.LlavaProcessor,sd=z.LlavaQwen2ForCausalLM,sm=z.LogitsProcessor,sp=z.LogitsProcessorList,s_=z.LogitsWarper,sh=z.LongT5ForConditionalGeneration,sf=z.LongT5Model,sg=z.LongT5PreTrainedModel,sM=z.M2M100ForConditionalGeneration,sw=z.M2M100Model,sT=z.M2M100PreTrainedModel,sx=z.M2M100Tokenizer,sP=z.MBart50Tokenizer,sb=z.MBartForCausalLM,sF=z.MBartForConditionalGeneration,sk=z.MBartForSequenceClassification,sy=z.MBartModel,sv=z.MBartPreTrainedModel,sC=z.MBartTokenizer,sS=z.MPNetForMaskedLM,sE=z.MPNetForQuestionAnswering,sA=z.MPNetForSequenceClassification,sL=z.MPNetForTokenClassification,sI=z.MPNetModel,sD=z.MPNetPreTrainedModel,sz=z.MPNetTokenizer,sj=z.MT5ForConditionalGeneration,sV=z.MT5Model,sO=z.MT5PreTrainedModel,sN=z.MarianMTModel,sB=z.MarianModel,sG=z.MarianPreTrainedModel,sR=z.MarianTokenizer,sq=z.Mask2FormerImageProcessor,s$=z.MaskFormerFeatureExtractor,sW=z.MaskFormerForInstanceSegmentation,sU=z.MaskFormerImageProcessor,sQ=z.MaskFormerModel,sX=z.MaskFormerPreTrainedModel,sH=z.MaskedLMOutput,sJ=z.MaxLengthCriteria,sY=z.Metric3DForDepthEstimation,sK=z.Metric3DPreTrainedModel,sZ=z.Metric3Dv2ForDepthEstimation,s0=z.Metric3Dv2PreTrainedModel,s1=z.MgpstrForSceneTextRecognition,s2=z.MgpstrModelOutput,s3=z.MgpstrPreTrainedModel,s4=z.MgpstrProcessor,s5=z.MgpstrTokenizer,s8=z.MimiDecoderModel,s6=z.MimiDecoderOutput,s9=z.MimiEncoderModel,s7=z.MimiEncoderOutput,ie=z.MimiModel,it=z.MimiPreTrainedModel,ir=z.MinLengthLogitsProcessor,io=z.MinNewTokensLengthLogitsProcessor,is=z.MistralForCausalLM,ii=z.MistralModel,ia=z.MistralPreTrainedModel,il=z.MobileBertForMaskedLM,ic=z.MobileBertForQuestionAnswering,iu=z.MobileBertForSequenceClassification,id=z.MobileBertModel,im=z.MobileBertPreTrainedModel,ip=z.MobileBertTokenizer,i_=z.MobileLLMForCausalLM,ih=z.MobileLLMModel,ig=z.MobileLLMPreTrainedModel,iM=z.MobileNetV1FeatureExtractor,iw=z.MobileNetV1ForImageClassification,iT=z.MobileNetV1ForSemanticSegmentation,ix=z.MobileNetV1ImageProcessor,iP=z.MobileNetV1Model,ib=z.MobileNetV1PreTrainedModel,iF=z.MobileNetV2FeatureExtractor,ik=z.MobileNetV2ForImageClassification,iy=z.MobileNetV2ForSemanticSegmentation,iv=z.MobileNetV2ImageProcessor,iC=z.MobileNetV2Model,iS=z.MobileNetV2PreTrainedModel,iE=z.MobileNetV3FeatureExtractor,iA=z.MobileNetV3ForImageClassification,iL=z.MobileNetV3ForSemanticSegmentation,iI=z.MobileNetV3ImageProcessor,iD=z.MobileNetV3Model,iz=z.MobileNetV3PreTrainedModel,ij=z.MobileNetV4FeatureExtractor,iV=z.MobileNetV4ForImageClassification,iO=z.MobileNetV4ForSemanticSegmentation,iN=z.MobileNetV4ImageProcessor,iB=z.MobileNetV4Model,iG=z.MobileNetV4PreTrainedModel,iR=z.MobileViTFeatureExtractor,iq=z.MobileViTForImageClassification,i$=z.MobileViTImageProcessor,iW=z.MobileViTModel,iU=z.MobileViTPreTrainedModel,iQ=z.MobileViTV2ForImageClassification,iX=z.MobileViTV2Model,iH=z.MobileViTV2PreTrainedModel,iJ=z.ModelOutput,iY=z.ModernBertDecoderForCausalLM,iK=z.ModernBertDecoderModel,iZ=z.ModernBertDecoderPreTrainedModel,i0=z.ModernBertForMaskedLM,i1=z.ModernBertForSequenceClassification,i2=z.ModernBertForTokenClassification,i3=z.ModernBertModel,i4=z.ModernBertPreTrainedModel,i5=z.Moondream1ForConditionalGeneration,i8=z.MoonshineFeatureExtractor,i6=z.MoonshineForConditionalGeneration,i9=z.MoonshineModel,i7=z.MoonshinePreTrainedModel,ae=z.MoonshineProcessor,at=z.MptForCausalLM,ar=z.MptModel,an=z.MptPreTrainedModel,ao=z.MultiModalityCausalLM,as=z.MultiModalityPreTrainedModel,ai=z.MusicgenForCausalLM,aa=z.MusicgenForConditionalGeneration,al=z.MusicgenModel,ac=z.MusicgenPreTrainedModel,au=z.NeoBertForMaskedLM,ad=z.NeoBertForQuestionAnswering,am=z.NeoBertForSequenceClassification,ap=z.NeoBertForTokenClassification,a_=z.NeoBertModel,ah=z.NeoBertPreTrainedModel,af=z.NllbTokenizer,ag=z.NoBadWordsLogitsProcessor,aM=z.NoRepeatNGramLogitsProcessor,aw=z.NomicBertModel,aT=z.NomicBertPreTrainedModel,ax=z.NougatImageProcessor,aP=z.NougatTokenizer,ab=z.OPTForCausalLM,aF=z.OPTModel,ak=z.OPTPreTrainedModel,ay=z.ObjectDetectionPipeline,av=z.Olmo2ForCausalLM,aC=z.Olmo2Model,aS=z.Olmo2PreTrainedModel,aE=z.OlmoForCausalLM,aA=z.OlmoModel,aL=z.OlmoPreTrainedModel,aI=z.OpenELMForCausalLM,aD=z.OpenELMModel,az=z.OpenELMPreTrainedModel,aj=z.OwlViTFeatureExtractor,aV=z.OwlViTForObjectDetection,aO=z.OwlViTImageProcessor,aN=z.OwlViTModel,aB=z.OwlViTPreTrainedModel,aG=z.OwlViTProcessor,aR=z.Owlv2ForObjectDetection,aq=z.Owlv2ImageProcessor,a$=z.Owlv2Model,aW=z.Owlv2PreTrainedModel,aU=z.PaliGemmaForConditionalGeneration,aQ=z.PaliGemmaPreTrainedModel,aX=z.PaliGemmaProcessor,aH=z.PatchTSMixerForPrediction,aJ=z.PatchTSMixerModel,aY=z.PatchTSMixerPreTrainedModel,aK=z.PatchTSTForPrediction,aZ=z.PatchTSTModel,a0=z.PatchTSTPreTrainedModel,a1=z.Phi3ForCausalLM,a2=z.Phi3Model,a3=z.Phi3PreTrainedModel,a4=z.Phi3VForCausalLM,a5=z.Phi3VImageProcessor,a8=z.Phi3VPreTrainedModel,a6=z.Phi3VProcessor,a9=z.PhiForCausalLM,a7=z.PhiModel,le=z.PhiPreTrainedModel,lt=z.Pipeline,lr=z.PreTrainedModel,ln=z.PreTrainedTokenizer,lo=z.PretrainedConfig,ls=z.PretrainedMixin,li=z.Processor,la=z.PvtForImageClassification,ll=z.PvtImageProcessor,lc=z.PvtModel,lu=z.PvtPreTrainedModel,ld=z.PyAnnoteFeatureExtractor,lm=z.PyAnnoteForAudioFrameClassification,lp=z.PyAnnoteModel,l_=z.PyAnnotePreTrainedModel,lh=z.PyAnnoteProcessor,lf=z.QuestionAnsweringModelOutput,lg=z.QuestionAnsweringPipeline,lM=z.Qwen2ForCausalLM,lw=z.Qwen2Model,lT=z.Qwen2PreTrainedModel,lx=z.Qwen2Tokenizer,lP=z.Qwen2VLForConditionalGeneration,lb=z.Qwen2VLImageProcessor,lF=z.Qwen2VLPreTrainedModel,lk=z.Qwen2VLProcessor,ly=z.Qwen3ForCausalLM,lv=z.Qwen3Model,lC=z.Qwen3PreTrainedModel,lS=z.RFDetrForObjectDetection,lE=z.RFDetrModel,lA=z.RFDetrObjectDetectionOutput,lL=z.RFDetrPreTrainedModel,lI=z.RTDetrForObjectDetection,lD=z.RTDetrImageProcessor,lz=z.RTDetrModel,lj=z.RTDetrObjectDetectionOutput,lV=z.RTDetrPreTrainedModel,lO=z.RTDetrV2ForObjectDetection,lN=z.RTDetrV2Model,lB=z.RTDetrV2ObjectDetectionOutput,lG=z.RTDetrV2PreTrainedModel,lR=z.RawAudio,lq=z.RawImage,l$=z.RawVideo,lW=z.RawVideoFrame,lU=z.RepetitionPenaltyLogitsProcessor,lQ=z.ResNetForImageClassification,lX=z.ResNetModel,lH=z.ResNetPreTrainedModel,lJ=z.RoFormerForMaskedLM,lY=z.RoFormerForQuestionAnswering,lK=z.RoFormerForSequenceClassification,lZ=z.RoFormerForTokenClassification,l0=z.RoFormerModel,l1=z.RoFormerPreTrainedModel,l2=z.RoFormerTokenizer,l3=z.RobertaForMaskedLM,l4=z.RobertaForQuestionAnswering,l5=z.RobertaForSequenceClassification,l8=z.RobertaForTokenClassification,l6=z.RobertaModel,l9=z.RobertaPreTrainedModel,l7=z.RobertaTokenizer,ce=z.SamImageProcessor,ct=z.SamImageSegmentationOutput,cr=z.SamModel,cn=z.SamPreTrainedModel,co=z.SamProcessor,cs=z.SapiensForDepthEstimation,ci=z.SapiensForNormalEstimation,ca=z.SapiensForSemanticSegmentation,cl=z.SapiensPreTrainedModel,cc=z.SeamlessM4TFeatureExtractor,cu=z.SegformerFeatureExtractor,cd=z.SegformerForImageClassification,cm=z.SegformerForSemanticSegmentation,cp=z.SegformerImageProcessor,c_=z.SegformerModel,ch=z.SegformerPreTrainedModel,cf=z.Seq2SeqLMOutput,cg=z.SequenceClassifierOutput,cM=z.SiglipImageProcessor,cw=z.SiglipModel,cT=z.SiglipPreTrainedModel,cx=z.SiglipTextModel,cP=z.SiglipTokenizer,cb=z.SiglipVisionModel,cF=z.SmolLM3ForCausalLM,ck=z.SmolLM3Model,cy=z.SmolLM3PreTrainedModel,cv=z.SmolVLMForConditionalGeneration,cC=z.SmolVLMImageProcessor,cS=z.SmolVLMProcessor,cE=z.SnacDecoderModel,cA=z.SnacEncoderModel,cL=z.SnacFeatureExtractor,cI=z.SnacModel,cD=z.SnacPreTrainedModel,cz=z.SpeechT5FeatureExtractor,cj=z.SpeechT5ForSpeechToText,cV=z.SpeechT5ForTextToSpeech,cO=z.SpeechT5HifiGan,cN=z.SpeechT5Model,cB=z.SpeechT5PreTrainedModel,cG=z.SpeechT5Processor,cR=z.SpeechT5Tokenizer,cq=z.SqueezeBertForMaskedLM,c$=z.SqueezeBertForQuestionAnswering,cW=z.SqueezeBertForSequenceClassification,cU=z.SqueezeBertModel,cQ=z.SqueezeBertPreTrainedModel,cX=z.SqueezeBertTokenizer,cH=z.StableLmForCausalLM,cJ=z.StableLmModel,cY=z.StableLmPreTrainedModel,cK=z.Starcoder2ForCausalLM,cZ=z.Starcoder2Model,c0=z.Starcoder2PreTrainedModel,c1=z.StoppingCriteria,c2=z.StoppingCriteriaList,c3=z.StyleTextToSpeech2Model,c4=z.StyleTextToSpeech2PreTrainedModel,c5=z.SummarizationPipeline,c8=z.SuppressTokensAtBeginLogitsProcessor,c6=z.Swin2SRForImageSuperResolution,c9=z.Swin2SRImageProcessor,c7=z.Swin2SRModel,ue=z.Swin2SRPreTrainedModel,ut=z.SwinForImageClassification,ur=z.SwinForSemanticSegmentation,un=z.SwinModel,uo=z.SwinPreTrainedModel,us=z.T5ForConditionalGeneration,ui=z.T5Model,ua=z.T5PreTrainedModel,ul=z.T5Tokenizer,uc=z.TableTransformerForObjectDetection,uu=z.TableTransformerModel,ud=z.TableTransformerObjectDetectionOutput,um=z.TableTransformerPreTrainedModel,up=z.TemperatureLogitsWarper,u_=z.Tensor,uh=z.Text2TextGenerationPipeline,uf=z.TextClassificationPipeline,ug=z.TextGenerationPipeline,uM=z.TextStreamer,uw=z.TextToAudioPipeline,uT=z.TokenClassificationPipeline,ux=z.TokenClassifierOutput,uP=z.TokenizerModel,ub=z.TopKLogitsWarper,uF=z.TopPLogitsWarper,uk=z.TrOCRForCausalLM,uy=z.TrOCRPreTrainedModel,uv=z.TranslationPipeline,uC=z.UltravoxModel,uS=z.UltravoxPreTrainedModel,uE=z.UltravoxProcessor,uA=z.UniSpeechForCTC,uL=z.UniSpeechForSequenceClassification,uI=z.UniSpeechModel,uD=z.UniSpeechPreTrainedModel,uz=z.UniSpeechSatForAudioFrameClassification,uj=z.UniSpeechSatForCTC,uV=z.UniSpeechSatForSequenceClassification,uO=z.UniSpeechSatModel,uN=z.UniSpeechSatPreTrainedModel,uB=z.VLChatProcessor,uG=z.VLMImageProcessor,uR=z.ViTFeatureExtractor,uq=z.ViTForImageClassification,u$=z.ViTImageProcessor,uW=z.ViTMAEModel,uU=z.ViTMAEPreTrainedModel,uQ=z.ViTMSNForImageClassification,uX=z.ViTMSNModel,uH=z.ViTMSNPreTrainedModel,uJ=z.ViTModel,uY=z.ViTPreTrainedModel,uK=z.VisionEncoderDecoderModel,uZ=z.VitMatteForImageMatting,u0=z.VitMatteImageProcessor,u1=z.VitMattePreTrainedModel,u2=z.VitPoseForPoseEstimation,u3=z.VitPoseImageProcessor,u4=z.VitPosePreTrainedModel,u5=z.VitsModel,u8=z.VitsModelOutput,u6=z.VitsPreTrainedModel,u9=z.VitsTokenizer,u7=z.VoxtralForConditionalGeneration,de=z.VoxtralProcessor,dt=z.Wav2Vec2BertForCTC,dr=z.Wav2Vec2BertForSequenceClassification,dn=z.Wav2Vec2BertModel,ds=z.Wav2Vec2BertPreTrainedModel,di=z.Wav2Vec2CTCTokenizer,da=z.Wav2Vec2FeatureExtractor,dl=z.Wav2Vec2ForAudioFrameClassification,dc=z.Wav2Vec2ForCTC,du=z.Wav2Vec2ForSequenceClassification,dd=z.Wav2Vec2Model,dm=z.Wav2Vec2PreTrainedModel,dp=z.Wav2Vec2Processor,d_=z.Wav2Vec2ProcessorWithLM,dh=z.WavLMForAudioFrameClassification,df=z.WavLMForCTC,dg=z.WavLMForSequenceClassification,dM=z.WavLMForXVector,dw=z.WavLMModel,dT=z.WavLMPreTrainedModel,dx=z.WeSpeakerFeatureExtractor,dP=z.WeSpeakerResNetModel,db=z.WeSpeakerResNetPreTrainedModel,dF=z.WhisperFeatureExtractor,dk=z.WhisperForConditionalGeneration,dy=z.WhisperModel,dv=z.WhisperPreTrainedModel,dC=z.WhisperProcessor,dS=z.WhisperTextStreamer,dE=z.WhisperTimeStampLogitsProcessor,dA=z.WhisperTokenizer,dL=z.XLMForQuestionAnswering,dI=z.XLMForSequenceClassification,dD=z.XLMForTokenClassification,dz=z.XLMModel,dj=z.XLMPreTrainedModel,dV=z.XLMRobertaForMaskedLM,dO=z.XLMRobertaForQuestionAnswering,dN=z.XLMRobertaForSequenceClassification,dB=z.XLMRobertaForTokenClassification,dG=z.XLMRobertaModel,dR=z.XLMRobertaPreTrainedModel,dq=z.XLMRobertaTokenizer,d$=z.XLMTokenizer,dW=z.XLMWithLMHeadModel,dU=z.XVectorOutput,dQ=z.YolosFeatureExtractor,dX=z.YolosForObjectDetection,dH=z.YolosImageProcessor,dJ=z.YolosModel,dY=z.YolosObjectDetectionOutput,dK=z.YolosPreTrainedModel,dZ=z.ZeroShotAudioClassificationPipeline,d0=z.ZeroShotClassificationPipeline,d1=z.ZeroShotImageClassificationPipeline,d2=z.ZeroShotObjectDetectionPipeline,d3=z.bankers_round,d4=z.cat,d5=z.cos_sim,d8=z.dot,d6=z.dynamic_time_warping,d9=z.env,d7=z.full,me=z.full_like,mt=z.getCacheShapes,mr=z.hamming,mn=z.hanning,mo=z.interpolate,ms=z.interpolate_4d,mi=z.interpolate_data,ma=z.is_chinese_char,ml=z.layer_norm,mc=z.load_image,mu=z.load_video,md=z.log_softmax,mm=z.magnitude,mp=z.matmul,m_=z.max,mh=z.mean,mf=z.mean_pooling,mg=z.medianFilter,mM=z.mel_filter_bank,mw=z.min,mT=z.ones,mx=z.ones_like,mP=z.permute,mb=z.permute_data,mF=z.pipeline,mk=z.quantize_embeddings,my=z.rand,mv=z.read_audio,mC=z.rfft,mS=z.round,mE=z.slice,mA=z.softmax,mL=z.spectrogram,mI=z.stack,mD=z.std_mean,mz=z.topk,mj=z.window_function,mV=z.zeros,mO=z.zeros_like}}]);